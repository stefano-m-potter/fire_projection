{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aea4fe3-f801-45b4-9ea8-03999a917799",
   "metadata": {},
   "source": [
    "This script will take the 2 stage model trained on FireCCI and apply it to modis 2020-2023, and then compare burned area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c22fa-66f3-49a8-82ec-a502fc15ba36",
   "metadata": {},
   "source": [
    "First we need to aggregate modis up to the 1 degree grid and save that as a parquet file.  We can use this to apply the saved stage 1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aa3eb5a-551c-42af-ae97-2b19ff91c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR] 2001 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2001_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2001_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n",
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'burned_label' to 'burned_lab'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2001_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2002 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2002_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2002_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2002_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2003 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2003_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2003_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2003_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2004 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2004_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2004_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2004_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2005 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2005_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2005_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2005_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2006 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2006_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2006_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2006_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2007 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2007_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2007_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2007_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2008 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2008_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2008_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2008_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2009 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2009_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2009_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2009_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2010 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2010_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2010_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2010_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2011 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2011_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2011_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2011_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2012 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2012_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2012_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2012_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2013 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2013_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2013_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2013_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2014 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2014_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2014_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2014_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2015 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2015_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2015_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2015_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2016 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2016_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2016_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2016_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2017 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2017_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2017_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2017_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2018 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2018_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2018_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2018_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2019 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2019_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2019_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2019_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2020 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2020_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2020_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2020_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2021 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2021_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2021_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2021_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2022 — 12 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2022_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2022_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2022_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[YEAR] 2023 — 11 monthly files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:447: RuntimeWarning: All-NaN slice encountered\n",
      "  annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:453: RuntimeWarning: Mean of empty slice\n",
      "  annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PARQUET] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2023_annual_grid1deg.parquet\n",
      "[TIF] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/tifs_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2023_annual_grid1deg_epsg4326_burned_unburned.tif (EPSG:4326, 1°)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/spotter5/temp_dir/ipykernel_458479/1444156610.py:362: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  shp_gdf.to_file(shp_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SHP] Saved /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical/cems_e5l_mcd_2023_annual_grid1deg_cells_epsg4326.shp (EPSG:4326)\n",
      "\n",
      "[DONE] Analytical coarse grids (1 degree, 0.05 threshold) created.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# PATHS\n",
    "# ----------------------------------------------------------------------\n",
    "# Monthly 4 km files with predictors + fraction live here:\n",
    "# FIXED: Added leading slash \"/\" to make this an absolute path\n",
    "OUT_DIR = \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\"\n",
    "\n",
    "# Where to save ANNUAL coarse-grid parquet, tifs, shapefiles\n",
    "PARQUET_DIR    = Path(OUT_DIR) / \"parquet_coarse_grids_annual_mcd_analytical\"\n",
    "COARSE_TIF_DIR = Path(OUT_DIR) / \"tifs_coarse_grids_annual_mcd_analytical\"\n",
    "COARSE_SHP_DIR = Path(OUT_DIR) / \"shp_coarse_grids_annual_mcd_analytical\"\n",
    "\n",
    "os.makedirs(PARQUET_DIR, exist_ok=True)\n",
    "os.makedirs(COARSE_TIF_DIR, exist_ok=True)\n",
    "os.makedirs(COARSE_SHP_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONSTANTS\n",
    "# ----------------------------------------------------------------------\n",
    "WANTED = [\n",
    "    \"DEM\",\n",
    "    \"slope\",\n",
    "    \"aspect\",                     # will match 'aspect' or 'aspectrad' etc.\n",
    "    \"b1\",                         # land cover (categorical)\n",
    "    \"relative_humidity\",\n",
    "    \"total_precipitation_sum\",\n",
    "    \"temperature_2m\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"build_up_index\",\n",
    "    \"drought_code\",\n",
    "    \"duff_moisture_code\",\n",
    "    \"fine_fuel_moisture_code\",\n",
    "    \"fire_weather_index\",\n",
    "    \"initial_fire_spread_index\",  # if files use 'initial_spread_index', it’ll still match\n",
    "]\n",
    "\n",
    "# UPDATED SETTINGS BASED ON OPTIMIZATION WINNER\n",
    "GRID_SIZES_DEG      = [1]         # ONLY 1 Degree\n",
    "BURNED_THRESHOLD    = 0.05        # >=5% of 4 km pixels burned -> coarse cell burned\n",
    "FRACTION_BAND_NAME  = \"fraction\"  # description set when you made *_with_fraction.tif\n",
    "\n",
    "# If True: also write a QA GeoTIFF that paints coarse labels back onto the 4 km EPSG:3413 grid\n",
    "WRITE_QA_LABEL_ON_4KM = False\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HELPERS\n",
    "# ----------------------------------------------------------------------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]\", \"\", s.lower())\n",
    "\n",
    "WANTED_NORM   = [_norm(x) for x in WANTED]\n",
    "FRACTION_NORM = _norm(FRACTION_BAND_NAME)\n",
    "\n",
    "# Filenames like: cems_e5l_mcd_2004_7_with_fraction.tif\n",
    "# FIXED: Matches 'mcd' filenames\n",
    "name_re = re.compile(r\"cems_e5l_mcd_(\\d{4})_(\\d{1,2})_with_fraction\\.tif$\", re.IGNORECASE)\n",
    "\n",
    "def parse_year_month(path: Path):\n",
    "    m = name_re.search(path.name)\n",
    "    return (int(m.group(1)), int(m.group(2))) if m else None\n",
    "\n",
    "def map_band_indices_by_name(ds: rio.DatasetReader):\n",
    "    mapping = {}\n",
    "    descs = ds.descriptions  # tuple length = band count; may contain None\n",
    "    for i, d in enumerate(descs, start=1):\n",
    "        if d is None:\n",
    "            d = f\"B{i}\"\n",
    "        mapping[_norm(d)] = i\n",
    "    return mapping, descs\n",
    "\n",
    "def compute_lonlat_grid(ds: rio.DatasetReader):\n",
    "    \"\"\"\n",
    "    Compute lon/lat center coordinates for each pixel in ds, always returning EPSG:4326 lon/lat.\n",
    "    Works whether ds is EPSG:3413 (meters) or already EPSG:4326 (degrees), etc.\n",
    "    \"\"\"\n",
    "    h, w = ds.height, ds.width\n",
    "    rows, cols = np.indices((h, w))\n",
    "    xs, ys = rio.transform.xy(ds.transform, rows, cols, offset=\"center\")\n",
    "    x = np.asarray(xs, dtype=np.float64)\n",
    "    y = np.asarray(ys, dtype=np.float64)\n",
    "\n",
    "    if ds.crs is None:\n",
    "        raise RuntimeError(\"Dataset has no CRS; cannot compute lon/lat.\")\n",
    "\n",
    "    epsg = ds.crs.to_epsg()\n",
    "    if epsg == 4326:\n",
    "        lon = x.astype(np.float32)\n",
    "        lat = y.astype(np.float32)\n",
    "        return lon, lat\n",
    "\n",
    "    transformer = Transformer.from_crs(ds.crs, \"EPSG:4326\", always_xy=True)\n",
    "    lon, lat = transformer.transform(x, y)\n",
    "    return lon.astype(np.float32), lat.astype(np.float32)\n",
    "\n",
    "def mode_ignore_nan(x: pd.Series):\n",
    "    \"\"\"Majority value ignoring NaNs. Returns NaN if all are NaN.\"\"\"\n",
    "    x = x.dropna()\n",
    "    if x.empty:\n",
    "        return np.nan\n",
    "    return x.value_counts().idxmax()\n",
    "\n",
    "def aggregate_to_coarse_grids_annual(\n",
    "    year: int,\n",
    "    ds: rio.DatasetReader,\n",
    "    predictors_stack: np.ndarray,\n",
    "    predictor_names: list,\n",
    "    annual_frac: np.ndarray,\n",
    "    lon: np.ndarray,\n",
    "    lat: np.ndarray,\n",
    "    grid_sizes_deg=GRID_SIZES_DEG,\n",
    "    burned_threshold=BURNED_THRESHOLD,\n",
    "    parquet_dir: Path = PARQUET_DIR,\n",
    "    coarse_tif_dir: Path = COARSE_TIF_DIR,\n",
    "    coarse_shp_dir: Path = COARSE_SHP_DIR,\n",
    "    base_name: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Aggregate annual 4 km fraction to coarse grids (1 deg only), build binary label,\n",
    "    assign unique ID per cell, and save outputs.\n",
    "    \"\"\"\n",
    "    H, W = ds.height, ds.width\n",
    "    N = H * W\n",
    "\n",
    "    # Flatten\n",
    "    lon_flat  = lon.ravel()\n",
    "    lat_flat  = lat.ravel()\n",
    "    frac_flat = annual_frac.ravel()\n",
    "\n",
    "    # Binary 4 km input: burned if fraction > 0 (ANY fire)\n",
    "    binary_4km_flat = np.zeros_like(frac_flat, dtype=np.uint8)\n",
    "    valid_frac = ~np.isnan(frac_flat)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # CRITICAL LOGIC: Using > 0 to capture any fire for input aggregation\n",
    "    # -----------------------------------------------------------\n",
    "    binary_4km_flat[valid_frac & (frac_flat > 0)] = 1 \n",
    "    binary_4km_flat[~valid_frac] = 0  # will be masked via valid_frac\n",
    "\n",
    "    # Flatten predictors\n",
    "    pred_flat = {\n",
    "        name: band.ravel()\n",
    "        for name, band in zip(predictor_names, predictors_stack)\n",
    "    }\n",
    "\n",
    "    # Use only pixels where fraction is not NaN\n",
    "    valid = valid_frac\n",
    "    valid_idx = np.nonzero(valid)[0]\n",
    "\n",
    "    if valid_idx.size == 0:\n",
    "        print(f\"[WARN] Year {year}: no valid annual fraction pixels; skipping coarse grids.\")\n",
    "        return\n",
    "\n",
    "    # Per-pixel values for valid pixels\n",
    "    frac_valid = frac_flat[valid]\n",
    "    bin_valid  = binary_4km_flat[valid]\n",
    "    lon_valid  = lon_flat[valid]\n",
    "    lat_valid  = lat_flat[valid]\n",
    "    pred_valid = {name: arr[valid] for name, arr in pred_flat.items()}\n",
    "\n",
    "    for size_deg in grid_sizes_deg:\n",
    "        # Assign each valid pixel to a coarse EPSG:4326 grid cell\n",
    "        big_lon = size_deg * np.floor(lon_valid / size_deg)\n",
    "        big_lat = size_deg * np.floor(lat_valid / size_deg)\n",
    "\n",
    "        df_dict = {\n",
    "            \"big_lon\": big_lon.astype(np.float32),\n",
    "            \"big_lat\": big_lat.astype(np.float32),\n",
    "            \"burned_4km\": bin_valid.astype(np.uint8),\n",
    "            \"frac_4km\": frac_valid.astype(np.float32),\n",
    "            \"flat_idx\": valid_idx.astype(np.int64),\n",
    "        }\n",
    "\n",
    "        for name in predictor_names:\n",
    "            # Keep b1 as float32 here; mode_ignore_nan will still work.\n",
    "            df_dict[name] = pred_valid[name].astype(np.float32)\n",
    "\n",
    "        df = pd.DataFrame(df_dict)\n",
    "\n",
    "        # Group by coarse cell\n",
    "        group_cols = [\"big_lon\", \"big_lat\"]\n",
    "        agg_dict = {\n",
    "            \"burned_4km\": \"mean\",  # fraction of 4 km pixels burned in the coarse cell\n",
    "            \"frac_4km\": \"mean\",    # mean annual fraction (diagnostic)\n",
    "        }\n",
    "\n",
    "        # new way which is right\n",
    "        for name in predictor_names:\n",
    "            if name == \"b1\":\n",
    "                agg_dict[name] = mode_ignore_nan  # majority land cover\n",
    "            elif name in [\"relative_humidity\", \"total_precipitation_sum\"]:\n",
    "                agg_dict[name] = \"min\"\n",
    "            elif name in [\n",
    "                \"temperature_2m\",\n",
    "                \"temperature_2m_min\",\n",
    "                \"temperature_2m_max\",\n",
    "                \"build_up_index\",\n",
    "                \"drought_code\",\n",
    "                \"duff_moisture_code\",\n",
    "                \"fine_fuel_moisture_code\",\n",
    "                \"fire_weather_index\",\n",
    "                \"initial_fire_spread_index\",\n",
    "            ]:\n",
    "                agg_dict[name] = \"max\"\n",
    "            else:\n",
    "                # Default to mean for DEM, slope, aspect, and any unspecified variables\n",
    "                agg_dict[name] = \"mean\"\n",
    "\n",
    "        grouped = df.groupby(group_cols, as_index=False).agg(agg_dict)\n",
    "\n",
    "        # Rename burned_4km -> burned_frac_4km for clarity\n",
    "        grouped = grouped.rename(columns={\"burned_4km\": \"burned_frac_4km\"})\n",
    "\n",
    "        # Coarse burned/unburned label: 1 if >= threshold (0.05) of underlying 4 km pixels burned\n",
    "        grouped[\"burned_label\"] = (grouped[\"burned_frac_4km\"] >= burned_threshold).astype(np.uint8)\n",
    "\n",
    "        # Deterministic row order and assign ID 0..N-1\n",
    "        grouped = grouped.sort_values([\"big_lat\", \"big_lon\"]).reset_index(drop=True)\n",
    "        grouped[\"ID\"] = np.arange(len(grouped), dtype=np.int64)\n",
    "\n",
    "        # Metadata\n",
    "        grouped[\"year\"]     = year\n",
    "        grouped[\"grid_deg\"] = size_deg\n",
    "\n",
    "        # Save Parquet: one row per coarse cell\n",
    "        parquet_name = f\"{base_name}_grid{size_deg}deg.parquet\"\n",
    "        parquet_path = parquet_dir / parquet_name\n",
    "        grouped.to_parquet(parquet_path, index=False)\n",
    "        print(f\"[PARQUET] Saved {parquet_path}\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # GeoTIFF (COARSE GRID): EPSG:4326 at size_deg resolution\n",
    "        # ------------------------------------------------------------------\n",
    "        min_lon = float(grouped[\"big_lon\"].min())\n",
    "        max_lon = float(grouped[\"big_lon\"].max()) + float(size_deg)\n",
    "        min_lat = float(grouped[\"big_lat\"].min())\n",
    "        max_lat = float(grouped[\"big_lat\"].max()) + float(size_deg)\n",
    "\n",
    "        transform = from_origin(min_lon, max_lat, float(size_deg), float(size_deg))\n",
    "        width  = int(np.ceil((max_lon - min_lon) / float(size_deg)))\n",
    "        height = int(np.ceil((max_lat - min_lat) / float(size_deg)))\n",
    "\n",
    "        shapes = []\n",
    "        for lon0, lat0, lab in zip(grouped[\"big_lon\"], grouped[\"big_lat\"], grouped[\"burned_label\"]):\n",
    "            lon1 = float(lon0) + float(size_deg)\n",
    "            lat1 = float(lat0) + float(size_deg)\n",
    "            poly = Polygon([(lon0, lat0), (lon1, lat0), (lon1, lat1), (lon0, lat1)])\n",
    "            shapes.append((poly, int(lab)))\n",
    "\n",
    "        coarse_raster = rasterize(\n",
    "            shapes=shapes,\n",
    "            out_shape=(height, width),\n",
    "            transform=transform,\n",
    "            fill=255,           # nodata\n",
    "            dtype=\"uint8\",\n",
    "            all_touched=False\n",
    "        )\n",
    "\n",
    "        coarse_profile = {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"count\": 1,\n",
    "            \"dtype\": \"uint8\",\n",
    "            \"crs\": \"EPSG:4326\",\n",
    "            \"transform\": transform,\n",
    "            \"nodata\": 255,\n",
    "            \"compress\": \"LZW\",\n",
    "            \"tiled\": True,\n",
    "            \"blockxsize\": 256,\n",
    "            \"blockysize\": 256,\n",
    "            \"BIGTIFF\": \"IF_SAFER\",\n",
    "        }\n",
    "\n",
    "        tif_name = f\"{base_name}_grid{size_deg}deg_epsg4326_burned_unburned.tif\"\n",
    "        tif_path = coarse_tif_dir / tif_name\n",
    "\n",
    "        with rio.open(tif_path, \"w\", **coarse_profile) as dst:\n",
    "            dst.write(coarse_raster, 1)\n",
    "\n",
    "        print(f\"[TIF] Saved {tif_path} (EPSG:4326, {size_deg}°)\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # OPTIONAL QA GeoTIFF: paint coarse labels back onto original 4 km grid\n",
    "        # ------------------------------------------------------------------\n",
    "        if WRITE_QA_LABEL_ON_4KM:\n",
    "            label_map = grouped[[\"big_lon\", \"big_lat\", \"burned_label\"]].copy()\n",
    "            df_lbl = df.merge(label_map, on=[\"big_lon\", \"big_lat\"], how=\"left\")\n",
    "\n",
    "            coarse_label_flat = np.full(N, 255, dtype=np.uint8)  # nodata=255\n",
    "            coarse_label_flat[df_lbl[\"flat_idx\"].to_numpy()] = (\n",
    "                df_lbl[\"burned_label\"].to_numpy().astype(np.uint8)\n",
    "            )\n",
    "            coarse_label_4km = coarse_label_flat.reshape(H, W)\n",
    "\n",
    "            profile_4km = ds.profile.copy()\n",
    "            profile_4km.update(\n",
    "                dtype=\"uint8\",\n",
    "                count=1,\n",
    "                compress=\"LZW\",\n",
    "                tiled=True,\n",
    "                blockxsize=256,\n",
    "                blockysize=256,\n",
    "                BIGTIFF=\"IF_SAFER\",\n",
    "                nodata=255,\n",
    "            )\n",
    "\n",
    "            tif_name_4km = f\"{base_name}_grid{size_deg}deg_label_on4km_epsg{ds.crs.to_epsg() if ds.crs else 'unknown'}.tif\"\n",
    "            tif_path_4km = coarse_tif_dir / tif_name_4km\n",
    "\n",
    "            with rio.open(tif_path_4km, \"w\", **profile_4km) as dst:\n",
    "                dst.write(coarse_label_4km, 1)\n",
    "\n",
    "            print(f\"[TIF-QA] Saved {tif_path_4km} (label on original grid)\")\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Shapefile: one polygon per coarse cell, attributes: ID + burned_label\n",
    "        # ------------------------------------------------------------------\n",
    "        geoms = []\n",
    "        ids    = grouped[\"ID\"].to_numpy()\n",
    "        labels = grouped[\"burned_label\"].to_numpy()\n",
    "\n",
    "        for lon0, lat0 in zip(grouped[\"big_lon\"], grouped[\"big_lat\"]):\n",
    "            lon1 = float(lon0) + float(size_deg)\n",
    "            lat1 = float(lat0) + float(size_deg)\n",
    "            poly = Polygon([\n",
    "                (lon0, lat0),\n",
    "                (lon1, lat0),\n",
    "                (lon1, lat1),\n",
    "                (lon0, lat1),\n",
    "                (lon0, lat0),\n",
    "            ])\n",
    "            geoms.append(poly)\n",
    "\n",
    "        shp_gdf = gpd.GeoDataFrame(\n",
    "            {\"ID\": ids, \"burned_label\": labels},\n",
    "            geometry=geoms,\n",
    "            crs=\"EPSG:4326\",\n",
    "        )\n",
    "\n",
    "        shp_name = f\"{base_name}_grid{size_deg}deg_cells_epsg4326.shp\"\n",
    "        shp_path = coarse_shp_dir / shp_name\n",
    "        shp_gdf.to_file(shp_path)\n",
    "        print(f\"[SHP] Saved {shp_path} (EPSG:4326)\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# MAIN: BUILD ANNUAL FROM MONTHLY *_with_fraction.tif\n",
    "# ----------------------------------------------------------------------\n",
    "# FIXED: Looking for 'mcd' files in the absolute path\n",
    "monthly_tifs = sorted(Path(OUT_DIR).glob(\"cems_e5l_mcd_*_with_fraction.tif\"))\n",
    "if not monthly_tifs:\n",
    "    print(f\"No monthly _with_fraction.tif files found in {OUT_DIR}\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Group monthly files by year\n",
    "year_to_paths = defaultdict(list)\n",
    "for p in monthly_tifs:\n",
    "    ym = parse_year_month(p)\n",
    "    if ym is None:\n",
    "        print(f\"[SKIP name] {p.name}\")\n",
    "        continue\n",
    "    year, month = ym\n",
    "    year_to_paths[year].append((month, p))\n",
    "\n",
    "for year in sorted(year_to_paths.keys()):\n",
    "    month_paths = sorted(year_to_paths[year], key=lambda x: x[0])\n",
    "    print(f\"\\n[YEAR] {year} — {len(month_paths)} monthly files\")\n",
    "\n",
    "    # Use first month's file as template for grid, CRS, etc.\n",
    "    first_month, first_path = month_paths[0]\n",
    "    with rio.open(first_path) as ds_template:\n",
    "        H, W = ds_template.height, ds_template.width\n",
    "        band_map, descs = map_band_indices_by_name(ds_template)\n",
    "\n",
    "        # Figure out predictor band indices and fraction band index\n",
    "        predictor_indices = []\n",
    "        predictor_names   = []\n",
    "\n",
    "        for want_norm, want_orig in zip(WANTED_NORM, WANTED):\n",
    "            if want_norm in band_map:\n",
    "                predictor_indices.append(band_map[want_norm])\n",
    "                predictor_names.append(want_orig)\n",
    "                continue\n",
    "            # partial match (handles 'aspect' vs 'aspectrad', etc.)\n",
    "            match_idx = None\n",
    "            for k_norm, idx in band_map.items():\n",
    "                if want_norm in k_norm or k_norm in want_norm:\n",
    "                    match_idx = idx\n",
    "                    break\n",
    "            if match_idx is not None:\n",
    "                predictor_indices.append(match_idx)\n",
    "                predictor_names.append(want_orig)\n",
    "            else:\n",
    "                print(f\"[WARN] {first_path.name}: could not find band like '{want_orig}'\")\n",
    "\n",
    "        if FRACTION_NORM not in band_map:\n",
    "            raise RuntimeError(f\"{first_path} has no band named/desc like '{FRACTION_BAND_NAME}'\")\n",
    "\n",
    "        frac_idx = band_map[FRACTION_NORM]\n",
    "\n",
    "        if not predictor_indices:\n",
    "            print(f\"[SKIP no predictors for year {year}]\")\n",
    "            continue\n",
    "\n",
    "        # Prepare storage for monthly stacks\n",
    "        frac_months = []  # list of (H, W)\n",
    "        pred_months = {name: [] for name in predictor_names}\n",
    "\n",
    "        # Read all months for this year\n",
    "        for month, path in month_paths:\n",
    "            with rio.open(path) as ds_m:\n",
    "                if ds_m.height != H or ds_m.width != W:\n",
    "                    raise ValueError(\n",
    "                        f\"Shape mismatch for {path}: expected {(H, W)}, got {(ds_m.height, ds_m.width)}\"\n",
    "                    )\n",
    "\n",
    "                # predictors\n",
    "                for name, idx in zip(predictor_names, predictor_indices):\n",
    "                    arr = ds_m.read(idx).astype(np.float32)\n",
    "                    pred_months[name].append(arr)\n",
    "\n",
    "                # fraction\n",
    "                frac_arr = ds_m.read(frac_idx).astype(np.float32)\n",
    "                frac_months.append(frac_arr)\n",
    "\n",
    "        # Annual fraction = max over months\n",
    "        frac_stack = np.stack(frac_months, axis=0)          # (n_months, H, W)\n",
    "        annual_frac = np.nanmax(frac_stack, axis=0)         # (H, W)\n",
    "\n",
    "        # Annual predictors = mean over months per pixel\n",
    "        predictor_arrays = []\n",
    "        for name in predictor_names:\n",
    "            stack = np.stack(pred_months[name], axis=0)     # (n_months, H, W)\n",
    "            annual_pred = np.nanmean(stack, axis=0).astype(np.float32)\n",
    "            predictor_arrays.append(annual_pred)\n",
    "\n",
    "        predictors_stack = np.stack(predictor_arrays, axis=0)  # (n_predictors, H, W)\n",
    "\n",
    "        # lon/lat grid (EPSG:4326) computed from template CRS\n",
    "        lon, lat = compute_lonlat_grid(ds_template)\n",
    "\n",
    "        # Aggregate to coarse annual grids\n",
    "        # FIXED: Naming outputs with 'mcd'\n",
    "        base_name = f\"cems_e5l_mcd_{year}_annual\"\n",
    "        aggregate_to_coarse_grids_annual(\n",
    "            year=year,\n",
    "            ds=ds_template,\n",
    "            predictors_stack=predictors_stack,\n",
    "            predictor_names=predictor_names,\n",
    "            annual_frac=annual_frac,\n",
    "            lon=lon,\n",
    "            lat=lat,\n",
    "            grid_sizes_deg=GRID_SIZES_DEG,\n",
    "            burned_threshold=BURNED_THRESHOLD,\n",
    "            parquet_dir=PARQUET_DIR,\n",
    "            coarse_tif_dir=COARSE_TIF_DIR,\n",
    "            coarse_shp_dir=COARSE_SHP_DIR,\n",
    "            base_name=base_name,\n",
    "        )\n",
    "\n",
    "print(\"\\n[DONE] Analytical coarse grids (1 degree, 0.05 threshold) created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103373b-953a-46f8-81c4-f04f99ec1b4c",
   "metadata": {},
   "source": [
    "Now apply the stage 1 model to the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550579ea-8855-46b0-a44e-4879407fafc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODEL] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_firecci_with_fraction/stage_1_model_analytical/lgbm_stage1_model.joblib\n",
      "[THR]   0.100\n",
      "Looking for Parquets in: /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/parquet_coarse_grids_annual_mcd_analytical\n",
      "Looking for Shapefiles in: /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/shp_coarse_grids_annual_mcd_analytical\n",
      "[YEARS] [2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "\n",
      "=== 2001 ===\n",
      "[PARQ] cems_e5l_mcd_2001_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2001_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=137 FN=41 TN=3,482 FP=1,831 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=2.49% FN=0.75% TN=63.41% FP=33.35%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2001_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2002 ===\n",
      "[PARQ] cems_e5l_mcd_2002_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2002_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=309 FN=43 TN=3,433 FP=1,706 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.63% FN=0.78% TN=62.52% FP=31.07%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2002_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2003 ===\n",
      "[PARQ] cems_e5l_mcd_2003_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2003_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=429 FN=57 TN=3,180 FP=1,825 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=7.81% FN=1.04% TN=57.91% FP=33.24%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2003_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2004 ===\n",
      "[PARQ] cems_e5l_mcd_2004_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2004_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=337 FN=27 TN=3,843 FP=1,284 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=6.14% FN=0.49% TN=69.99% FP=23.38%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2004_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2005 ===\n",
      "[PARQ] cems_e5l_mcd_2005_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2005_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=298 FN=20 TN=3,188 FP=1,985 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.43% FN=0.36% TN=58.06% FP=36.15%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2005_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2006 ===\n",
      "[PARQ] cems_e5l_mcd_2006_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2006_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=303 FN=28 TN=3,427 FP=1,733 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.52% FN=0.51% TN=62.41% FP=31.56%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2006_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2007 ===\n",
      "[PARQ] cems_e5l_mcd_2007_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2007_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=183 FN=20 TN=3,499 FP=1,789 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=3.33% FN=0.36% TN=63.72% FP=32.58%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2007_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2008 ===\n",
      "[PARQ] cems_e5l_mcd_2008_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2008_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=310 FN=31 TN=3,574 FP=1,576 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.65% FN=0.56% TN=65.09% FP=28.70%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2008_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2009 ===\n",
      "[PARQ] cems_e5l_mcd_2009_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2009_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=258 FN=54 TN=3,321 FP=1,858 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.70% FN=0.98% TN=60.48% FP=33.84%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2009_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2010 ===\n",
      "[PARQ] cems_e5l_mcd_2010_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2010_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=325 FN=23 TN=3,329 FP=1,814 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.92% FN=0.42% TN=60.63% FP=33.04%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2010_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2011 ===\n",
      "[PARQ] cems_e5l_mcd_2011_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2011_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=272 FN=10 TN=3,238 FP=1,971 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.95% FN=0.18% TN=58.97% FP=35.90%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2011_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2012 ===\n",
      "[PARQ] cems_e5l_mcd_2012_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2012_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=424 FN=40 TN=3,161 FP=1,866 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=7.72% FN=0.73% TN=57.57% FP=33.98%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2012_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2013 ===\n",
      "[PARQ] cems_e5l_mcd_2013_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2013_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=322 FN=47 TN=3,090 FP=2,032 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.86% FN=0.86% TN=56.27% FP=37.01%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2013_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2014 ===\n",
      "[PARQ] cems_e5l_mcd_2014_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2014_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=287 FN=39 TN=3,365 FP=1,800 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.23% FN=0.71% TN=61.28% FP=32.78%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2014_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2015 ===\n",
      "[PARQ] cems_e5l_mcd_2015_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2015_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=320 FN=35 TN=3,495 FP=1,641 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.83% FN=0.64% TN=63.65% FP=29.89%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2015_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2016 ===\n",
      "[PARQ] cems_e5l_mcd_2016_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2016_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=262 FN=29 TN=3,106 FP=2,094 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.77% FN=0.53% TN=56.57% FP=38.14%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2016_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2017 ===\n",
      "[PARQ] cems_e5l_mcd_2017_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2017_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=259 FN=26 TN=3,545 FP=1,661 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.72% FN=0.47% TN=64.56% FP=30.25%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2017_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2018 ===\n",
      "[PARQ] cems_e5l_mcd_2018_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2018_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=237 FN=6 TN=3,179 FP=2,069 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.32% FN=0.11% TN=57.89% FP=37.68%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2018_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2019 ===\n",
      "[PARQ] cems_e5l_mcd_2019_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2019_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=332 FN=27 TN=3,230 FP=1,902 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=6.05% FN=0.49% TN=58.82% FP=34.64%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2019_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2020 ===\n",
      "[PARQ] cems_e5l_mcd_2020_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2020_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=222 FN=23 TN=3,094 FP=2,152 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=4.04% FN=0.42% TN=56.35% FP=39.19%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2020_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2021 ===\n",
      "[PARQ] cems_e5l_mcd_2021_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2021_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=349 FN=41 TN=3,188 FP=1,913 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=6.36% FN=0.75% TN=58.06% FP=34.84%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2021_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2022 ===\n",
      "[PARQ] cems_e5l_mcd_2022_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2022_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=282 FN=28 TN=3,160 FP=2,021 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=5.14% FN=0.51% TN=57.55% FP=36.81%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2022_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "=== 2023 ===\n",
      "[PARQ] cems_e5l_mcd_2023_annual_grid1deg.parquet\n",
      "[SHP ] cems_e5l_mcd_2023_annual_grid1deg_cells_epsg4326.shp\n",
      "[OBS] Using observed label column: 'burned_lab'\n",
      "[WARN] 5,827 polygons had no matching prediction by ID\n",
      "[COUNTS] TP=415 FN=41 TN=2,694 FP=2,341 NA=5,827 (valid=5,491)\n",
      "[PCT]    TP=7.56% FN=0.75% TN=49.06% FP=42.63%\n",
      "[SAVE] /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual/cems_e5l_mcd_2023_annual_grid1deg_pred_vs_obs_analytical.shp\n",
      "\n",
      "[SUMMARY] Saved CSV:  /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_obs_counts_and_pct_by_year_mcd_analytical.csv\n",
      "[PLOT]    Saved PNG:  /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_obs_percent_by_year_4panel_mcd_analytical.png\n",
      "\n",
      "[DONE] Wrote 23 annual MCD shapefiles to /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Predict Stage-1 burned/unburned on MCD annual 1° parquet (analytical).\n",
    "- Uses Model trained on FireCCI (MODEL_ROOT).\n",
    "- Joins to MCD annual 1° shapefiles by ID.\n",
    "- Saves MCD shapefiles with TP/FN/TN/FP labels.\n",
    "- Generates summary CSV and 4-panel plot for MCD years.\n",
    "\n",
    "ALL OUTPUTS are suffixed with '_analytical'.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# PATHS\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1. WHERE THE DATA IS (MCD)\n",
    "DATA_ROOT = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# 2. WHERE THE TRAINED MODEL IS (FireCCI)\n",
    "# We load the model trained on FireCCI to apply it to MCD\n",
    "MODEL_ROOT = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"training_e5l_cems_firecci_with_fraction\"\n",
    ")\n",
    "\n",
    "# INPUTS (MCD Analytical Data)\n",
    "# Note: These folders must exist from your previous aggregation script\n",
    "PARQUET_DIR = DATA_ROOT / \"parquet_coarse_grids_annual_mcd_analytical\"\n",
    "OBS_SHP_DIR = DATA_ROOT / \"shp_coarse_grids_annual_mcd_analytical\"\n",
    "\n",
    "# MODEL FILES (From FireCCI Stage 1)\n",
    "MODEL_DIR   = MODEL_ROOT / \"stage_1_model_analytical\"\n",
    "MODEL_PATH  = MODEL_DIR / \"lgbm_stage1_model.joblib\"\n",
    "THRESH_CSV  = MODEL_DIR / \"threshold_metrics.csv\"\n",
    "THRESH_TXT  = MODEL_DIR / \"final_metrics.txt\"\n",
    "\n",
    "DEFAULT_THRESHOLD = 0.5\n",
    "\n",
    "# OUTPUTS (Saved inside the MCD folder)\n",
    "OUT_DIR_BASE = DATA_ROOT / \"stage_1_predictions_on_mcd_analytical\"\n",
    "OUT_SHP_DIR  = OUT_DIR_BASE / \"pred_vs_obs_shapefiles_annual\"\n",
    "OUT_SHP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUMMARY_CSV = OUT_DIR_BASE / \"pred_obs_counts_and_pct_by_year_mcd_analytical.csv\"\n",
    "SUMMARY_PNG = OUT_DIR_BASE / \"pred_obs_percent_by_year_4panel_mcd_analytical.png\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------------\n",
    "FEATURES = [\n",
    "    \"DEM\",\n",
    "    \"slope\",\n",
    "    \"aspect\",\n",
    "    \"b1\",\n",
    "    \"relative_humidity\",\n",
    "    \"total_precipitation_sum\",\n",
    "    \"temperature_2m\",\n",
    "    \"temperature_2m_min\",\n",
    "    \"temperature_2m_max\",\n",
    "    \"build_up_index\",\n",
    "    \"drought_code\",\n",
    "    \"duff_moisture_code\",\n",
    "    \"fine_fuel_moisture_code\",\n",
    "    \"fire_weather_index\",\n",
    "    \"initial_fire_spread_index\",\n",
    "]\n",
    "\n",
    "OBS_LABEL_CANDIDATES = [\n",
    "    \"burned_label\",\n",
    "    \"burned_lab\",\n",
    "    \"burn_label\",\n",
    "    \"burned\",\n",
    "    \"label\",\n",
    "    \"obs_label\",\n",
    "    \"class\",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# HELPERS\n",
    "# ---------------------------------------------------------------------\n",
    "# UPDATED REGEX FOR MCD\n",
    "parq_re = re.compile(r\"cems_e5l_mcd_(\\d{4})_annual_grid1deg\\.parquet$\", re.IGNORECASE)\n",
    "shp_re  = re.compile(r\"cems_e5l_mcd_(\\d{4})_annual_grid1deg_cells_epsg4326\\.shp$\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def load_best_threshold() -> float:\n",
    "    if THRESH_TXT.exists():\n",
    "        try:\n",
    "            txt = THRESH_TXT.read_text().splitlines()\n",
    "            json_start = None\n",
    "            for i, line in enumerate(txt):\n",
    "                if line.strip().startswith(\"{\"):\n",
    "                    json_start = i\n",
    "                    break\n",
    "            if json_start is not None:\n",
    "                import json\n",
    "                d = json.loads(\"\\n\".join(txt[json_start:]))\n",
    "                return float(d.get(\"threshold\", DEFAULT_THRESHOLD))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if THRESH_CSV.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(THRESH_CSV)\n",
    "            df = df.sort_values([\"recall\", \"precision\", \"f1\"], ascending=False)\n",
    "            return float(df.iloc[0][\"threshold\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return float(DEFAULT_THRESHOLD)\n",
    "\n",
    "\n",
    "def ensure_b1_category(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    X[\"b1\"] = X[\"b1\"].astype(\"Int64\").astype(\"category\")\n",
    "    return X\n",
    "\n",
    "\n",
    "def find_year_parquets(parquet_dir: Path):\n",
    "    out = {}\n",
    "    if not parquet_dir.exists():\n",
    "        return out\n",
    "    for p in parquet_dir.glob(\"*_grid1deg.parquet\"):\n",
    "        m = parq_re.search(p.name)\n",
    "        if m:\n",
    "            out[int(m.group(1))] = p\n",
    "    return dict(sorted(out.items()))\n",
    "\n",
    "\n",
    "def find_year_shapefiles(shp_dir: Path):\n",
    "    out = {}\n",
    "    if not shp_dir.exists():\n",
    "        return out\n",
    "    for p in shp_dir.glob(\"*.shp\"):\n",
    "        m = shp_re.search(p.name)\n",
    "        if m:\n",
    "            out[int(m.group(1))] = p\n",
    "    return dict(sorted(out.items()))\n",
    "\n",
    "\n",
    "def pick_obs_label_column(gdf: gpd.GeoDataFrame) -> str:\n",
    "    cols = list(gdf.columns)\n",
    "    cols_lower = {c.lower(): c for c in cols}\n",
    "\n",
    "    for cand in OBS_LABEL_CANDIDATES:\n",
    "        if cand.lower() in cols_lower:\n",
    "            return cols_lower[cand.lower()]\n",
    "\n",
    "    for c in cols:\n",
    "        cl = c.lower()\n",
    "        if (\"burn\" in cl and \"lab\" in cl) or cl in (\"burn\", \"burned\"):\n",
    "            return c\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def label_tpfn_tnfp(obs: np.ndarray, pred: np.ndarray) -> np.ndarray:\n",
    "    obs = obs.astype(np.uint8)\n",
    "    pred = pred.astype(np.uint8)\n",
    "    out = np.empty(obs.shape[0], dtype=object)\n",
    "    out[(pred == 1) & (obs == 1)] = \"TP\"\n",
    "    out[(pred == 0) & (obs == 1)] = \"FN\"\n",
    "    out[(pred == 0) & (obs == 0)] = \"TN\"\n",
    "    out[(pred == 1) & (obs == 0)] = \"FP\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_percent_4panel(df_counts: pd.DataFrame, out_png: Path):\n",
    "    \"\"\"\n",
    "    df_counts columns:\n",
    "      year, TP_pct, FN_pct, TN_pct, FP_pct\n",
    "\n",
    "    Floating y-axis: each panel auto-scales independently.\n",
    "    \"\"\"\n",
    "    dfp = df_counts.sort_values(\"year\").copy()\n",
    "    years = dfp[\"year\"].to_numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    panels = [\n",
    "        (\"TP_pct\", \"TP (%)\"),\n",
    "        (\"FN_pct\", \"FN (%)\"),\n",
    "        (\"TN_pct\", \"TN (%)\"),\n",
    "        (\"FP_pct\", \"FP (%)\"),\n",
    "    ]\n",
    "\n",
    "    for ax, (col, title) in zip(axes, panels):\n",
    "        ax.plot(years, dfp[col].to_numpy(), marker=\"o\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Year\")\n",
    "        ax.set_ylabel(\"Percent\")\n",
    "        ax.autoscale(enable=True, axis=\"y\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MAIN\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    if not MODEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
    "\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    thr = load_best_threshold()\n",
    "\n",
    "    print(f\"[MODEL] {MODEL_PATH}\")\n",
    "    print(f\"[THR]   {thr:.3f}\")\n",
    "\n",
    "    year_to_parq = find_year_parquets(PARQUET_DIR)\n",
    "    year_to_shp  = find_year_shapefiles(OBS_SHP_DIR)\n",
    "\n",
    "    years = sorted(set(year_to_parq) & set(year_to_shp))\n",
    "    \n",
    "    print(f\"Looking for Parquets in: {PARQUET_DIR}\")\n",
    "    print(f\"Looking for Shapefiles in: {OBS_SHP_DIR}\")\n",
    "    \n",
    "    if not years:\n",
    "        raise RuntimeError(\n",
    "            \"No overlapping years between parquet and shapefiles.\\n\"\n",
    "            f\"Parquet years found: {list(year_to_parq.keys())}\\n\"\n",
    "            f\"SHP years found: {list(year_to_shp.keys())}\"\n",
    "        )\n",
    "\n",
    "    print(f\"[YEARS] {years}\")\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for year in years:\n",
    "        parq_path = year_to_parq[year]\n",
    "        shp_path  = year_to_shp[year]\n",
    "\n",
    "        print(f\"\\n=== {year} ===\")\n",
    "        print(f\"[PARQ] {parq_path.name}\")\n",
    "        print(f\"[SHP ] {shp_path.name}\")\n",
    "\n",
    "        # --- predict on parquet ---\n",
    "        dfp = pd.read_parquet(parq_path, columns=[\"ID\"] + FEATURES).copy()\n",
    "        dfp = dfp.dropna(subset=FEATURES).copy()\n",
    "\n",
    "        X = ensure_b1_category(dfp[FEATURES])\n",
    "        prob = model.predict_proba(X)[:, 1].astype(np.float32)\n",
    "        pred = (prob >= thr).astype(np.uint8)\n",
    "\n",
    "        pred_df = pd.DataFrame(\n",
    "            {\n",
    "                \"ID\": dfp[\"ID\"].astype(np.int64).to_numpy(),\n",
    "                \"pred_prob\": prob,\n",
    "                \"pred_label\": pred,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # --- read observed shapefile ---\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "\n",
    "        if \"ID\" not in gdf.columns:\n",
    "            raise RuntimeError(f\"[{year}] Shapefile missing 'ID' column: {shp_path}\")\n",
    "\n",
    "        obs_col = pick_obs_label_column(gdf)\n",
    "        if not obs_col:\n",
    "            raise RuntimeError(\n",
    "                f\"[{year}] Could not find an observed label column in {shp_path}\\n\"\n",
    "                f\"Available columns: {list(gdf.columns)}\\n\"\n",
    "                f\"Tried candidates: {OBS_LABEL_CANDIDATES}\"\n",
    "            )\n",
    "        print(f\"[OBS] Using observed label column: '{obs_col}'\")\n",
    "\n",
    "        gdf[\"ID\"] = gdf[\"ID\"].astype(np.int64)\n",
    "\n",
    "        obs_vals = pd.to_numeric(gdf[obs_col], errors=\"coerce\")\n",
    "        gdf[\"obs_label\"] = obs_vals  # float with NaNs\n",
    "        valid_obs = gdf[\"obs_label\"].isin([0, 1])\n",
    "\n",
    "        # --- join ---\n",
    "        gdf = gdf.merge(pred_df, on=\"ID\", how=\"left\", validate=\"one_to_one\")\n",
    "\n",
    "        missing_pred = int(gdf[\"pred_label\"].isna().sum())\n",
    "        if missing_pred:\n",
    "            print(f\"[WARN] {missing_pred:,} polygons had no matching prediction by ID\")\n",
    "\n",
    "        # --- label TP/FN/TN/FP/NA ---\n",
    "        gdf[\"pred_obs\"] = \"NA\"\n",
    "        valid = valid_obs & (~gdf[\"pred_label\"].isna())\n",
    "\n",
    "        if valid.any():\n",
    "            gdf.loc[valid, \"pred_label\"] = gdf.loc[valid, \"pred_label\"].astype(np.uint8)\n",
    "            gdf.loc[valid, \"pred_obs\"] = label_tpfn_tnfp(\n",
    "                gdf.loc[valid, \"obs_label\"].astype(np.uint8).to_numpy(),\n",
    "                gdf.loc[valid, \"pred_label\"].to_numpy(),\n",
    "            )\n",
    "\n",
    "        # --- counts + percents (percents exclude NA) ---\n",
    "        vc = gdf[\"pred_obs\"].value_counts().to_dict()\n",
    "        tp = int(vc.get(\"TP\", 0))\n",
    "        fn = int(vc.get(\"FN\", 0))\n",
    "        tn = int(vc.get(\"TN\", 0))\n",
    "        fp = int(vc.get(\"FP\", 0))\n",
    "        na = int(vc.get(\"NA\", 0))\n",
    "        denom = tp + fn + tn + fp  # VALID comparisons only\n",
    "\n",
    "        def pct(x):\n",
    "            return float(100.0 * x / denom) if denom > 0 else 0.0\n",
    "\n",
    "        row = {\n",
    "            \"year\": int(year),\n",
    "            \"TP\": tp,\n",
    "            \"FN\": fn,\n",
    "            \"TN\": tn,\n",
    "            \"FP\": fp,\n",
    "            \"NA\": na,\n",
    "            \"n_total\": int(len(gdf)),\n",
    "            \"n_valid\": int(denom),\n",
    "            \"TP_pct\": pct(tp),\n",
    "            \"FN_pct\": pct(fn),\n",
    "            \"TN_pct\": pct(tn),\n",
    "            \"FP_pct\": pct(fp),\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "        print(f\"[COUNTS] TP={tp:,} FN={fn:,} TN={tn:,} FP={fp:,} NA={na:,} (valid={denom:,})\")\n",
    "        print(f\"[PCT]    TP={row['TP_pct']:.2f}% FN={row['FN_pct']:.2f}% TN={row['TN_pct']:.2f}% FP={row['FP_pct']:.2f}%\")\n",
    "\n",
    "        # ensure year column\n",
    "        if \"year\" not in gdf.columns:\n",
    "            gdf[\"year\"] = int(year)\n",
    "\n",
    "        # --- write shapefile (Analytical) ---\n",
    "        out_name = f\"cems_e5l_mcd_{year}_annual_grid1deg_pred_vs_obs_analytical.shp\"\n",
    "        out_path = OUT_SHP_DIR / out_name\n",
    "        gdf.to_file(out_path)\n",
    "        print(f\"[SAVE] {out_path}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # Save summary dataframe + plot percents (Analytical)\n",
    "    # -----------------------------------------------------------------\n",
    "    if summary_rows:\n",
    "        df_sum = pd.DataFrame(summary_rows).sort_values(\"year\").reset_index(drop=True)\n",
    "        df_sum.to_csv(SUMMARY_CSV, index=False)\n",
    "        print(f\"\\n[SUMMARY] Saved CSV:  {SUMMARY_CSV}\")\n",
    "\n",
    "        plot_percent_4panel(df_sum[[\"year\", \"TP_pct\", \"FN_pct\", \"TN_pct\", \"FP_pct\"]], SUMMARY_PNG)\n",
    "        print(f\"[PLOT]    Saved PNG:  {SUMMARY_PNG}\")\n",
    "\n",
    "        print(f\"\\n[DONE] Wrote {len(years)} annual MCD shapefiles to {OUT_SHP_DIR}\")\n",
    "    else:\n",
    "        print(\"\\n[WARN] No years processed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5487991-5985-4d0f-bf06-165479f747e8",
   "metadata": {},
   "source": [
    "Now take the cells we predicted as burnable and extract 4km predictor data per year and month and save to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f66ab6-6172-45ef-b8fa-0b767b671180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for analytical shapefiles in: /explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):   0%|          | 0/275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2001] burned_lab mask keeps 253,221 / 4,273,642 pixels (5.93%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):   4%|▍         | 12/275 [00:35<09:05,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2002] burned_lab mask keeps 397,886 / 4,273,642 pixels (9.31%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):   9%|▊         | 24/275 [01:23<15:49,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2003] burned_lab mask keeps 460,364 / 4,273,642 pixels (10.77%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  13%|█▎        | 36/275 [01:47<07:52,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2004] burned_lab mask keeps 374,898 / 4,273,642 pixels (8.77%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  17%|█▋        | 48/275 [02:29<14:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2005] burned_lab mask keeps 358,563 / 4,273,642 pixels (8.39%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  22%|██▏       | 60/275 [02:57<06:32,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2006] burned_lab mask keeps 404,603 / 4,273,642 pixels (9.47%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  26%|██▌       | 72/275 [03:32<12:07,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2007] burned_lab mask keeps 339,347 / 4,273,642 pixels (7.94%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  31%|███       | 84/275 [04:06<06:21,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2008] burned_lab mask keeps 401,621 / 4,273,642 pixels (9.40%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  35%|███▍      | 96/275 [04:42<10:44,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2009] burned_lab mask keeps 352,779 / 4,273,642 pixels (8.25%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  39%|███▉      | 108/275 [05:17<05:34,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2010] burned_lab mask keeps 379,490 / 4,273,642 pixels (8.88%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  44%|████▎     | 120/275 [05:49<08:50,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2011] burned_lab mask keeps 283,831 / 4,273,642 pixels (6.64%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  48%|████▊     | 132/275 [06:27<05:15,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2012] burned_lab mask keeps 394,427 / 4,273,642 pixels (9.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  52%|█████▏    | 144/275 [07:05<08:04,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2013] burned_lab mask keeps 242,740 / 4,273,642 pixels (5.68%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  57%|█████▋    | 156/275 [07:37<03:46,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2014] burned_lab mask keeps 374,668 / 4,273,642 pixels (8.77%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  61%|██████    | 168/275 [08:09<05:59,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2015] burned_lab mask keeps 359,512 / 4,273,642 pixels (8.41%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  65%|██████▌   | 180/275 [08:47<03:32,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2016] burned_lab mask keeps 268,992 / 4,273,642 pixels (6.29%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  70%|██████▉   | 192/275 [09:18<04:28,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2017] burned_lab mask keeps 341,895 / 4,273,642 pixels (8.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  74%|███████▍  | 204/275 [10:01<03:10,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2018] burned_lab mask keeps 316,095 / 4,273,642 pixels (7.40%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  79%|███████▊  | 216/275 [10:33<03:24,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2019] burned_lab mask keeps 325,901 / 4,273,642 pixels (7.63%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  83%|████████▎ | 228/275 [11:13<01:50,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2020] burned_lab mask keeps 284,904 / 4,273,642 pixels (6.67%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  87%|████████▋ | 240/275 [11:43<01:55,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2021] burned_lab mask keeps 330,361 / 4,273,642 pixels (7.73%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  92%|█████████▏| 252/275 [12:23<00:52,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2022] burned_lab mask keeps 259,732 / 4,273,642 pixels (6.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask):  96%|█████████▌| 264/275 [12:57<00:39,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[YEAR 2023] burned_lab mask keeps 327,195 / 4,273,642 pixels (7.66%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partitioned Parquet dataset (burned_lab mask): 100%|██████████| 275/275 [13:32<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done. Parquet dataset at:\n",
      "/explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_mcd_with_fraction_dataset_burnedlab_mask_analytical\n",
      "(partitioned by year=/month=)\n",
      "\n",
      "=== Burned/Unburned pixel counts (filtered to burned_lab==1 1° cells) ===\n",
      "Valid labeled pixels (fraction != NaN and != 0.5): 29,114,950\n",
      "Burned pixels    (fraction > 0.5): 62,312\n",
      "Unburned pixels (fraction < 0.5): 29,052,638\n",
      "Unburned:Burned ratio = 466.245 : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.warp import transform as rio_transform\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "# 1. INPUT DATA (MCD)\n",
    "IN_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\")\n",
    "\n",
    "# 2. INPUT SHAPEFILES (MCD Analytical Predictions from previous step)\n",
    "# These are used to create the spatial mask (only keeping cells predicted as 'burned')\n",
    "PRED_SHP_DIR = IN_DIR / \"stage_1_predictions_on_mcd_analytical\" / \"pred_vs_obs_shapefiles_annual\"\n",
    "\n",
    "# 3. OUTPUT DATASET (MCD Parquet)\n",
    "OUT_DATASET_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_mcd_with_fraction_dataset_burnedlab_mask_analytical\")\n",
    "OUT_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REPROJECT_TO_EPSG4326 = True\n",
    "\n",
    "# Years to process\n",
    "YEAR_MIN = 2001\n",
    "YEAR_MAX = 2023\n",
    "\n",
    "# Mask shapefile criterion: keep only burned-lab cells\n",
    "BURNED_LAB_VALUE = 1\n",
    "BURNED_LAB_FIELD_OVERRIDE = None  # set if you know exact field name\n",
    "\n",
    "# Fraction band description/name candidates (searched in ds.descriptions)\n",
    "FRACTION_BAND_DESC_CANDIDATES = [\"fraction\", \"frac\", \"burn_fraction\"]\n",
    "\n",
    "# Pixel label from fraction\n",
    "PIXEL_BURN_THRESHOLD = 0.5  # burned if fraction > 0.5, unburned if fraction < 0.5\n",
    "\n",
    "# ================== HELPERS ==================\n",
    "def sanitize_names(names):\n",
    "    \"\"\"Make unique, safe column names (avoid duplicates).\"\"\"\n",
    "    seen = {}\n",
    "    out = []\n",
    "    for n in names:\n",
    "        if n is None or str(n).strip() == \"\":\n",
    "            n = \"band\"\n",
    "        n0 = re.sub(r\"[^a-zA-Z0-9_]\", \"_\", str(n).strip())\n",
    "        n0 = re.sub(r\"_+\", \"_\", n0).strip(\"_\")\n",
    "        if n0 == \"\":\n",
    "            n0 = \"band\"\n",
    "        if n0 in seen:\n",
    "            seen[n0] += 1\n",
    "            n0 = f\"{n0}_{seen[n0]}\"\n",
    "        else:\n",
    "            seen[n0] = 1\n",
    "        out.append(n0)\n",
    "    return out\n",
    "\n",
    "# UPDATED REGEX FOR MCD TIFFS\n",
    "name_re = re.compile(r\"cems_e5l_mcd_(\\d{4})_(\\d{1,2})_with_fraction\\.tif$\", re.IGNORECASE)\n",
    "\n",
    "# UPDATED REGEX FOR MCD SHAPEFILES\n",
    "# Matches files like: cems_e5l_mcd_2001_annual_grid1deg_pred_vs_obs_analytical.shp\n",
    "shp_re = re.compile(r\"cems_e5l_mcd_(\\d{4})_annual_grid1deg_pred_vs_obs_analytical\\.shp$\", re.IGNORECASE)\n",
    "\n",
    "def parse_year_month(fname: str):\n",
    "    m = name_re.search(fname)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "def append_chunk_to_dataset(df: pd.DataFrame, root: Path):\n",
    "    if not df.columns.is_unique:\n",
    "        dups = df.columns[df.columns.duplicated()].tolist()\n",
    "        raise ValueError(f\"Duplicate column names found: {dups}\")\n",
    "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "    pq.write_to_dataset(\n",
    "        table,\n",
    "        root_path=str(root),\n",
    "        partition_cols=[\"year\", \"month\"],\n",
    "        use_dictionary=False\n",
    "    )\n",
    "\n",
    "def find_fraction_band_index(ds: rio.DatasetReader) -> int:\n",
    "    \"\"\"\n",
    "    Return 0-based band index for fraction band by inspecting ds.descriptions.\n",
    "    \"\"\"\n",
    "    descs = list(ds.descriptions) if ds.descriptions else [None] * ds.count\n",
    "    descs_safe = sanitize_names([d if d else f\"B{i}\" for i, d in enumerate(descs, start=1)])\n",
    "    descs_safe_lower = [d.lower() for d in descs_safe]\n",
    "\n",
    "    for cand in FRACTION_BAND_DESC_CANDIDATES:\n",
    "        cand = cand.lower()\n",
    "        for i, d in enumerate(descs_safe_lower):\n",
    "            if cand == d or cand in d:\n",
    "                return i\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Could not find fraction band by description. \"\n",
    "        f\"Band descriptions (sanitized): {descs_safe}\"\n",
    "    )\n",
    "\n",
    "def build_lonlat(ds: rio.DatasetReader, xs, ys):\n",
    "    if (\n",
    "        REPROJECT_TO_EPSG4326\n",
    "        and ds.crs is not None\n",
    "        and ds.crs.to_string().upper() not in (\"EPSG:4326\", \"OGC:CRS84\")\n",
    "    ):\n",
    "        lons, lats = rio_transform(ds.crs, \"EPSG:4326\", xs, ys)\n",
    "        return np.asarray(lons, dtype=np.float64), np.asarray(lats, dtype=np.float64)\n",
    "    return xs.astype(np.float64), ys.astype(np.float64)\n",
    "\n",
    "def find_burned_lab_field(gdf: gpd.GeoDataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Find the 'burned_lab' field even if DBF truncates it.\n",
    "    \"\"\"\n",
    "    if BURNED_LAB_FIELD_OVERRIDE:\n",
    "        if BURNED_LAB_FIELD_OVERRIDE not in gdf.columns:\n",
    "            raise RuntimeError(f\"Override burned-lab field '{BURNED_LAB_FIELD_OVERRIDE}' not in: {list(gdf.columns)}\")\n",
    "        return BURNED_LAB_FIELD_OVERRIDE\n",
    "\n",
    "    cols_lower = {c.lower(): c for c in gdf.columns}\n",
    "\n",
    "    # common names\n",
    "    candidates = [\"burned_lab\", \"burned_label\", \"burnedlab\", \"burn_lab\", \"burnlab\", \"burned\"]\n",
    "    for c in candidates:\n",
    "        if c in cols_lower:\n",
    "            return cols_lower[c]\n",
    "\n",
    "    # fuzzy fallback\n",
    "    for c in gdf.columns:\n",
    "        cl = c.lower()\n",
    "        if \"burn\" in cl and (\"lab\" in cl or \"label\" in cl):\n",
    "            return c\n",
    "\n",
    "    raise RuntimeError(f\"Could not find burned_lab field. Columns: {list(gdf.columns)}\")\n",
    "\n",
    "def raster_mask_from_burnedlab(ds: rio.DatasetReader, shp_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rasterize polygons where burned_lab==1 onto ds grid -> boolean mask (H,W).\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    lab_col = find_burned_lab_field(gdf)\n",
    "\n",
    "    lab_vals = pd.to_numeric(gdf[lab_col], errors=\"coerce\")\n",
    "    gdf_keep = gdf.loc[lab_vals == BURNED_LAB_VALUE].copy()\n",
    "\n",
    "    if gdf_keep.empty:\n",
    "        return np.zeros((ds.height, ds.width), dtype=bool)\n",
    "\n",
    "    if ds.crs is None:\n",
    "        raise RuntimeError(f\"Raster has no CRS; cannot rasterize: {shp_path}\")\n",
    "    if gdf_keep.crs is None:\n",
    "        raise RuntimeError(f\"Shapefile has no CRS; cannot rasterize: {shp_path}\")\n",
    "\n",
    "    if gdf_keep.crs != ds.crs:\n",
    "        gdf_keep = gdf_keep.to_crs(ds.crs)\n",
    "\n",
    "    shapes = [(geom, 1) for geom in gdf_keep.geometry if geom is not None and not geom.is_empty]\n",
    "    if not shapes:\n",
    "        return np.zeros((ds.height, ds.width), dtype=bool)\n",
    "\n",
    "    mask_u8 = rasterize(\n",
    "        shapes=shapes,\n",
    "        out_shape=(ds.height, ds.width),\n",
    "        transform=ds.transform,\n",
    "        fill=0,\n",
    "        dtype=\"uint8\",\n",
    "        all_touched=False,\n",
    "    )\n",
    "    return mask_u8.astype(bool)\n",
    "\n",
    "# ================== MAIN ==================\n",
    "def main():\n",
    "    # UPDATED GLOB FOR MCD\n",
    "    tifs = sorted(IN_DIR.glob(\"cems_e5l_mcd_*_with_fraction.tif\"))\n",
    "    if not tifs:\n",
    "        raise FileNotFoundError(f\"No monthly _with_fraction.tif found in {IN_DIR}\")\n",
    "\n",
    "    # Filter to years 2001-2019 only\n",
    "    todo = []\n",
    "    for tif in tifs:\n",
    "        y, m = parse_year_month(tif.name)\n",
    "        if y is None:\n",
    "            continue\n",
    "        if y < YEAR_MIN or y > YEAR_MAX:\n",
    "            continue\n",
    "        todo.append((y, m, tif))\n",
    "    todo.sort()\n",
    "\n",
    "    if not todo:\n",
    "        raise RuntimeError(f\"No TIFFs found in year range {YEAR_MIN}-{YEAR_MAX}\")\n",
    "\n",
    "    # Cache the rasterized burned-lab mask per year\n",
    "    year_mask_cache = {}\n",
    "\n",
    "    canonical_cols = None\n",
    "\n",
    "    # Global ratio counters (only where burned_pixel is defined)\n",
    "    burned_total = 0\n",
    "    unburned_total = 0\n",
    "    valid_lab_total = 0\n",
    "\n",
    "    print(f\"Scanning for analytical shapefiles in: {PRED_SHP_DIR}\")\n",
    "\n",
    "    for year, month, tif in tqdm(todo, desc=\"Building partitioned Parquet dataset (burned_lab mask)\"):\n",
    "        # UPDATED: Filename format for MCD analytical shapefiles\n",
    "        shp_name = f\"cems_e5l_mcd_{year}_annual_grid1deg_pred_vs_obs_analytical.shp\"\n",
    "        shp_path = PRED_SHP_DIR / shp_name\n",
    "        \n",
    "        if not shp_path.exists():\n",
    "            print(f\"\\n[SKIP] {tif.name} (missing annual analytical shapefile: {shp_path})\")\n",
    "            continue\n",
    "\n",
    "        with rio.open(tif) as ds:\n",
    "            # band names\n",
    "            band_names = list(ds.descriptions) if ds.descriptions else []\n",
    "            if not any(band_names):\n",
    "                band_names = [f\"B{i}\" for i in range(1, ds.count + 1)]\n",
    "            safe_names = sanitize_names(band_names)\n",
    "\n",
    "            # fraction band index (0-based)\n",
    "            frac_band0 = find_fraction_band_index(ds)\n",
    "            frac_col_name = \"fraction\"\n",
    "\n",
    "            # burned-lab mask per year (rasterized once)\n",
    "            if year not in year_mask_cache:\n",
    "                mask = raster_mask_from_burnedlab(ds, shp_path)\n",
    "                year_mask_cache[year] = mask\n",
    "                print(f\"\\n[YEAR {year}] burned_lab mask keeps {mask.sum():,} / {mask.size:,} pixels ({100*mask.mean():.2f}%)\")\n",
    "            else:\n",
    "                mask = year_mask_cache[year]\n",
    "                if mask.shape != (ds.height, ds.width):\n",
    "                    raise RuntimeError(f\"Mask shape mismatch for {year}: mask {mask.shape} vs raster {(ds.height, ds.width)}\")\n",
    "\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            # Read raster (bands, H, W)\n",
    "            data = ds.read().astype(np.float32)\n",
    "            bands, h, w = data.shape\n",
    "\n",
    "            # Flatten to (pixels, bands)\n",
    "            arr2d = data.reshape(bands, -1).T\n",
    "\n",
    "            # Keep only pixels with build_up_index not NaN (domain mask)\n",
    "            build_col = None\n",
    "            for s in safe_names:\n",
    "                if \"build\" in s.lower() and \"index\" in s.lower():\n",
    "                    build_col = s\n",
    "                    break\n",
    "            if build_col is None:\n",
    "                raise ValueError(f\"Could not find build_up_index band in: {tif.name}\")\n",
    "\n",
    "            build_idx = safe_names.index(build_col)\n",
    "            build_vals = arr2d[:, build_idx]\n",
    "\n",
    "            keep_mask = mask.reshape(-1) & (~np.isnan(build_vals))\n",
    "            if not keep_mask.any():\n",
    "                continue\n",
    "\n",
    "            # Subset pixels\n",
    "            arr_keep = arr2d[keep_mask, :]\n",
    "            df = pd.DataFrame(arr_keep, columns=safe_names)\n",
    "\n",
    "            # Ensure fraction column exists exactly once\n",
    "            frac_vals_from_band = df.iloc[:, frac_band0].astype(np.float32).to_numpy()\n",
    "            df[frac_col_name] = frac_vals_from_band  # overwrite if already present\n",
    "\n",
    "            # burned_pixel binary from fraction\n",
    "            frac_vals = df[frac_col_name].to_numpy(dtype=np.float32, copy=False)\n",
    "            burned_pixel = np.full(frac_vals.shape, np.nan, dtype=np.float32)\n",
    "            valid_frac = ~np.isnan(frac_vals)\n",
    "            burned_pixel[valid_frac & (frac_vals > PIXEL_BURN_THRESHOLD)] = 1.0\n",
    "            burned_pixel[valid_frac & (frac_vals < PIXEL_BURN_THRESHOLD)] = 0.0\n",
    "            df[\"burned_pixel\"] = burned_pixel\n",
    "\n",
    "            # Update global counters\n",
    "            valid_lab = ~np.isnan(burned_pixel)\n",
    "            if valid_lab.any():\n",
    "                burned_total += int(np.sum(burned_pixel[valid_lab] == 1.0))\n",
    "                unburned_total += int(np.sum(burned_pixel[valid_lab] == 0.0))\n",
    "                valid_lab_total += int(valid_lab.sum())\n",
    "\n",
    "            # Coordinates for kept pixels\n",
    "            rows = np.arange(h)\n",
    "            cols = np.arange(w)\n",
    "            rr, cc = np.meshgrid(rows, cols, indexing=\"ij\")\n",
    "            xs, ys = rio.transform.xy(ds.transform, rr, cc, offset=\"center\")\n",
    "            xs = np.asarray(xs, dtype=np.float64).reshape(-1)[keep_mask]\n",
    "            ys = np.asarray(ys, dtype=np.float64).reshape(-1)[keep_mask]\n",
    "            lons, lats = build_lonlat(ds, xs, ys)\n",
    "\n",
    "            df[\"longitude\"] = lons\n",
    "            df[\"latitude\"] = lats\n",
    "            df[\"year\"] = year\n",
    "            df[\"month\"] = month\n",
    "\n",
    "            # Canonical schema\n",
    "            if canonical_cols is None:\n",
    "                canonical_cols = list(safe_names)\n",
    "                if frac_col_name not in canonical_cols:\n",
    "                    canonical_cols.append(frac_col_name)\n",
    "                for extra in [\"burned_pixel\", \"longitude\", \"latitude\", \"year\", \"month\"]:\n",
    "                    if extra not in canonical_cols:\n",
    "                        canonical_cols.append(extra)\n",
    "                if len(canonical_cols) != len(set(canonical_cols)):\n",
    "                    raise RuntimeError(f\"Canonical cols not unique: {canonical_cols}\")\n",
    "\n",
    "            for col in canonical_cols:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = np.nan\n",
    "\n",
    "            df = df[canonical_cols]\n",
    "            append_chunk_to_dataset(df, OUT_DATASET_DIR)\n",
    "\n",
    "    print(f\"\\n✅ Done. Parquet dataset at:\\n{OUT_DATASET_DIR}\\n(partitioned by year=/month=)\")\n",
    "\n",
    "    # Global ratios\n",
    "    print(\"\\n=== Burned/Unburned pixel counts (filtered to burned_lab==1 1° cells) ===\")\n",
    "    print(f\"Valid labeled pixels (fraction != NaN and != {PIXEL_BURN_THRESHOLD}): {valid_lab_total:,}\")\n",
    "    print(f\"Burned pixels    (fraction > {PIXEL_BURN_THRESHOLD}): {burned_total:,}\")\n",
    "    print(f\"Unburned pixels (fraction < {PIXEL_BURN_THRESHOLD}): {unburned_total:,}\")\n",
    "\n",
    "    if burned_total > 0:\n",
    "        ratio = unburned_total / burned_total\n",
    "        print(f\"Unburned:Burned ratio = {ratio:.3f} : 1\")\n",
    "    else:\n",
    "        print(\"Unburned:Burned ratio = inf (no burned pixels found)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aace8fd-e73d-4bba-acf7-113187f14326",
   "metadata": {},
   "source": [
    "Now apply stage 2 model to these files we just saved, and only in TP/FP stage 1 model cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b185773e-c4e8-48df-8920-6ae3b1a70de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\n",
      "Found 23 years to process: [2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "Years marked for overwrite: [2020, 2021, 2022, 2023]\n",
      "\n",
      "--- Starting Year: 2001 ---\n",
      "Processing 1968 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2001_01.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_02.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_03.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_04.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_05.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_06.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_07.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_08.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_09.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_10.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_11.tif (Predicted 766,801 pixels)\n",
      "Saved: pred_tp_fp_mcd_2001_12.tif (Predicted 766,801 pixels)\n",
      "\n",
      "--- Starting Year: 2002 ---\n",
      "Processing 2015 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2002_01.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_02.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_03.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_04.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_05.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_06.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_07.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_08.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_09.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_10.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_11.tif (Predicted 789,721 pixels)\n",
      "Saved: pred_tp_fp_mcd_2002_12.tif (Predicted 789,721 pixels)\n",
      "\n",
      "--- Starting Year: 2003 ---\n",
      "Processing 2254 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2003_01.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_02.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_03.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_04.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_05.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_06.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_07.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_08.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_09.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_10.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_11.tif (Predicted 886,129 pixels)\n",
      "Saved: pred_tp_fp_mcd_2003_12.tif (Predicted 886,129 pixels)\n",
      "\n",
      "--- Starting Year: 2004 ---\n",
      "Processing 1621 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2004_01.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_02.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_03.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_04.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_05.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_06.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_07.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_08.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_09.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_10.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_11.tif (Predicted 632,001 pixels)\n",
      "Saved: pred_tp_fp_mcd_2004_12.tif (Predicted 632,001 pixels)\n",
      "\n",
      "--- Starting Year: 2005 ---\n",
      "Processing 2283 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2005_01.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_02.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_03.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_04.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_05.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_06.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_07.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_08.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_09.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_10.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_11.tif (Predicted 888,682 pixels)\n",
      "Saved: pred_tp_fp_mcd_2005_12.tif (Predicted 888,682 pixels)\n",
      "\n",
      "--- Starting Year: 2006 ---\n",
      "Processing 2036 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2006_01.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_02.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_03.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_04.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_05.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_06.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_07.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_08.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_09.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_10.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_11.tif (Predicted 806,056 pixels)\n",
      "Saved: pred_tp_fp_mcd_2006_12.tif (Predicted 806,056 pixels)\n",
      "\n",
      "--- Starting Year: 2007 ---\n",
      "Processing 1972 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2007_01.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_02.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_03.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_04.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_05.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_06.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_07.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_08.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_09.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_10.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_11.tif (Predicted 764,197 pixels)\n",
      "Saved: pred_tp_fp_mcd_2007_12.tif (Predicted 764,197 pixels)\n",
      "\n",
      "--- Starting Year: 2008 ---\n",
      "Processing 1886 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2008_01.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_02.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_03.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_04.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_05.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_06.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_07.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_08.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_09.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_10.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_11.tif (Predicted 739,948 pixels)\n",
      "Saved: pred_tp_fp_mcd_2008_12.tif (Predicted 739,948 pixels)\n",
      "\n",
      "--- Starting Year: 2009 ---\n",
      "Processing 2116 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2009_01.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_02.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_03.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_04.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_05.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_06.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_07.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_08.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_09.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_10.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_11.tif (Predicted 811,797 pixels)\n",
      "Saved: pred_tp_fp_mcd_2009_12.tif (Predicted 811,797 pixels)\n",
      "\n",
      "--- Starting Year: 2010 ---\n",
      "Processing 2139 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2010_01.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_02.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_03.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_04.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_05.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_06.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_07.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_08.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_09.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_10.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_11.tif (Predicted 830,281 pixels)\n",
      "Saved: pred_tp_fp_mcd_2010_12.tif (Predicted 830,281 pixels)\n",
      "\n",
      "--- Starting Year: 2011 ---\n",
      "Processing 2243 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2011_01.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_02.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_03.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_04.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_05.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_06.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_07.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_08.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_09.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_10.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_11.tif (Predicted 867,098 pixels)\n",
      "Saved: pred_tp_fp_mcd_2011_12.tif (Predicted 867,098 pixels)\n",
      "\n",
      "--- Starting Year: 2012 ---\n",
      "Processing 2290 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2012_01.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_02.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_03.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_04.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_05.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_06.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_07.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_08.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_09.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_10.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_11.tif (Predicted 883,839 pixels)\n",
      "Saved: pred_tp_fp_mcd_2012_12.tif (Predicted 883,839 pixels)\n",
      "\n",
      "--- Starting Year: 2013 ---\n",
      "Processing 2354 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2013_01.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_02.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_03.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_04.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_05.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_06.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_07.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_08.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_09.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_10.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_11.tif (Predicted 892,491 pixels)\n",
      "Saved: pred_tp_fp_mcd_2013_12.tif (Predicted 892,491 pixels)\n",
      "\n",
      "--- Starting Year: 2014 ---\n",
      "Processing 2087 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2014_01.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_02.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_03.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_06.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_07.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_08.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_09.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_10.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_11.tif (Predicted 825,965 pixels)\n",
      "Saved: pred_tp_fp_mcd_2014_12.tif (Predicted 825,965 pixels)\n",
      "\n",
      "--- Starting Year: 2015 ---\n",
      "Processing 1961 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2015_01.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_02.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_03.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_04.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_05.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_06.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_07.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_08.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_09.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_10.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_11.tif (Predicted 768,223 pixels)\n",
      "Saved: pred_tp_fp_mcd_2015_12.tif (Predicted 768,223 pixels)\n",
      "\n",
      "--- Starting Year: 2016 ---\n",
      "Processing 2356 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2016_01.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_02.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_03.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_04.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_05.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_06.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_07.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_08.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_09.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_10.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_11.tif (Predicted 892,649 pixels)\n",
      "Saved: pred_tp_fp_mcd_2016_12.tif (Predicted 892,649 pixels)\n",
      "\n",
      "--- Starting Year: 2017 ---\n",
      "Processing 1920 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2017_01.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_02.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_03.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_04.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_05.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_06.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_07.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_08.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_09.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_10.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_11.tif (Predicted 753,535 pixels)\n",
      "Saved: pred_tp_fp_mcd_2017_12.tif (Predicted 753,535 pixels)\n",
      "\n",
      "--- Starting Year: 2018 ---\n",
      "Processing 2306 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2018_01.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_02.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_03.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_04.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_05.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_06.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_07.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_08.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_09.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_10.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_11.tif (Predicted 891,448 pixels)\n",
      "Saved: pred_tp_fp_mcd_2018_12.tif (Predicted 891,448 pixels)\n",
      "\n",
      "--- Starting Year: 2019 ---\n",
      "Processing 2234 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2019_01.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_02.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_03.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_04.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_05.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_06.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_07.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_08.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_09.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_10.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_11.tif (Predicted 844,278 pixels)\n",
      "Saved: pred_tp_fp_mcd_2019_12.tif (Predicted 844,278 pixels)\n",
      "\n",
      "--- Starting Year: 2020 ---\n",
      "Processing 2374 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2020_01.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_02.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_03.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_04.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_05.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_06.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_07.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_08.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_09.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_10.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_11.tif (Predicted 894,092 pixels)\n",
      "Saved: pred_tp_fp_mcd_2020_12.tif (Predicted 894,092 pixels)\n",
      "\n",
      "--- Starting Year: 2021 ---\n",
      "Processing 2262 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2021_01.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_02.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_03.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_04.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_05.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_06.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_07.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_08.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_09.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_10.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_11.tif (Predicted 877,857 pixels)\n",
      "Saved: pred_tp_fp_mcd_2021_12.tif (Predicted 877,857 pixels)\n",
      "\n",
      "--- Starting Year: 2022 ---\n",
      "Processing 2303 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2022_01.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_02.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_03.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_04.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_05.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_06.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_07.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_08.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_09.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_10.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_11.tif (Predicted 875,984 pixels)\n",
      "Saved: pred_tp_fp_mcd_2022_12.tif (Predicted 875,984 pixels)\n",
      "\n",
      "--- Starting Year: 2023 ---\n",
      "Processing 2756 TP/FP coarse cells...\n",
      "Saved: pred_tp_fp_mcd_2023_01.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_02.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_03.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_04.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_05.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_06.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_07.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_08.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_09.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_10.tif (Predicted 1,056,046 pixels)\n",
      "Saved: pred_tp_fp_mcd_2023_11.tif (Predicted 1,056,046 pixels)\n",
      "\n",
      "✅ All available years and months processed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Apply Stage-2 XGBoost model to MCD 4km pixels.\n",
    "-- ANALYTICAL VERSION --\n",
    "\n",
    "Logic:\n",
    "1. Load \"Analytical\" Stage 1 predictions for MCD (Shapefiles).\n",
    "2. Filter for coarse grid cells labeled 'TP' or 'FP'.\n",
    "3. For every month in that year, load the 4km MCD GeoTIFF.\n",
    "4. Mask 4km pixels: only predict on pixels INSIDE those TP/FP coarse cells.\n",
    "5. Save the resulting probability map as a new GeoTIFF.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio import features\n",
    "import xgboost as xgb\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "# 1. INPUT SHAPEFILES (MCD Analytical Predictions from Stage 1)\n",
    "SHP_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"training_e5l_cems_mcd_with_fraction/stage_1_predictions_on_mcd_analytical/pred_vs_obs_shapefiles_annual\"\n",
    ")\n",
    "\n",
    "# 2. INPUT TIFFS (MCD Monthly Data)\n",
    "IN_TIF_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# 3. MODEL (Trained on FireCCI Stage 2)\n",
    "MODEL_PATH = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\"\n",
    ")\n",
    "\n",
    "# 4. OUTPUT DIRECTORY\n",
    "OUT_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"predictions_tp_fp_only_mcd_analytical\"\n",
    ")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 5. OVERWRITE SETTINGS\n",
    "# Years listed here will be re-processed even if the output file exists.\n",
    "OVERWRITE_YEARS = [2020, 2021, 2022, 2023]\n",
    "\n",
    "# 15 Predictors used by the model (Must match training order)\n",
    "FEATURES = [\n",
    "    \"DEM\", \"slope\", \"aspect\", \"b1\", \"relative_humidity\", \n",
    "    \"total_precipitation_sum\", \"temperature_2m\", \"temperature_2m_min\", \n",
    "    \"temperature_2m_max\", \"build_up_index\", \"drought_code\", \n",
    "    \"duff_moisture_code\", \"fine_fuel_moisture_code\", \n",
    "    \"fire_weather_index\", \"initial_fire_spread_index\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "\n",
    "def get_annual_shp(year):\n",
    "    path = SHP_DIR / f\"cems_e5l_mcd_{year}_annual_grid1deg_pred_vs_obs_analytical.shp\"\n",
    "    return path if path.exists() else None\n",
    "\n",
    "def get_monthly_tif(year, month):\n",
    "    pattern = f\"cems_e5l_mcd_{year}_{month}_with_fraction.tif\"\n",
    "    path = IN_TIF_DIR / pattern\n",
    "    return path if path.exists() else None\n",
    "\n",
    "# ============================================================\n",
    "# Main Prediction Logic\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    if not MODEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
    "\n",
    "    # Load XGBoost model\n",
    "    print(f\"Loading model: {MODEL_PATH}\")\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(str(MODEL_PATH))\n",
    "    \n",
    "    # Identify available years from shapefiles\n",
    "    shp_files = list(SHP_DIR.glob(\"*_analytical.shp\"))\n",
    "    \n",
    "    years = []\n",
    "    for f in shp_files:\n",
    "        m = re.search(r'cems_e5l_mcd_(\\d{4})_', f.name)\n",
    "        if m:\n",
    "            years.append(int(m.group(1)))\n",
    "    years = sorted(years)\n",
    "    \n",
    "    if not years:\n",
    "        print(f\"No matching analytical shapefiles found in {SHP_DIR}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(years)} years to process: {years}\")\n",
    "    print(f\"Years marked for overwrite: {OVERWRITE_YEARS}\")\n",
    "    \n",
    "    for year in years:\n",
    "        shp_path = get_annual_shp(year)\n",
    "        if not shp_path:\n",
    "            print(f\"Skipping {year}: Expected file not found at {shp_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n--- Starting Year: {year} ---\")\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "        \n",
    "        if 'pred_obs' not in gdf.columns:\n",
    "            print(f\"Column 'pred_obs' missing in {shp_path.name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        mask_gdf = gdf[gdf['pred_obs'].str.upper().isin(['TP', 'FP'])].copy()\n",
    "        \n",
    "        if mask_gdf.empty:\n",
    "            print(f\"No TP/FP regions found for {year}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {len(mask_gdf)} TP/FP coarse cells...\")\n",
    "\n",
    "        for month in range(1, 13):\n",
    "            out_name = OUT_DIR / f\"pred_tp_fp_mcd_{year}_{month:02d}.tif\"\n",
    "            \n",
    "            # --- CHECK FOR EXISTING FILES & OVERWRITE LOGIC ---\n",
    "            if out_name.exists():\n",
    "                if year in OVERWRITE_YEARS:\n",
    "                    print(f\"  [OVERWRITE] File exists for {year}-{month:02d}, reprocessing as requested.\")\n",
    "                else:\n",
    "                    print(f\"  [SKIP] File exists for {year}-{month:02d}, skipping.\")\n",
    "                    continue\n",
    "            # --------------------------------------------------\n",
    "\n",
    "            tif_path = get_monthly_tif(year, month)\n",
    "            if not tif_path:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                with rio.open(tif_path) as src:\n",
    "                    # 1. Align CRS\n",
    "                    if mask_gdf.crs != src.crs:\n",
    "                        mask_gdf = mask_gdf.to_crs(src.crs)\n",
    "                    \n",
    "                    # 2. Rasterize TP/FP mask\n",
    "                    mask = features.rasterize(\n",
    "                        [(geom, 1) for geom in mask_gdf.geometry],\n",
    "                        out_shape=src.shape,\n",
    "                        transform=src.transform,\n",
    "                        fill=0,\n",
    "                        dtype='uint8'\n",
    "                    )\n",
    "                    \n",
    "                    if not np.any(mask == 1):\n",
    "                        continue\n",
    "\n",
    "                    # 3. Read and Prepare Data\n",
    "                    img_data = src.read()\n",
    "                    \n",
    "                    idx_y, idx_x = np.where(mask == 1)\n",
    "                    pixels = img_data[:, idx_y, idx_x].T\n",
    "                    \n",
    "                    if pixels.shape[1] >= 15:\n",
    "                        pixels = pixels[:, :15]\n",
    "                    else:\n",
    "                        print(f\"Error: {tif_path.name} has only {pixels.shape[1]} bands (need 15+).\")\n",
    "                        continue\n",
    "\n",
    "                    # 4. Predict\n",
    "                    dmat = xgb.DMatrix(pixels, feature_names=FEATURES)\n",
    "                    preds = booster.predict(dmat)\n",
    "                    \n",
    "                    # 5. Save\n",
    "                    out_proba = np.zeros((src.height, src.width), dtype='float32')\n",
    "                    out_proba[idx_y, idx_x] = preds\n",
    "                    \n",
    "                    out_meta = src.meta.copy()\n",
    "                    out_meta.update(\n",
    "                        dtype='float32', \n",
    "                        count=1, \n",
    "                        nodata=0,\n",
    "                        compress='deflate'\n",
    "                    )\n",
    "                    \n",
    "                    with rio.open(out_name, 'w', **out_meta) as dst:\n",
    "                        dst.write(out_proba, 1)\n",
    "                    \n",
    "                    print(f\"Saved: {out_name.name} (Predicted {len(preds):,} pixels)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {year}-{month:02d}: {e}\")\n",
    "\n",
    "    print(\"\\n✅ All available years and months processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc43b93d-aad3-49f7-89fa-74516242222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace01b4-9c8f-4256-a202-e4f9dc8c4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save burned area per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c2af10-7dfe-4550-befd-5fbad8d8a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecoregions...\n",
      "Processing Year: 2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2001: 100%|██████████| 27/27 [00:05<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2002: 100%|██████████| 27/27 [00:05<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2003: 100%|██████████| 27/27 [00:05<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2004: 100%|██████████| 27/27 [00:05<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2005: 100%|██████████| 27/27 [00:06<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2006: 100%|██████████| 27/27 [00:05<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2007: 100%|██████████| 27/27 [00:05<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2008: 100%|██████████| 27/27 [00:06<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2009: 100%|██████████| 27/27 [00:05<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2010: 100%|██████████| 27/27 [00:05<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2011: 100%|██████████| 27/27 [00:12<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2012: 100%|██████████| 27/27 [00:12<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2013: 100%|██████████| 27/27 [00:12<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2014: 100%|██████████| 27/27 [00:12<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2015: 100%|██████████| 27/27 [00:12<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2016: 100%|██████████| 27/27 [00:12<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2017: 100%|██████████| 27/27 [00:12<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2018: 100%|██████████| 27/27 [00:12<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2019: 100%|██████████| 27/27 [00:12<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2020: 100%|██████████| 27/27 [00:12<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2021: 100%|██████████| 27/27 [00:12<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2022: 100%|██████████| 27/27 [00:12<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Year: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ecoregions 2023: 100%|██████████| 27/27 [00:12<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE. Results saved to /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical/ba_ecoregion_tp_fp_predictions_08_mcd_analytical.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Calculate Annual Burned Area (Mha) per Ecoregion for MCD Analytical Predictions.\n",
    "\n",
    "Logic:\n",
    "1. Loads monthly probability TIFFs for MCD (pred_tp_fp_mcd_YYYY_MM.tif).\n",
    "2. Thresholds probabilities (> 0.80) to create binary monthly masks.\n",
    "3. Aggregates monthly masks into a single Annual Burned Mask.\n",
    "4. Intersects the Annual Mask with Ecoregion polygons.\n",
    "5. Calculates area in Million Hectares (Mha), accounting for pixel area variation by latitude (EPSG:4326).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import geometry_mask\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "YEARS  = list(range(2001, 2024)) # Adjust as needed\n",
    "MONTHS = list(range(1, 13))\n",
    "\n",
    "# UPDATED: Point to the MCD analytical predictions directory\n",
    "PRED_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/predictions_tp_fp_only_mcd_analytical\")\n",
    "PROB_THRESHOLD = 0.50  # To convert probability to 0/1 mask\n",
    "\n",
    "# Ecoregion shapefile\n",
    "ECOS_PATH = \"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\"\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "# UPDATED: Output CSV directory (MCD analytical)\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = OUT_DIR / \"ba_ecoregion_tp_fp_predictions_08_mcd_analytical.csv\"\n",
    "\n",
    "# ============================\n",
    "# HELPERS\n",
    "# ============================\n",
    "\n",
    "def get_annual_mask(year, pred_dir, threshold):\n",
    "    \"\"\"\n",
    "    Aggregates monthly probability TIFFs into a single annual binary mask.\n",
    "    Returns: (annual_mask_bool, transform, crs)\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "    transform = None\n",
    "    crs = None\n",
    "    \n",
    "    found_any = False\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        # UPDATED Pattern: pred_tp_fp_mcd_YYYY_MM.tif\n",
    "        tif_path = pred_dir / f\"pred_tp_fp_mcd_{year}_{month:02d}.tif\"\n",
    "        if not tif_path.exists():\n",
    "            continue\n",
    "            \n",
    "        found_any = True\n",
    "        with rio.open(tif_path) as src:\n",
    "            prob = src.read(1)\n",
    "            # Binary mask: 1 if prob >= threshold, else 0\n",
    "            monthly_burn = (prob >= threshold).astype(bool)\n",
    "            \n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "                transform = src.transform\n",
    "                crs = src.crs\n",
    "            else:\n",
    "                # Logical OR accumulation\n",
    "                annual = annual | monthly_burn\n",
    "                \n",
    "    if not found_any:\n",
    "        return None, None, None\n",
    "                \n",
    "    return annual, transform, crs\n",
    "\n",
    "def get_pixel_area_grid(shape, transform, crs):\n",
    "    \"\"\"\n",
    "    Generates a grid of pixel areas in Mha.\n",
    "    Handles EPSG:4326 by calculating area based on latitude.\n",
    "    \"\"\"\n",
    "    height, width = shape\n",
    "    \n",
    "    # Resolution\n",
    "    res_x = abs(transform.a)\n",
    "    res_y = abs(transform.e)\n",
    "\n",
    "    if crs.is_geographic:\n",
    "        # EPSG:4326 - Area depends on latitude\n",
    "        # 1 degree lat ~ 111,320 meters\n",
    "        # 1 degree lon ~ 111,320 * cos(lat) meters\n",
    "        \n",
    "        # Get latitude of every row center\n",
    "        # transform * (0, row) gives top-left of row\n",
    "        # We want center, so row + 0.5\n",
    "        rows = np.arange(height) + 0.5\n",
    "        _, lats = rio.transform.xy(transform, rows, np.zeros_like(rows), offset='center')\n",
    "        lats = np.array(lats)\n",
    "        \n",
    "        # Calculate area per pixel for each row (in square meters)\n",
    "        # Area = (res_x * 111320 * cos(lat)) * (res_y * 111320)\n",
    "        \n",
    "        lat_rads = np.radians(lats)\n",
    "        # Cosine scaling for longitude width\n",
    "        pixel_width_m = res_x * 111320 * np.cos(lat_rads)\n",
    "        pixel_height_m = res_y * 111320\n",
    "        \n",
    "        row_areas_m2 = pixel_width_m * pixel_height_m\n",
    "        \n",
    "        # Broadcast to full grid (H, W)\n",
    "        # Shape (H, 1) to broadcast across columns\n",
    "        area_grid_m2 = row_areas_m2[:, np.newaxis] * np.ones((1, width))\n",
    "        \n",
    "    else:\n",
    "        # Projected CRS (Meters) - Constant area\n",
    "        pixel_area_m2 = res_x * res_y\n",
    "        area_grid_m2 = np.full(shape, pixel_area_m2)\n",
    "\n",
    "    # Convert m2 to Million Hectares (Mha)\n",
    "    # 1 Ha = 10,000 m2\n",
    "    # 1 Mha = 1,000,000 Ha = 10,000,000,000 m2 (1e10)\n",
    "    area_grid_Mha = area_grid_m2 / 1e10\n",
    "    \n",
    "    return area_grid_Mha\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "print(\"Loading ecoregions...\")\n",
    "ecos = gpd.read_file(ECOS_PATH)\n",
    "\n",
    "results = []\n",
    "\n",
    "for year in YEARS:\n",
    "    print(f\"Processing Year: {year}\")\n",
    "    annual_mask, transform, crs = get_annual_mask(year, PRED_DIR, PROB_THRESHOLD)\n",
    "    \n",
    "    if annual_mask is None:\n",
    "        print(f\"  No predictions found for {year}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Reproject ecoregions to match raster if necessary\n",
    "    if ecos.crs != crs:\n",
    "        ecos_proj = ecos.to_crs(crs)\n",
    "    else:\n",
    "        ecos_proj = ecos\n",
    "\n",
    "    # Generate Pixel Area Map (Mha) for this raster geometry\n",
    "    pixel_area_map = get_pixel_area_grid(annual_mask.shape, transform, crs)\n",
    "\n",
    "    height, width = annual_mask.shape\n",
    "    \n",
    "    # Iterate through ecoregions\n",
    "    for idx, row in tqdm(ecos_proj.iterrows(), total=len(ecos_proj), desc=f\"Ecoregions {year}\"):\n",
    "        eco_id = row[ECO_ID_COL]\n",
    "        geom = row.geometry\n",
    "        \n",
    "        if geom is None or geom.is_empty:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Create boolean mask for this specific ecoregion\n",
    "            # invert=True means True inside the shape\n",
    "            eco_mask = geometry_mask(\n",
    "                [geom],\n",
    "                transform=transform,\n",
    "                invert=True,\n",
    "                out_shape=(height, width),\n",
    "                all_touched=False # strict center inclusion\n",
    "            )\n",
    "            \n",
    "            # Intersection: (Pixel is Burned) AND (Pixel is in Ecoregion)\n",
    "            burned_in_eco_mask = annual_mask & eco_mask\n",
    "            \n",
    "            if burned_in_eco_mask.any():\n",
    "                # Sum the specific areas of the burned pixels\n",
    "                ba_Mha = pixel_area_map[burned_in_eco_mask].sum()\n",
    "            else:\n",
    "                ba_Mha = 0.0\n",
    "            \n",
    "            results.append({\n",
    "                \"ecoregion\": eco_id,\n",
    "                \"year\": year,\n",
    "                \"ba_pred_tp_fp_Mha\": ba_Mha\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing eco {eco_id} in {year}: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"DONE. Results saved to {OUT_CSV}\")\n",
    "else:\n",
    "    print(\"No results generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a47bbd-e9b8-4680-96df-3bb837ff94e4",
   "metadata": {},
   "source": [
    "Make multipanel plot per ecoregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c41b2d-d908-4357-8466-bb6e0a96228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Base Reference Data from: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions.csv\n",
      "Loading New MCD Predictions from: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical/ba_ecoregion_tp_fp_predictions_08_mcd_analytical.csv\n",
      "Merged CSV saved to: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical/burned_area_by_ecoregion_all_merged_08_mcd_analytical.csv\n",
      "✅ Comparison plot (2001-2019) with TOTAL panel saved to:\n",
      "   /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical/burned_area_multipanel_tp_fp_comparison_08_mcd_analytical.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Compare TP/FP predictions (MCD Analytical) to MCD64A1 and FireCCI native products (2001-2019).\n",
    "Includes an ecoregion-summed \"Total\" panel and professional color palette.\n",
    "-- MCD ANALYTICAL VERSION --\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "# Directory containing the REFERENCE data (MCD/FireCCI) - assumed to be in the original folder\n",
    "REF_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "\n",
    "# Directory for NEW outputs (MCD Analytical)\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries_mcd_analytical\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Files\n",
    "BASE_CSV     = REF_DIR / \"burned_area_by_ecoregion_predictions.csv\"  # Contains ba_mcd_native_Mha / ba_firecci_native_Mha\n",
    "NEW_PRED_CSV = OUT_DIR / \"ba_ecoregion_tp_fp_predictions_08_mcd_analytical.csv\" # From previous step\n",
    "\n",
    "# Output Files\n",
    "FINAL_CSV    = OUT_DIR / \"burned_area_by_ecoregion_all_merged_08_mcd_analytical.csv\"\n",
    "OUT_PNG      = OUT_DIR / \"burned_area_multipanel_tp_fp_comparison_08_mcd_analytical.png\"\n",
    "\n",
    "# Column Names\n",
    "ECO_ID_COL  = \"ecoregion\"\n",
    "MCD_COL     = \"ba_mcd_native_Mha\"\n",
    "FIRECCI_COL = \"ba_firecci_native_Mha\"\n",
    "PRED_COL    = \"ba_pred_tp_fp_Mha\"\n",
    "\n",
    "YEAR_START, YEAR_END = 2001, 2024\n",
    "\n",
    "# EXCLUSIONS\n",
    "EXCLUDE_ECOS = {\"WATER\", \"MIXED WOOD SHIELD\", \"TEMPERATE PRAIRIES\", \"WESTERN CORDILLERA\"}\n",
    "\n",
    "# PROFESSIONAL COLORS\n",
    "COLORS = {\n",
    "    MCD_COL: \"#2c3e50\",      # Slate Grey\n",
    "    FIRECCI_COL: \"#e67e22\",  # Vivid Orange\n",
    "    PRED_COL: \"#16a085\"      # Deep Teal (Predicted MCD TP+FP)\n",
    "}\n",
    "\n",
    "def nice_pred_label(colname: str) -> str:\n",
    "    if colname == \"ba_pred_tp_fp_Mha\":\n",
    "        return \"Prediction (MCD TP+FP)\"\n",
    "    return colname\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(f\"Loading Base Reference Data from: {BASE_CSV}\")\n",
    "    if not BASE_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Base CSV not found: {BASE_CSV}\")\n",
    "        \n",
    "    print(f\"Loading New MCD Predictions from: {NEW_PRED_CSV}\")\n",
    "    if not NEW_PRED_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Prediction CSV not found: {NEW_PRED_CSV}\")\n",
    "\n",
    "    # --- 1. Load, Filter and Merge ---\n",
    "    df_base = pd.read_csv(BASE_CSV)\n",
    "    df_pred = pd.read_csv(NEW_PRED_CSV)\n",
    "    \n",
    "    # Merge on Ecoregion and Year\n",
    "    # We left join pred onto base to keep the structure.\n",
    "    df = df_base.merge(df_pred, on=[ECO_ID_COL, \"year\"], how=\"left\")\n",
    "    \n",
    "    # Filter years 2001-2019\n",
    "    df = df[(df[\"year\"] >= YEAR_START) & (df[\"year\"] <= YEAR_END)].copy()\n",
    "    \n",
    "    # Save merged data for inspection\n",
    "    df.to_csv(FINAL_CSV, index=False)\n",
    "    print(f\"Merged CSV saved to: {FINAL_CSV}\")\n",
    "\n",
    "    # --- 2. Prepare Subplots ---\n",
    "    ecos_all = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    ecos_list = [e for e in ecos_all if e not in EXCLUDE_ECOS]\n",
    "    \n",
    "    # Add a virtual \"TOTAL\" entry to the list\n",
    "    plot_list = ecos_list + [\"TOTAL BURNED AREA\"]\n",
    "    n_panels = len(plot_list)\n",
    "\n",
    "    ncols = 4\n",
    "    nrows = int(np.ceil(n_panels / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, \n",
    "        figsize=(4 * ncols, 3.5 * nrows), \n",
    "        sharex=True\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    handles_for_legend = None\n",
    "\n",
    "    # --- 3. Plotting Loop ---\n",
    "    for i, title in enumerate(plot_list):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        if title == \"TOTAL BURNED AREA\":\n",
    "            # Aggregate sum across all ecoregions\n",
    "            df_plot = df.groupby(\"year\")[[MCD_COL, FIRECCI_COL, PRED_COL]].sum().reset_index()\n",
    "            ax.set_facecolor('#fdfefe') # Light highlight for total panel\n",
    "        else:\n",
    "            df_plot = df[df[ECO_ID_COL] == title].sort_values(\"year\")\n",
    "\n",
    "        # Plot datasets\n",
    "        p1, = ax.plot(df_plot[\"year\"], df_plot[MCD_COL], marker=\"o\", markersize=4, \n",
    "                      label=\"MCD64A1\", color=COLORS[MCD_COL], linewidth=1.5)\n",
    "        p2, = ax.plot(df_plot[\"year\"], df_plot[FIRECCI_COL], marker=\"s\", markersize=4, \n",
    "                      label=\"Fire CCI\", color=COLORS[FIRECCI_COL], linewidth=1.5)\n",
    "        p3, = ax.plot(df_plot[\"year\"], df_plot[PRED_COL], marker=\"^\", markersize=4, \n",
    "                      label=nice_pred_label(PRED_COL), color=COLORS[PRED_COL], linewidth=2)\n",
    "\n",
    "        ax.set_title(str(title), fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, ls=\":\", alpha=0.6)\n",
    "        ax.tick_params(axis='both', labelsize=9)\n",
    "\n",
    "        if i == 0:\n",
    "            handles_for_legend = [p1, p2, p3]\n",
    "\n",
    "        # Axis labeling\n",
    "        if i >= (n_panels - ncols):\n",
    "            ax.set_xlabel(\"Year\", fontsize=10)\n",
    "        if i % ncols == 0:\n",
    "            ax.set_ylabel(\"Burned Area (Mha)\", fontsize=10)\n",
    "\n",
    "        # Handle scaling for very low values (avoid scientific notation or flat lines at 0)\n",
    "        # Check max of columns ignoring NaNs\n",
    "        vals = df_plot[[MCD_COL, FIRECCI_COL, PRED_COL]]\n",
    "        y_max = vals.max().max() if not vals.empty else 0\n",
    "        \n",
    "        if pd.notna(y_max) and y_max < 0.005:\n",
    "            ax.set_ylim(0, 0.01)\n",
    "\n",
    "    # Clean up empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Global legend\n",
    "    if handles_for_legend:\n",
    "        fig.legend(\n",
    "            handles=handles_for_legend,\n",
    "            labels=[\"MCD64A1\", \"Fire CCI\", nice_pred_label(PRED_COL)],\n",
    "            loc=\"lower center\", \n",
    "            ncol=3, \n",
    "            fontsize=12,\n",
    "            frameon=False,\n",
    "            bbox_to_anchor=(0.5, -0.02)\n",
    "        )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    plt.savefig(OUT_PNG, dpi=250, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Comparison plot (2001-2019) with TOTAL panel saved to:\\n   {OUT_PNG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791215a0-f4a0-462d-8e31-1af40d56635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7c306-c006-4034-80df-30d302a1b9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
