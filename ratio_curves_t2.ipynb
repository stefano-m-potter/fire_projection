{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d64fd9-f433-47e4-aa8b-4edece41644a",
   "metadata": {},
   "source": [
    "Option 2: Vary negative ratios in train/val, use scale_pos_weight, fixed global test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c81f0e8-1f41-4edf-88a1-4f50f27fb8ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction_balanced.parquet\n",
      "Dropped 0 rows with NaNs/Â±inf; 172,072 remain.\n",
      "\n",
      "Class counts before any splitting:\n",
      "0    112224\n",
      "1     59848\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Treating 'b1' as pandas 'category'.\n",
      "\n",
      "Predictor columns: 15\n",
      "\n",
      "Global split sizes (true distribution in test):\n",
      "  Train/Val pool: 154,864\n",
      "  Test (fixed)  : 17,208\n",
      "\n",
      "Test set class counts (true distribution):\n",
      "0    11223\n",
      "1     5985\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Train/Val pool class counts:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Effective positive samples in train/val sweeps: 53,863\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 10% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 10,773\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    10773\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 10%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg010pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 50,272\n",
      "  Val  : 14,364\n",
      "scale_pos_weight for this sweep (train subset): 0.200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.833327 -> initscore=1.609390\n",
      "[LightGBM] [Info] Start training from score 1.609390\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.447201\ttrain's IoU: 0.813388\tvalidation's binary_logloss: 0.465328\tvalidation's IoU: 0.796564\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttrain's binary_logloss: 0.413593\ttrain's IoU: 0.833327\tvalidation's binary_logloss: 0.418519\tvalidation's IoU: 0.833333\n",
      "Saved IoU learning curve for 10%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg010pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=10%): 0.734  (precision=0.9127, recall=0.8000)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 10\n",
      "Threshold    : 0.734\n",
      "IoU (Jaccard): 0.48\n",
      "Precision    : 0.54\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.65\n",
      "Saved feature importance plot for 10%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg010pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 20% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 21,545\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    21545\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 20%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg020pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 58,650\n",
      "  Val  : 16,758\n",
      "scale_pos_weight for this sweep (train subset): 0.400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.714288 -> initscore=0.916303\n",
      "[LightGBM] [Info] Start training from score 0.916303\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.480747\ttrain's IoU: 0.753951\tvalidation's binary_logloss: 0.497364\tvalidation's IoU: 0.737002\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttrain's binary_logloss: 0.511377\ttrain's IoU: 0.785081\tvalidation's binary_logloss: 0.517394\tvalidation's IoU: 0.783602\n",
      "Saved IoU learning curve for 20%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg020pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=20%): 0.609  (precision=0.8510, recall=0.8011)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 20\n",
      "Threshold    : 0.609\n",
      "IoU (Jaccard): 0.49\n",
      "Precision    : 0.55\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.66\n",
      "Saved feature importance plot for 20%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg020pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 30% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 32,318\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    32318\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 30%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg030pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 67,029\n",
      "  Val  : 19,152\n",
      "scale_pos_weight for this sweep (train subset): 0.600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624998 -> initscore=0.510818\n",
      "[LightGBM] [Info] Start training from score 0.510818\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.495374\ttrain's IoU: 0.703195\tvalidation's binary_logloss: 0.511989\tvalidation's IoU: 0.683071\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttrain's binary_logloss: 0.566031\ttrain's IoU: 0.718304\tvalidation's binary_logloss: 0.571624\tvalidation's IoU: 0.71347\n",
      "Saved IoU learning curve for 30%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg030pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=30%): 0.572  (precision=0.7860, recall=0.8001)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 30\n",
      "Threshold    : 0.572\n",
      "IoU (Jaccard): 0.49\n",
      "Precision    : 0.55\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.66\n",
      "Saved feature importance plot for 30%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg030pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 40% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 43,090\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    43090\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 40%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg040pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 75,407\n",
      "  Val  : 21,546\n",
      "scale_pos_weight for this sweep (train subset): 0.800\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555559 -> initscore=0.223155\n",
      "[LightGBM] [Info] Start training from score 0.223155\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.504923\ttrain's IoU: 0.660375\tvalidation's binary_logloss: 0.517516\tvalidation's IoU: 0.644373\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttrain's binary_logloss: 0.609952\ttrain's IoU: 0.66438\tvalidation's binary_logloss: 0.611943\tvalidation's IoU: 0.658204\n",
      "Saved IoU learning curve for 40%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg040pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=40%): 0.546  (precision=0.7372, recall=0.8003)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 40\n",
      "Threshold    : 0.546\n",
      "IoU (Jaccard): 0.48\n",
      "Precision    : 0.55\n",
      "Recall       : 0.79\n",
      "F1 Score     : 0.65\n",
      "Saved feature importance plot for 40%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg040pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 50% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 53,863\n",
      "Class counts in sweep train/val dataset:\n",
      "0    53863\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 50%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg050pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "scale_pos_weight for this sweep (train subset): 1.000\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.507913\ttrain's IoU: 0.624373\tvalidation's binary_logloss: 0.516911\tvalidation's IoU: 0.615621\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Saved IoU learning curve for 50%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg050pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=50%): 0.526  (precision=0.7189, recall=0.8000)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 50\n",
      "Threshold    : 0.526\n",
      "IoU (Jaccard): 0.50\n",
      "Precision    : 0.57\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 50%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg050pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 60% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 64,636\n",
      "Class counts in sweep train/val dataset:\n",
      "0    64636\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 60%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg060pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 92,165\n",
      "  Val  : 26,334\n",
      "scale_pos_weight for this sweep (train subset): 1.200\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454543 -> initscore=-0.182330\n",
      "[LightGBM] [Info] Start training from score -0.182330\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.510498\ttrain's IoU: 0.591879\tvalidation's binary_logloss: 0.521466\tvalidation's IoU: 0.579731\n",
      "[100]\ttrain's binary_logloss: 0.486419\ttrain's IoU: 0.606416\tvalidation's binary_logloss: 0.505773\tvalidation's IoU: 0.586437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.486419\ttrain's IoU: 0.606416\tvalidation's binary_logloss: 0.505773\tvalidation's IoU: 0.586437\n",
      "Saved IoU learning curve for 60%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg060pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=60%): 0.529  (precision=0.6727, recall=0.8000)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 60\n",
      "Threshold    : 0.529\n",
      "IoU (Jaccard): 0.50\n",
      "Precision    : 0.57\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 60%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg060pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 70% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 75,408\n",
      "Class counts in sweep train/val dataset:\n",
      "0    75408\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 70%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg070pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 100,544\n",
      "  Val  : 28,727\n",
      "scale_pos_weight for this sweep (train subset): 1.400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416663 -> initscore=-0.336486\n",
      "[LightGBM] [Info] Start training from score -0.336486\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.510627\ttrain's IoU: 0.564077\tvalidation's binary_logloss: 0.520558\tvalidation's IoU: 0.552881\n",
      "[100]\ttrain's binary_logloss: 0.489014\ttrain's IoU: 0.579832\tvalidation's binary_logloss: 0.505696\tvalidation's IoU: 0.561183\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.489014\ttrain's IoU: 0.579832\tvalidation's binary_logloss: 0.505696\tvalidation's IoU: 0.561183\n",
      "Saved IoU learning curve for 70%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg070pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=70%): 0.530  (precision=0.6448, recall=0.8000)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 70\n",
      "Threshold    : 0.530\n",
      "IoU (Jaccard): 0.51\n",
      "Precision    : 0.58\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 70%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg070pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 80% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 86,181\n",
      "Class counts in sweep train/val dataset:\n",
      "0    86181\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 80%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg080pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 108,923\n",
      "  Val  : 31,121\n",
      "scale_pos_weight for this sweep (train subset): 1.600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384611 -> initscore=-0.470022\n",
      "[LightGBM] [Info] Start training from score -0.470022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.510657\ttrain's IoU: 0.538979\tvalidation's binary_logloss: 0.520953\tvalidation's IoU: 0.525724\n",
      "[100]\ttrain's binary_logloss: 0.49037\ttrain's IoU: 0.553335\tvalidation's binary_logloss: 0.508239\tvalidation's IoU: 0.532513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.49037\ttrain's IoU: 0.553335\tvalidation's binary_logloss: 0.508239\tvalidation's IoU: 0.532513\n",
      "Saved IoU learning curve for 80%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg080pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=80%): 0.525  (precision=0.6087, recall=0.8003)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 80\n",
      "Threshold    : 0.525\n",
      "IoU (Jaccard): 0.51\n",
      "Precision    : 0.58\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 80%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg080pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 90% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 96,953\n",
      "Class counts in sweep train/val dataset:\n",
      "0    96953\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 90%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg090pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 117,301\n",
      "  Val  : 33,515\n",
      "scale_pos_weight for this sweep (train subset): 1.800\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357141 -> initscore=-0.587795\n",
      "[LightGBM] [Info] Start training from score -0.587795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.511732\ttrain's IoU: 0.515032\tvalidation's binary_logloss: 0.51672\tvalidation's IoU: 0.503989\n",
      "[100]\ttrain's binary_logloss: 0.493767\ttrain's IoU: 0.530136\tvalidation's binary_logloss: 0.504716\tvalidation's IoU: 0.512605\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.493767\ttrain's IoU: 0.530136\tvalidation's binary_logloss: 0.504716\tvalidation's IoU: 0.512605\n",
      "Saved IoU learning curve for 90%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg090pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=90%): 0.526  (precision=0.5851, recall=0.8005)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 90\n",
      "Threshold    : 0.526\n",
      "IoU (Jaccard): 0.51\n",
      "Precision    : 0.58\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 90%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg090pct.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 100% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 100%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/trainval_data_neg100pct.parquet\n",
      "\n",
      "Sweep split sizes (within train/val pool):\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n",
      "scale_pos_weight for this sweep (train subset): 1.875\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.347807 -> initscore=-0.628693\n",
      "[LightGBM] [Info] Start training from score -0.628693\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.510845\ttrain's IoU: 0.505453\tvalidation's binary_logloss: 0.516588\tvalidation's IoU: 0.498304\n",
      "[100]\ttrain's binary_logloss: 0.494731\ttrain's IoU: 0.519136\tvalidation's binary_logloss: 0.506573\tvalidation's IoU: 0.504649\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.494731\ttrain's IoU: 0.519136\tvalidation's binary_logloss: 0.506573\tvalidation's IoU: 0.504649\n",
      "Saved IoU learning curve for 100%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/iou_curve_neg100pct.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (NEG=100%): 0.529  (precision=0.5750, recall=0.8000)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 100\n",
      "Threshold    : 0.529\n",
      "IoU (Jaccard): 0.50\n",
      "Precision    : 0.58\n",
      "Recall       : 0.79\n",
      "F1 Score     : 0.67\n",
      "Saved feature importance plot for 100%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/feature_importance_neg100pct.png\n",
      "\n",
      "Saved Option 2 global-test sweep summary to: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight/option2_neg_ratio_sweep_globaltest_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Option 2 (global fixed test set, per-sweep scale_pos_weight, rounded metrics):\n",
    "- Read full cems_with_fraction_balanced.parquet\n",
    "- Build features, coerce to numeric, drop bad rows\n",
    "- Create a single global test set (10%) with true 0/1 distribution (no resampling)\n",
    "- Use the remaining 90% as a train/val pool\n",
    "- Within the train/val pool:\n",
    "    - Fix a positive sample set once\n",
    "    - Sweep negative ratios (10%..100%, where 100% = 2x positives)\n",
    "    - For each sweep:\n",
    "        - Build a balanced train/val dataset with that negative count\n",
    "        - Split into train/val; compute scale_pos_weight from TRAIN subset\n",
    "        - Train LightGBM (sklearn API)\n",
    "        - Choose threshold on val (max precision with recall â¥ floor)\n",
    "        - Evaluate on the SAME global test set\n",
    "- Save:\n",
    "    - Balanced train/val parquet per sweep\n",
    "    - IoU learning curve PNG per sweep\n",
    "    - Feature importance PNG per sweep\n",
    "    - Summary CSV with **rounded** test metrics across sweeps\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    jaccard_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "PARQUET_IN    = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction.parquet\"\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "# Overall split: global test set (10%), rest train/val pool (90%)\n",
    "TEST_SIZE_GLOBAL = 0.10\n",
    "VAL_SIZE_OVERALL = 0.20   # overall val fraction of full dataset; derive inner val from this\n",
    "\n",
    "THRESH_INIT   = 0.50      # for IoU logging during training\n",
    "RECALL_FLOOR  = 0.80\n",
    "TOP_N_IMPORT  = 30\n",
    "\n",
    "# Negative ratio sweep within the train/val pool:\n",
    "# 100% = 2x positives, 10% = 0.2x positives, etc.\n",
    "PCT_STEPS = list(range(10, 101, 10))\n",
    "\n",
    "# Optional: cap positives in train/val pool for speed (None = use all)\n",
    "MAX_SAMPLES_POS_TRAINVAL = None\n",
    "\n",
    "# LightGBM base params\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=48,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.75,\n",
    "    bagging_freq=5,\n",
    "    lambda_l2=2.0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Output root and option-specific dir\n",
    "OUT_ROOT = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest\"\n",
    "OUT_DIR  = os.path.join(OUT_ROOT, \"option2_scale_pos_weight\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD & EARLY CLEAN (ONCE)\n",
    "# =====================================================\n",
    "print(f\"Loading: {PARQUET_IN}\")\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "\n",
    "if \"fraction\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'fraction' in dataset.\")\n",
    "\n",
    "df[\"fraction\"] = df[\"fraction\"].astype(\"float32\").clip(0.0, 1.0)\n",
    "before = len(df)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\").copy()\n",
    "print(f\"Dropped {before - len(df):,} rows with NaNs/Â±inf; {len(df):,} remain.\")\n",
    "\n",
    "# =====================================================\n",
    "# FRACTION -> BINARY\n",
    "# =====================================================\n",
    "df[\"burned\"] = (df[\"fraction\"] > THRESH_INIT).astype(np.uint8)\n",
    "\n",
    "print(\"\\nClass counts before any splitting:\")\n",
    "print(df[\"burned\"].value_counts(dropna=False))\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE MATRIX (GLOBAL) + TYPE COERCION\n",
    "# =====================================================\n",
    "drop_cols = {\"fraction\", \"burned\", \"bin\", \"year\", \"month\", \"latitude\", \"longitude\"}\n",
    "predictors = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X_full = df[predictors].copy()\n",
    "y_full = df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# Treat 'b1' as category if present\n",
    "if \"b1\" in X_full.columns and not pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "    X_full[\"b1\"] = X_full[\"b1\"].astype(\"category\")\n",
    "    print(\"\\nTreating 'b1' as pandas 'category'.\")\n",
    "\n",
    "# Coerce non-category columns to numeric and drop rows with NaNs\n",
    "coerced = 0\n",
    "for c in X_full.columns:\n",
    "    if c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[c]):\n",
    "        continue\n",
    "    if not np.issubdtype(X_full[c].dtype, np.number):\n",
    "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
    "        coerced += 1\n",
    "\n",
    "if coerced:\n",
    "    pre = len(X_full)\n",
    "    num_cols = [c for c in X_full.columns if not (c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]))]\n",
    "    mask = X_full[num_cols].notna().all(axis=1)\n",
    "    if \"b1\" in X_full.columns and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        mask &= X_full[\"b1\"].notna()\n",
    "    X_full = X_full.loc[mask].copy()\n",
    "    y_full = y_full.loc[X_full.index]\n",
    "    print(f\"Coerced {coerced} column(s); dropped {pre - len(X_full):,} rows post-coercion.\")\n",
    "\n",
    "print(f\"\\nPredictor columns: {len(X_full.columns)}\")\n",
    "\n",
    "# Combine into a single DataFrame for convenient splitting\n",
    "data = X_full.copy()\n",
    "data[\"burned\"] = y_full\n",
    "\n",
    "# =====================================================\n",
    "# GLOBAL TRAINVAL / TEST SPLIT (FIXED TEST SET)\n",
    "# =====================================================\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    data.index,\n",
    "    test_size=TEST_SIZE_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[\"burned\"],\n",
    ")\n",
    "\n",
    "trainval = data.loc[idx_trainval].copy()\n",
    "test     = data.loc[idx_test].copy()\n",
    "\n",
    "print(\"\\nGlobal split sizes (true distribution in test):\")\n",
    "print(f\"  Train/Val pool: {len(trainval):,}\")\n",
    "print(f\"  Test (fixed)  : {len(test):,}\")\n",
    "print(\"\\nTest set class counts (true distribution):\")\n",
    "print(test[\"burned\"].value_counts())\n",
    "\n",
    "# Extract global test X, y\n",
    "X_test = test[predictors].copy()\n",
    "y_test = test[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# =====================================================\n",
    "# TRAIN/VAL POOL: POS/NEG SPLITTING BASE\n",
    "# =====================================================\n",
    "pos_tv = trainval[trainval[\"burned\"] == 1]\n",
    "neg_tv = trainval[trainval[\"burned\"] == 0]\n",
    "\n",
    "n_pos_tv = len(pos_tv)\n",
    "n_neg_tv = len(neg_tv)\n",
    "\n",
    "print(\"\\nTrain/Val pool class counts:\")\n",
    "print(trainval[\"burned\"].value_counts())\n",
    "\n",
    "if n_pos_tv == 0 or n_neg_tv == 0:\n",
    "    raise ValueError(\"Train/Val pool has only one class; cannot proceed.\")\n",
    "\n",
    "# Fix positive sample within train/val pool (optionally capped)\n",
    "target_pos = n_pos_tv\n",
    "if MAX_SAMPLES_POS_TRAINVAL is not None:\n",
    "    target_pos = min(target_pos, MAX_SAMPLES_POS_TRAINVAL)\n",
    "\n",
    "pos_tv_s = pos_tv.sample(n=min(n_pos_tv, target_pos), random_state=RANDOM_STATE)\n",
    "n_pos_eff = len(pos_tv_s)\n",
    "print(f\"\\nEffective positive samples in train/val sweeps: {n_pos_eff:,}\")\n",
    "\n",
    "# =====================================================\n",
    "# Custom IoU metric for logging (sklearn API)\n",
    "# =====================================================\n",
    "def lgb_iou_metric_skl(y_true, y_pred):\n",
    "    y_hat = (y_pred >= THRESH_INIT).astype(np.uint8)\n",
    "    iou = jaccard_score(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    return (\"IoU\", iou, True)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# =====================================================\n",
    "# SWEEP OVER NEGATIVE RATIOS IN TRAIN/VAL POOL\n",
    "# =====================================================\n",
    "for pct in PCT_STEPS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"== Option 2: NEGATIVE PERCENT = {pct}% (100% = 2x positives in TRAIN/VAL) ==\")\n",
    "\n",
    "    # 100% -> 2 * n_pos_eff\n",
    "    # 10%  -> 0.2 * n_pos_eff\n",
    "    neg_target = int(round((pct / 100.0) * 2.0 * n_pos_eff))\n",
    "    neg_target = max(1, min(neg_target, n_neg_tv))\n",
    "\n",
    "    print(f\"Target negatives for this sweep (from train/val pool): {neg_target:,}\")\n",
    "\n",
    "    neg_tv_s = neg_tv.sample(n=neg_target, random_state=RANDOM_STATE + pct)\n",
    "\n",
    "    sweep_df = (\n",
    "        pd.concat([pos_tv_s, neg_tv_s], axis=0)\n",
    "          .sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"Class counts in sweep train/val dataset:\")\n",
    "    print(sweep_df[\"burned\"].value_counts())\n",
    "\n",
    "    # Save sweep train/val parquet\n",
    "    parquet_out = os.path.join(\n",
    "        OUT_DIR, f\"trainval_data_neg{pct:03d}pct.parquet\"\n",
    "    )\n",
    "    sweep_df.to_parquet(parquet_out)\n",
    "    print(f\"Saved sweep train/val parquet for {pct}%: {parquet_out}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # FEATURES / TARGET FOR THIS SWEEP (TRAIN/VAL ONLY)\n",
    "    # =====================================================\n",
    "    X_sweep = sweep_df[predictors].copy()\n",
    "    y_sweep = sweep_df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "    # 70/20 of the *full dataset* corresponds to 70/20 out of (1 - TEST_SIZE_GLOBAL)\n",
    "    val_size_inner = VAL_SIZE_OVERALL / (1.0 - TEST_SIZE_GLOBAL)  # e.g., 0.20 / 0.90\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_sweep,\n",
    "        y_sweep,\n",
    "        test_size=val_size_inner,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_sweep,\n",
    "    )\n",
    "\n",
    "    print(\"\\nSweep split sizes (within train/val pool):\")\n",
    "    print(f\"  Train: {len(X_train):,}\")\n",
    "    print(f\"  Val  : {len(X_val):,}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # scale_pos_weight BASED ON TRAIN SUBSET\n",
    "    # =====================================================\n",
    "    n_pos_train = int((y_train == 1).sum())\n",
    "    n_neg_train = int((y_train == 0).sum())\n",
    "    pos_weight = n_neg_train / max(1, n_pos_train)\n",
    "    print(f\"scale_pos_weight for this sweep (train subset): {pos_weight:.3f}\")\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        **LGB_PARAMS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scale_pos_weight=pos_weight,\n",
    "    )\n",
    "\n",
    "    evals_result = {}\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_names=[\"train\", \"validation\"],\n",
    "        eval_metric=[\"aucpr\", lgb_iou_metric_skl],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=50),\n",
    "            lgb.record_evaluation(evals_result),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # LEARNING CURVE: IoU (TRAIN vs VAL)\n",
    "    # =====================================================\n",
    "    if \"IoU\" in evals_result.get(\"train\", {}):\n",
    "        train_iou_curve = evals_result[\"train\"][\"IoU\"]\n",
    "        val_iou_curve   = evals_result[\"validation\"][\"IoU\"]\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(train_iou_curve, label=\"Train IoU\")\n",
    "        plt.plot(val_iou_curve,   label=\"Validation IoU\")\n",
    "        plt.xlabel(\"Boosting Rounds\")\n",
    "        plt.ylabel(\"IoU (Jaccard)\")\n",
    "        plt.title(\n",
    "            f\"Option 2: Train vs Val IoU\\n\"\n",
    "            f\"NEG={pct}% (100% = 2x positives in train/val), THRESH_INIT={THRESH_INIT:.2f}\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        iou_fig_out = os.path.join(\n",
    "            OUT_DIR, f\"iou_curve_neg{pct:03d}pct.png\"\n",
    "        )\n",
    "        plt.savefig(iou_fig_out, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved IoU learning curve for {pct}%: {iou_fig_out}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # THRESHOLD SELECTION ON VALIDATION\n",
    "    # =====================================================\n",
    "    y_val_proba = model.predict_proba(X_val, num_iteration=model.best_iteration_)[:, 1]\n",
    "    prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "    mask = rec[:-1] >= RECALL_FLOOR\n",
    "\n",
    "    if not np.any(mask):\n",
    "        print(f\"\\nNo threshold meets recall >= {RECALL_FLOOR:.2f}; using global max precision.\")\n",
    "        best_idx = np.argmax(prec[:-1])\n",
    "    else:\n",
    "        best_idx_rel = np.argmax(prec[:-1][mask])\n",
    "        best_idx = np.flatnonzero(mask)[best_idx_rel]\n",
    "\n",
    "    best_thr = float(thr[best_idx])  # probability threshold in [0,1]\n",
    "    print(\n",
    "        f\"\\nChosen threshold on VALID (NEG={pct}%): {best_thr:.3f}  \"\n",
    "        f\"(precision={prec[best_idx]:.4f}, recall={rec[best_idx]:.4f})\"\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # FINAL METRICS ON FIXED GLOBAL TEST SET\n",
    "    # =====================================================\n",
    "    y_test_proba = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "    y_test_hat   = (y_test_proba >= best_thr).astype(np.uint8)\n",
    "\n",
    "    test_iou  = jaccard_score(y_test, y_test_hat, average=\"binary\", zero_division=0)\n",
    "    test_prec = precision_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_rec  = recall_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_f1   = f1_score(y_test, y_test_hat, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== FINAL TEST METRICS (fixed global test set) ====\")\n",
    "    print(f\"NEG % in train/val (100%=2x pos): {pct}\")\n",
    "    print(f\"Threshold    : {best_thr:.3f}\")\n",
    "    print(f\"IoU (Jaccard): {test_iou:.2f}\")\n",
    "    print(f\"Precision    : {test_prec:.2f}\")\n",
    "    print(f\"Recall       : {test_rec:.2f}\")\n",
    "    print(f\"F1 Score     : {test_f1:.2f}\")\n",
    "\n",
    "    summary_rows.append(\n",
    "        dict(\n",
    "            neg_percent=pct,\n",
    "            n_pos_train=n_pos_train,\n",
    "            n_neg_train=n_neg_train,\n",
    "            scale_pos_weight=round(pos_weight, 3),\n",
    "            threshold=round(best_thr, 3),\n",
    "            test_iou=round(test_iou, 2),\n",
    "            test_precision=round(test_prec, 2),\n",
    "            test_recall=round(test_rec, 2),\n",
    "            test_f1=round(test_f1, 2),\n",
    "            best_iteration=int(model.best_iteration_ if hasattr(model, \"best_iteration_\") else -1),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # FEATURE IMPORTANCE\n",
    "    # =====================================================\n",
    "    gain_imp = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    gain_imp = gain_imp / (gain_imp.sum() + 1e-12)\n",
    "    feat_names = np.array(X_train.columns)\n",
    "\n",
    "    order = np.argsort(gain_imp)[::-1][:TOP_N_IMPORT]\n",
    "    plt.figure(figsize=(9, max(5, 0.28 * len(order))))\n",
    "    plt.barh(feat_names[order][::-1], gain_imp[order][::-1])\n",
    "    plt.xlabel(\"Relative Gain Importance\")\n",
    "    plt.title(\n",
    "        f\"Option 2: Feature Importance (Top {len(order)})\\n\"\n",
    "        f\"NEG={pct}% (100% = 2x positives in train/val)\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fi_fig_out = os.path.join(\n",
    "        OUT_DIR, f\"feature_importance_neg{pct:03d}pct.png\"\n",
    "    )\n",
    "    plt.savefig(fi_fig_out, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved feature importance plot for {pct}%: {fi_fig_out}\")\n",
    "\n",
    "# =====================================================\n",
    "# SAVE SUMMARY CSV (rounded metrics)\n",
    "# =====================================================\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv = os.path.join(OUT_DIR, \"option2_neg_ratio_sweep_globaltest_metrics.csv\")\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSaved Option 2 global-test sweep summary to: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo sweeps were run; summary not saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579bf6f-32eb-43af-8cee-a2c22547d4c4",
   "metadata": {},
   "source": [
    "Option 2 penalize false positives more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ad0e08-3730-4152-a7bb-93a86d2b9d98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTPUT DIRECTORY ===\n",
      "/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp\n",
      "\n",
      "Loading: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction_balanced.parquet\n",
      "Dropped 0 rows with NaNs/Â±inf; 172,072 remain.\n",
      "\n",
      "Class counts before any splitting:\n",
      "0    112224\n",
      "1     59848\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Treating 'b1' as pandas 'category'.\n",
      "\n",
      "Predictor columns: 15\n",
      "\n",
      "Global split sizes (true distribution in test):\n",
      "  Train/Val pool: 154,864\n",
      "  Test (fixed)  : 17,208\n",
      "\n",
      "Test set class counts (true distribution):\n",
      "0    11223\n",
      "1     5985\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Train/Val pool class counts:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Effective positive samples in train/val sweeps: 53,863\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 10% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 10,773\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    10773\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.833327 -> initscore=1.609390\n",
      "[LightGBM] [Info] Start training from score 1.609390\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.312667\ttrain's IoU: 0.878394\tvalidation's binary_logloss: 0.33238\tvalidation's IoU: 0.874669\n",
      "[100]\ttrain's binary_logloss: 0.291151\ttrain's IoU: 0.882799\tvalidation's binary_logloss: 0.324587\tvalidation's IoU: 0.876995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.291151\ttrain's IoU: 0.882799\tvalidation's binary_logloss: 0.324587\tvalidation's IoU: 0.876995\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.008 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=10, w_neg=1.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.008\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w1.0.png\n",
      "[Saved model artifacts for NEG=10%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg010pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.714276 -> initscore=0.916243\n",
      "[LightGBM] [Info] Start training from score 0.916243\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.417412\ttrain's IoU: 0.877423\tvalidation's binary_logloss: 0.358709\tvalidation's IoU: 0.871583\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttrain's binary_logloss: 0.47191\ttrain's IoU: 0.874681\tvalidation's binary_logloss: 0.395772\tvalidation's IoU: 0.873244\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.290 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=10, w_neg=2.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.290\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w2.0.png\n",
      "[Saved model artifacts for NEG=10%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg010pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624989 -> initscore=0.510778\n",
      "[LightGBM] [Info] Start training from score 0.510778\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.464275\ttrain's IoU: 0.865112\tvalidation's binary_logloss: 0.402302\tvalidation's IoU: 0.85478\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttrain's binary_logloss: 0.578427\ttrain's IoU: 0.873436\tvalidation's binary_logloss: 0.491062\tvalidation's IoU: 0.872219\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.419 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=10, w_neg=3.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.419\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w3.0.png\n",
      "[Saved model artifacts for NEG=10%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg010pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000048\n",
      "[LightGBM] [Info] Start training from score -0.000048\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.491681\ttrain's IoU: 0.796687\tvalidation's binary_logloss: 0.492728\tvalidation's IoU: 0.776944\n",
      "[100]\ttrain's binary_logloss: 0.453334\ttrain's IoU: 0.810593\tvalidation's binary_logloss: 0.467654\tvalidation's IoU: 0.785415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.453334\ttrain's IoU: 0.810593\tvalidation's binary_logloss: 0.467654\tvalidation's IoU: 0.785415\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.005 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=10, w_neg=5.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.005\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w5.0.png\n",
      "[Saved model artifacts for NEG=10%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg010pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 20% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 21,545\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    21545\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.714288 -> initscore=0.916303\n",
      "[LightGBM] [Info] Start training from score 0.916303\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.425104\ttrain's IoU: 0.793313\tvalidation's binary_logloss: 0.440951\tvalidation's IoU: 0.789144\n",
      "[100]\ttrain's binary_logloss: 0.400091\ttrain's IoU: 0.802163\tvalidation's binary_logloss: 0.428102\tvalidation's IoU: 0.789527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.400091\ttrain's IoU: 0.802163\tvalidation's binary_logloss: 0.428102\tvalidation's IoU: 0.789527\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.414 (precision=0.8000, recall=0.9843)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=20, w_neg=1.0] TEST: IoU=0.457, Prec=0.462, Rec=0.980, F1=0.628, Thr=0.414\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w1.0.png\n",
      "[Saved model artifacts for NEG=20%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg020pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555559 -> initscore=0.223155\n",
      "[LightGBM] [Info] Start training from score 0.223155\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.495306\ttrain's IoU: 0.775199\tvalidation's binary_logloss: 0.479492\tvalidation's IoU: 0.75979\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttrain's binary_logloss: 0.621262\ttrain's IoU: 0.784119\tvalidation's binary_logloss: 0.591681\tvalidation's IoU: 0.782827\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.503 (precision=0.8000, recall=0.9728)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=20, w_neg=2.0] TEST: IoU=0.456, Prec=0.462, Rec=0.971, F1=0.626, Thr=0.503\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w2.0.png\n",
      "[Saved model artifacts for NEG=20%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg020pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454548 -> initscore=-0.182310\n",
      "[LightGBM] [Info] Start training from score -0.182310\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.502348\ttrain's IoU: 0.70028\tvalidation's binary_logloss: 0.538316\tvalidation's IoU: 0.674533\n",
      "[100]\ttrain's binary_logloss: 0.471344\ttrain's IoU: 0.726745\tvalidation's binary_logloss: 0.516278\tvalidation's IoU: 0.688704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.471344\ttrain's IoU: 0.726745\tvalidation's binary_logloss: 0.516278\tvalidation's IoU: 0.688704\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.218 (precision=0.8000, recall=0.9814)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=20, w_neg=3.0] TEST: IoU=0.457, Prec=0.462, Rec=0.978, F1=0.627, Thr=0.218\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w3.0.png\n",
      "[Saved model artifacts for NEG=20%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg020pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333336 -> initscore=-0.693135\n",
      "[LightGBM] [Info] Start training from score -0.693135\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.471405\ttrain's IoU: 0.484703\tvalidation's binary_logloss: 0.654952\tvalidation's IoU: 0.460149\n",
      "[100]\ttrain's binary_logloss: 0.442236\ttrain's IoU: 0.556216\tvalidation's binary_logloss: 0.623806\tvalidation's IoU: 0.517504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.442236\ttrain's IoU: 0.556216\tvalidation's binary_logloss: 0.623806\tvalidation's IoU: 0.517504\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.150 (precision=0.8000, recall=0.9821)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=20, w_neg=5.0] TEST: IoU=0.456, Prec=0.461, Rec=0.977, F1=0.626, Thr=0.150\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w5.0.png\n",
      "[Saved model artifacts for NEG=20%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg020pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 30% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 32,318\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    32318\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624998 -> initscore=0.510818\n",
      "[LightGBM] [Info] Start training from score 0.510818\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.476096\ttrain's IoU: 0.730202\tvalidation's binary_logloss: 0.492316\tvalidation's IoU: 0.717233\n",
      "[100]\ttrain's binary_logloss: 0.450173\ttrain's IoU: 0.73771\tvalidation's binary_logloss: 0.477307\tvalidation's IoU: 0.719861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.450173\ttrain's IoU: 0.73771\tvalidation's binary_logloss: 0.477307\tvalidation's IoU: 0.719861\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.629 (precision=0.8000, recall=0.8219)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=30, w_neg=1.0] TEST: IoU=0.502, Prec=0.564, Rec=0.821, F1=0.669, Thr=0.629\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w1.0.png\n",
      "[Saved model artifacts for NEG=30%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg030pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454543 -> initscore=-0.182330\n",
      "[LightGBM] [Info] Start training from score -0.182330\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.505212\ttrain's IoU: 0.661583\tvalidation's binary_logloss: 0.534636\tvalidation's IoU: 0.643529\n",
      "[100]\ttrain's binary_logloss: 0.477319\ttrain's IoU: 0.682656\tvalidation's binary_logloss: 0.516111\tvalidation's IoU: 0.652257\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.477319\ttrain's IoU: 0.682656\tvalidation's binary_logloss: 0.516111\tvalidation's IoU: 0.652257\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.470 (precision=0.8000, recall=0.8104)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=30, w_neg=2.0] TEST: IoU=0.502, Prec=0.567, Rec=0.813, F1=0.668, Thr=0.470\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w2.0.png\n",
      "[Saved model artifacts for NEG=30%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg030pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357141 -> initscore=-0.587795\n",
      "[LightGBM] [Info] Start training from score -0.587795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.484024\ttrain's IoU: 0.507906\tvalidation's binary_logloss: 0.597955\tvalidation's IoU: 0.480278\n",
      "[100]\ttrain's binary_logloss: 0.458087\ttrain's IoU: 0.565049\tvalidation's binary_logloss: 0.575646\tvalidation's IoU: 0.5306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.458087\ttrain's IoU: 0.565049\tvalidation's binary_logloss: 0.575646\tvalidation's IoU: 0.5306\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.370 (precision=0.8000, recall=0.8143)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=30, w_neg=3.0] TEST: IoU=0.504, Prec=0.566, Rec=0.820, F1=0.670, Thr=0.370\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w3.0.png\n",
      "[Saved model artifacts for NEG=30%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg030pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249999 -> initscore=-1.098620\n",
      "[LightGBM] [Info] Start training from score -1.098620\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.424891\ttrain's IoU: 0.27894\tvalidation's binary_logloss: 0.719065\tvalidation's IoU: 0.260353\n",
      "[100]\ttrain's binary_logloss: 0.402903\ttrain's IoU: 0.353057\tvalidation's binary_logloss: 0.6903\tvalidation's IoU: 0.324326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.402903\ttrain's IoU: 0.353057\tvalidation's binary_logloss: 0.6903\tvalidation's IoU: 0.324326\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.267 (precision=0.8000, recall=0.8048)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=30, w_neg=5.0] TEST: IoU=0.501, Prec=0.568, Rec=0.810, F1=0.668, Thr=0.267\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w5.0.png\n",
      "[Saved model artifacts for NEG=30%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg030pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 40% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 43,090\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    43090\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555559 -> initscore=0.223155\n",
      "[LightGBM] [Info] Start training from score 0.223155\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.500125\ttrain's IoU: 0.674971\tvalidation's binary_logloss: 0.512931\tvalidation's IoU: 0.660163\n",
      "[100]\ttrain's binary_logloss: 0.473772\ttrain's IoU: 0.684949\tvalidation's binary_logloss: 0.496627\tvalidation's IoU: 0.665042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.473772\ttrain's IoU: 0.684949\tvalidation's binary_logloss: 0.496627\tvalidation's IoU: 0.665042\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.677 (precision=0.8000, recall=0.6166)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=40, w_neg=1.0] TEST: IoU=0.460, Prec=0.641, Rec=0.620, F1=0.630, Thr=0.677\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w1.0.png\n",
      "[Saved model artifacts for NEG=40%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg040pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384618 -> initscore=-0.469992\n",
      "[LightGBM] [Info] Start training from score -0.469992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.49571\ttrain's IoU: 0.540988\tvalidation's binary_logloss: 0.556202\tvalidation's IoU: 0.521789\n",
      "[100]\ttrain's binary_logloss: 0.469726\ttrain's IoU: 0.588622\tvalidation's binary_logloss: 0.536023\tvalidation's IoU: 0.555516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.469726\ttrain's IoU: 0.588622\tvalidation's binary_logloss: 0.536023\tvalidation's IoU: 0.555516\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.519 (precision=0.8001, recall=0.6108)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=40, w_neg=2.0] TEST: IoU=0.457, Prec=0.642, Rec=0.613, F1=0.627, Thr=0.519\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w2.0.png\n",
      "[Saved model artifacts for NEG=40%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg040pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294120 -> initscore=-0.875457\n",
      "[LightGBM] [Info] Start training from score -0.875457\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.4572\ttrain's IoU: 0.355822\tvalidation's binary_logloss: 0.619887\tvalidation's IoU: 0.344819\n",
      "[100]\ttrain's binary_logloss: 0.434368\ttrain's IoU: 0.433483\tvalidation's binary_logloss: 0.596436\tvalidation's IoU: 0.410288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.434368\ttrain's IoU: 0.433483\tvalidation's binary_logloss: 0.596436\tvalidation's IoU: 0.410288\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.414 (precision=0.8000, recall=0.6239)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=40, w_neg=3.0] TEST: IoU=0.459, Prec=0.637, Rec=0.621, F1=0.629, Thr=0.414\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w3.0.png\n",
      "[Saved model artifacts for NEG=40%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg040pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200002 -> initscore=-1.386282\n",
      "[LightGBM] [Info] Start training from score -1.386282\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.384899\ttrain's IoU: 0.159674\tvalidation's binary_logloss: 0.740245\tvalidation's IoU: 0.151838\n",
      "[100]\ttrain's binary_logloss: 0.366499\ttrain's IoU: 0.230307\tvalidation's binary_logloss: 0.710695\tvalidation's IoU: 0.218541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.366499\ttrain's IoU: 0.230307\tvalidation's binary_logloss: 0.710695\tvalidation's IoU: 0.218541\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.299 (precision=0.8000, recall=0.6260)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=40, w_neg=5.0] TEST: IoU=0.460, Prec=0.635, Rec=0.625, F1=0.630, Thr=0.299\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w5.0.png\n",
      "[Saved model artifacts for NEG=40%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg040pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 50% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 53,863\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    53863\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.507913\ttrain's IoU: 0.624373\tvalidation's binary_logloss: 0.516911\tvalidation's IoU: 0.615621\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.678 (precision=0.8000, recall=0.5007)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=50, w_neg=1.0] TEST: IoU=0.400, Prec=0.680, Rec=0.493, F1=0.571, Thr=0.678\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w1.0.png\n",
      "[Saved model artifacts for NEG=50%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg050pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.478066\ttrain's IoU: 0.437838\tvalidation's binary_logloss: 0.560591\tvalidation's IoU: 0.422161\n",
      "[100]\ttrain's binary_logloss: 0.454367\ttrain's IoU: 0.500032\tvalidation's binary_logloss: 0.539757\tvalidation's IoU: 0.473873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.454367\ttrain's IoU: 0.500032\tvalidation's binary_logloss: 0.539757\tvalidation's IoU: 0.473873\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.516 (precision=0.8001, recall=0.5081)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=50, w_neg=2.0] TEST: IoU=0.410, Prec=0.683, Rec=0.506, F1=0.582, Thr=0.516\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w2.0.png\n",
      "[Saved model artifacts for NEG=50%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg050pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250000 -> initscore=-1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.428734\ttrain's IoU: 0.257159\tvalidation's binary_logloss: 0.623652\tvalidation's IoU: 0.253143\n",
      "[100]\ttrain's binary_logloss: 0.408386\ttrain's IoU: 0.33467\tvalidation's binary_logloss: 0.599952\tvalidation's IoU: 0.320446\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.408386\ttrain's IoU: 0.33467\tvalidation's binary_logloss: 0.599952\tvalidation's IoU: 0.320446\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.412 (precision=0.8001, recall=0.5195)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=50, w_neg=3.0] TEST: IoU=0.412, Prec=0.680, Rec=0.512, F1=0.584, Thr=0.412\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w3.0.png\n",
      "[Saved model artifacts for NEG=50%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg050pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.350387\ttrain's IoU: 0.0912944\tvalidation's binary_logloss: 0.740613\tvalidation's IoU: 0.0875477\n",
      "[100]\ttrain's binary_logloss: 0.334409\ttrain's IoU: 0.157414\tvalidation's binary_logloss: 0.712321\tvalidation's IoU: 0.146518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.334409\ttrain's IoU: 0.157414\tvalidation's binary_logloss: 0.712321\tvalidation's IoU: 0.146518\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.297 (precision=0.8000, recall=0.5253)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=50, w_neg=5.0] TEST: IoU=0.418, Prec=0.681, Rec=0.519, F1=0.589, Thr=0.297\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w5.0.png\n",
      "[Saved model artifacts for NEG=50%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg050pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 60% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 64,636\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    64636\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454543 -> initscore=-0.182330\n",
      "[LightGBM] [Info] Start training from score -0.182330\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.508943\ttrain's IoU: 0.576704\tvalidation's binary_logloss: 0.519326\tvalidation's IoU: 0.559007\n",
      "[100]\ttrain's binary_logloss: 0.484167\ttrain's IoU: 0.594797\tvalidation's binary_logloss: 0.502782\tvalidation's IoU: 0.569416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.484167\ttrain's IoU: 0.594797\tvalidation's binary_logloss: 0.502782\tvalidation's IoU: 0.569416\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.701 (precision=0.8000, recall=0.3439)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=60, w_neg=1.0] TEST: IoU=0.303, Prec=0.734, Rec=0.340, F1=0.465, Thr=0.701\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w1.0.png\n",
      "[Saved model artifacts for NEG=60%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg060pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294116 -> initscore=-0.875477\n",
      "[LightGBM] [Info] Start training from score -0.875477\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.45902\ttrain's IoU: 0.344018\tvalidation's binary_logloss: 0.560621\tvalidation's IoU: 0.333485\n",
      "[100]\ttrain's binary_logloss: 0.43732\ttrain's IoU: 0.416111\tvalidation's binary_logloss: 0.541359\tvalidation's IoU: 0.390383\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.43732\ttrain's IoU: 0.416111\tvalidation's binary_logloss: 0.541359\tvalidation's IoU: 0.390383\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.538 (precision=0.8000, recall=0.3609)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=60, w_neg=2.0] TEST: IoU=0.313, Prec=0.735, Rec=0.353, F1=0.477, Thr=0.538\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w2.0.png\n",
      "[Saved model artifacts for NEG=60%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg060pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217390 -> initscore=-1.280942\n",
      "[LightGBM] [Info] Start training from score -1.280942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.402913\ttrain's IoU: 0.183958\tvalidation's binary_logloss: 0.621164\tvalidation's IoU: 0.185766\n",
      "[100]\ttrain's binary_logloss: 0.384573\ttrain's IoU: 0.260119\tvalidation's binary_logloss: 0.599078\tvalidation's IoU: 0.248031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.384573\ttrain's IoU: 0.260119\tvalidation's binary_logloss: 0.599078\tvalidation's IoU: 0.248031\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.431 (precision=0.8001, recall=0.3835)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=60, w_neg=3.0] TEST: IoU=0.328, Prec=0.728, Rec=0.373, F1=0.494, Thr=0.431\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w3.0.png\n",
      "[Saved model artifacts for NEG=60%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg060pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142856 -> initscore=-1.791767\n",
      "[LightGBM] [Info] Start training from score -1.791767\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.321792\ttrain's IoU: 0.0633507\tvalidation's binary_logloss: 0.732169\tvalidation's IoU: 0.06193\n",
      "[100]\ttrain's binary_logloss: 0.307898\ttrain's IoU: 0.116132\tvalidation's binary_logloss: 0.705831\tvalidation's IoU: 0.110709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.307898\ttrain's IoU: 0.116132\tvalidation's binary_logloss: 0.705831\tvalidation's IoU: 0.110709\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.318 (precision=0.8000, recall=0.3803)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=60, w_neg=5.0] TEST: IoU=0.332, Prec=0.735, Rec=0.377, F1=0.498, Thr=0.318\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w5.0.png\n",
      "[Saved model artifacts for NEG=60%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg060pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 70% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 75,408\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    75408\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416663 -> initscore=-0.336486\n",
      "[LightGBM] [Info] Start training from score -0.336486\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.504044\ttrain's IoU: 0.529569\tvalidation's binary_logloss: 0.513944\tvalidation's IoU: 0.510898\n",
      "[100]\ttrain's binary_logloss: 0.48035\ttrain's IoU: 0.553552\tvalidation's binary_logloss: 0.497136\tvalidation's IoU: 0.530004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.48035\ttrain's IoU: 0.553552\tvalidation's binary_logloss: 0.497136\tvalidation's IoU: 0.530004\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.696 (precision=0.8001, recall=0.2792)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=70, w_neg=1.0] TEST: IoU=0.253, Prec=0.757, Rec=0.276, F1=0.404, Thr=0.696\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w1.0.png\n",
      "[Saved model artifacts for NEG=70%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg070pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.263155 -> initscore=-1.029633\n",
      "[LightGBM] [Info] Start training from score -1.029633\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.438632\ttrain's IoU: 0.276565\tvalidation's binary_logloss: 0.55393\tvalidation's IoU: 0.264587\n",
      "[100]\ttrain's binary_logloss: 0.418494\ttrain's IoU: 0.35274\tvalidation's binary_logloss: 0.533818\tvalidation's IoU: 0.330532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.418494\ttrain's IoU: 0.35274\tvalidation's binary_logloss: 0.533818\tvalidation's IoU: 0.330532\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.529 (precision=0.8001, recall=0.3123)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=70, w_neg=2.0] TEST: IoU=0.283, Prec=0.761, Rec=0.310, F1=0.441, Thr=0.529\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w2.0.png\n",
      "[Saved model artifacts for NEG=70%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg070pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.192306 -> initscore=-1.435098\n",
      "[LightGBM] [Info] Start training from score -1.435098\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.378844\ttrain's IoU: 0.140837\tvalidation's binary_logloss: 0.612792\tvalidation's IoU: 0.137611\n",
      "[100]\ttrain's binary_logloss: 0.362398\ttrain's IoU: 0.206282\tvalidation's binary_logloss: 0.590272\tvalidation's IoU: 0.200322\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.362398\ttrain's IoU: 0.206282\tvalidation's binary_logloss: 0.590272\tvalidation's IoU: 0.200322\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.438 (precision=0.8000, recall=0.3038)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=70, w_neg=3.0] TEST: IoU=0.274, Prec=0.762, Rec=0.300, F1=0.430, Thr=0.438\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w3.0.png\n",
      "[Saved model artifacts for NEG=70%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg070pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.124999 -> initscore=-1.945924\n",
      "[LightGBM] [Info] Start training from score -1.945924\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.297211\ttrain's IoU: 0.0412523\tvalidation's binary_logloss: 0.719138\tvalidation's IoU: 0.0405124\n",
      "[100]\ttrain's binary_logloss: 0.285068\ttrain's IoU: 0.0877392\tvalidation's binary_logloss: 0.692039\tvalidation's IoU: 0.0801158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.285068\ttrain's IoU: 0.0877392\tvalidation's binary_logloss: 0.692039\tvalidation's IoU: 0.0801158\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.314 (precision=0.8000, recall=0.3308)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=70, w_neg=5.0] TEST: IoU=0.295, Prec=0.759, Rec=0.326, F1=0.456, Thr=0.314\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w5.0.png\n",
      "[Saved model artifacts for NEG=70%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg070pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 80% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 86,181\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    86181\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384611 -> initscore=-0.470022\n",
      "[LightGBM] [Info] Start training from score -0.470022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.496954\ttrain's IoU: 0.484719\tvalidation's binary_logloss: 0.507188\tvalidation's IoU: 0.462457\n",
      "[100]\ttrain's binary_logloss: 0.472908\ttrain's IoU: 0.51571\tvalidation's binary_logloss: 0.490378\tvalidation's IoU: 0.487683\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.472908\ttrain's IoU: 0.51571\tvalidation's binary_logloss: 0.490378\tvalidation's IoU: 0.487683\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.699 (precision=0.8001, recall=0.2183)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=80, w_neg=1.0] TEST: IoU=0.203, Prec=0.784, Rec=0.215, F1=0.337, Thr=0.699\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w1.0.png\n",
      "[Saved model artifacts for NEG=80%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg080pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238092 -> initscore=-1.163169\n",
      "[LightGBM] [Info] Start training from score -1.163169\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.420106\ttrain's IoU: 0.217661\tvalidation's binary_logloss: 0.545988\tvalidation's IoU: 0.212627\n",
      "[100]\ttrain's binary_logloss: 0.400958\ttrain's IoU: 0.295423\tvalidation's binary_logloss: 0.527386\tvalidation's IoU: 0.278857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.400958\ttrain's IoU: 0.295423\tvalidation's binary_logloss: 0.527386\tvalidation's IoU: 0.278857\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.536 (precision=0.8000, recall=0.2379)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=80, w_neg=2.0] TEST: IoU=0.221, Prec=0.782, Rec=0.235, F1=0.361, Thr=0.536\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w2.0.png\n",
      "[Saved model artifacts for NEG=80%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg080pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.172411 -> initscore=-1.568634\n",
      "[LightGBM] [Info] Start training from score -1.568634\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.357789\ttrain's IoU: 0.100665\tvalidation's binary_logloss: 0.603483\tvalidation's IoU: 0.0954255\n",
      "[100]\ttrain's binary_logloss: 0.342489\ttrain's IoU: 0.160708\tvalidation's binary_logloss: 0.582745\tvalidation's IoU: 0.150125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.342489\ttrain's IoU: 0.160708\tvalidation's binary_logloss: 0.582745\tvalidation's IoU: 0.150125\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.439 (precision=0.8001, recall=0.2414)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=80, w_neg=3.0] TEST: IoU=0.223, Prec=0.785, Rec=0.238, F1=0.365, Thr=0.439\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w3.0.png\n",
      "[Saved model artifacts for NEG=80%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg080pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.111109 -> initscore=-2.079459\n",
      "[LightGBM] [Info] Start training from score -2.079459\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.276991\ttrain's IoU: 0.0173787\tvalidation's binary_logloss: 0.705097\tvalidation's IoU: 0.014663\n",
      "[100]\ttrain's binary_logloss: 0.265808\ttrain's IoU: 0.06056\tvalidation's binary_logloss: 0.680637\tvalidation's IoU: 0.0549896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.265808\ttrain's IoU: 0.06056\tvalidation's binary_logloss: 0.680637\tvalidation's IoU: 0.0549896\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.319 (precision=0.8000, recall=0.2613)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=80, w_neg=5.0] TEST: IoU=0.240, Prec=0.784, Rec=0.256, F1=0.387, Thr=0.319\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w5.0.png\n",
      "[Saved model artifacts for NEG=80%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg080pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 90% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 96,953\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    96953\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357141 -> initscore=-0.587795\n",
      "[LightGBM] [Info] Start training from score -0.587795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.490284\ttrain's IoU: 0.428068\tvalidation's binary_logloss: 0.496384\tvalidation's IoU: 0.415469\n",
      "[100]\ttrain's binary_logloss: 0.466721\ttrain's IoU: 0.476299\tvalidation's binary_logloss: 0.478834\tvalidation's IoU: 0.450685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.466721\ttrain's IoU: 0.476299\tvalidation's binary_logloss: 0.478834\tvalidation's IoU: 0.450685\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.700 (precision=0.8001, recall=0.1752)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=90, w_neg=1.0] TEST: IoU=0.165, Prec=0.806, Rec=0.172, F1=0.283, Thr=0.700\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w1.0.png\n",
      "[Saved model artifacts for NEG=90%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg090pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217390 -> initscore=-1.280942\n",
      "[LightGBM] [Info] Start training from score -1.280942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.404415\ttrain's IoU: 0.182548\tvalidation's binary_logloss: 0.535852\tvalidation's IoU: 0.176982\n",
      "[100]\ttrain's binary_logloss: 0.386679\ttrain's IoU: 0.244397\tvalidation's binary_logloss: 0.516955\tvalidation's IoU: 0.232491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.386679\ttrain's IoU: 0.244397\tvalidation's binary_logloss: 0.516955\tvalidation's IoU: 0.232491\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.536 (precision=0.8002, recall=0.1967)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=90, w_neg=2.0] TEST: IoU=0.185, Prec=0.797, Rec=0.194, F1=0.312, Thr=0.536\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w2.0.png\n",
      "[Saved model artifacts for NEG=90%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg090pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.156249 -> initscore=-1.686407\n",
      "[LightGBM] [Info] Start training from score -1.686407\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.340024\ttrain's IoU: 0.0771245\tvalidation's binary_logloss: 0.591117\tvalidation's IoU: 0.070187\n",
      "[100]\ttrain's binary_logloss: 0.325818\ttrain's IoU: 0.136323\tvalidation's binary_logloss: 0.570078\tvalidation's IoU: 0.124786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.325818\ttrain's IoU: 0.136323\tvalidation's binary_logloss: 0.570078\tvalidation's IoU: 0.124786\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.425 (precision=0.8001, recall=0.2224)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=90, w_neg=3.0] TEST: IoU=0.208, Prec=0.795, Rec=0.220, F1=0.345, Thr=0.425\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w3.0.png\n",
      "[Saved model artifacts for NEG=90%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg090pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099999 -> initscore=-2.197233\n",
      "[LightGBM] [Info] Start training from score -2.197233\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.260212\ttrain's IoU: 0.00644407\tvalidation's binary_logloss: 0.688904\tvalidation's IoU: 0.00509437\n",
      "[100]\ttrain's binary_logloss: 0.249908\ttrain's IoU: 0.0359532\tvalidation's binary_logloss: 0.663909\tvalidation's IoU: 0.0335275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.249908\ttrain's IoU: 0.0359532\tvalidation's binary_logloss: 0.663909\tvalidation's IoU: 0.0335275\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.303 (precision=0.8001, recall=0.2460)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=90, w_neg=5.0] TEST: IoU=0.226, Prec=0.790, Rec=0.241, F1=0.369, Thr=0.303\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w5.0.png\n",
      "[Saved model artifacts for NEG=90%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg090pct_w5\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 100% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 101,001\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.347807 -> initscore=-0.628693\n",
      "[LightGBM] [Info] Start training from score -0.628693\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.485917\ttrain's IoU: 0.413301\tvalidation's binary_logloss: 0.492194\tvalidation's IoU: 0.395111\n",
      "[100]\ttrain's binary_logloss: 0.463763\ttrain's IoU: 0.460246\tvalidation's binary_logloss: 0.475826\tvalidation's IoU: 0.432457\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.463763\ttrain's IoU: 0.460246\tvalidation's binary_logloss: 0.475826\tvalidation's IoU: 0.432457\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.691 (precision=0.8002, recall=0.1713)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=100, w_neg=1.0] TEST: IoU=0.159, Prec=0.798, Rec=0.165, F1=0.274, Thr=0.691\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w1.0.png\n",
      "[Saved model artifacts for NEG=100%, w=1] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg100pct_w1\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210512 -> initscore=-1.321840\n",
      "[LightGBM] [Info] Start training from score -1.321840\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.397472\ttrain's IoU: 0.163387\tvalidation's binary_logloss: 0.530341\tvalidation's IoU: 0.157162\n",
      "[100]\ttrain's binary_logloss: 0.38062\ttrain's IoU: 0.232469\tvalidation's binary_logloss: 0.512294\tvalidation's IoU: 0.218473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.38062\ttrain's IoU: 0.232469\tvalidation's binary_logloss: 0.512294\tvalidation's IoU: 0.218473\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.517 (precision=0.8001, recall=0.2094)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=100, w_neg=2.0] TEST: IoU=0.195, Prec=0.796, Rec=0.205, F1=0.326, Thr=0.517\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w2.0.png\n",
      "[Saved model artifacts for NEG=100%, w=2] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg100pct_w2\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.150933 -> initscore=-1.727305\n",
      "[LightGBM] [Info] Start training from score -1.727305\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.333127\ttrain's IoU: 0.0750584\tvalidation's binary_logloss: 0.584556\tvalidation's IoU: 0.0723945\n",
      "[100]\ttrain's binary_logloss: 0.319543\ttrain's IoU: 0.125938\tvalidation's binary_logloss: 0.564229\tvalidation's IoU: 0.11616\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.319543\ttrain's IoU: 0.125938\tvalidation's binary_logloss: 0.564229\tvalidation's IoU: 0.11616\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.425 (precision=0.8001, recall=0.2053)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=100, w_neg=3.0] TEST: IoU=0.193, Prec=0.801, Rec=0.203, F1=0.323, Thr=0.425\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w3.0.png\n",
      "[Saved model artifacts for NEG=100%, w=3] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg100pct_w3\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.096378 -> initscore=-2.238131\n",
      "[LightGBM] [Info] Start training from score -2.238131\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.25386\ttrain's IoU: 0.00443935\tvalidation's binary_logloss: 0.680853\tvalidation's IoU: 0.00359111\n",
      "[100]\ttrain's binary_logloss: 0.244324\ttrain's IoU: 0.0317702\tvalidation's binary_logloss: 0.658005\tvalidation's IoU: 0.0268222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.244324\ttrain's IoU: 0.0317702\tvalidation's binary_logloss: 0.658005\tvalidation's IoU: 0.0268222\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.319 (precision=0.8001, recall=0.1983)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[NEG%=100, w_neg=5.0] TEST: IoU=0.185, Prec=0.808, Rec=0.193, F1=0.312, Thr=0.319\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w5.0.png\n",
      "[Saved model artifacts for NEG=100%, w=5] -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/saved_model_neg100pct_w5\n",
      "\n",
      "Saved Option 2 global-test sweep summary to:\n",
      "/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/option2_neg_ratio_sweep_globaltest_metrics_pf08.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Option 2 (global fixed test set) â Penalize False Positives:\n",
    "- Read full cems_with_fraction_balanced.parquet\n",
    "- Build features, coerce to numeric, drop bad rows\n",
    "- Create a single global test set (10%), remaining 90% is train/val pool\n",
    "- Fix a positive sample set once\n",
    "- Sweep negative ratios (10..100%, where 100% = 2x positives)\n",
    "- For each neg% sweep, ALSO sweep negative class weights to penalize false positives\n",
    "- Train LightGBM (sklearn API)\n",
    "- Choose threshold on validation by maximizing RECALL subject to PRECISION â¥ PRECISION_FLOOR\n",
    "  (fall back to max precision if no point meets the floor)\n",
    "- Evaluate on the SAME fixed global test set\n",
    "- Save per (neg_percent, neg_class_weight):\n",
    "    - train/val parquet\n",
    "    - IoU learning curve PNG\n",
    "    - feature importance PNG\n",
    "    - model + metadata:\n",
    "        saved_model_neg{pct:03d}pct_w{w}/\n",
    "          - lgb_model_neg{pct:03d}pct_w{w}.txt\n",
    "          - lgb_sklearn_neg{pct:03d}pct_w{w}.pkl\n",
    "          - feature_importance_neg{pct:03d}pct_w{w}.csv\n",
    "          - model_meta_neg{pct:03d}pct_w{w}.json\n",
    "- Also save summary CSV across all sweeps\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    jaccard_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "PARQUET_IN    = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction.parquet\"\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "# Overall split: global test set (10%), rest train/val pool (90%)\n",
    "TEST_SIZE_GLOBAL = 0.10\n",
    "VAL_SIZE_OVERALL = 0.20   # overall val fraction of full dataset; derive inner val from this\n",
    "\n",
    "THRESH_INIT   = 0.50      # used for IoU logging metric\n",
    "RECALL_FLOOR  = 0.80      # legacy recall requirement (still printed)\n",
    "PRECISION_FLOOR = 0.80    # precision floor to penalize false positives\n",
    "\n",
    "TOP_N_IMPORT  = 30\n",
    "\n",
    "# Negative ratio sweep within the train/val pool:\n",
    "# 100% = 2x positives, 10% = 0.2x positives, etc.\n",
    "PCT_STEPS = list(range(10, 101, 10))\n",
    "\n",
    "# Optional: cap positives in train/val pool for speed (None = use all)\n",
    "MAX_SAMPLES_POS_TRAINVAL = None\n",
    "\n",
    "# Class-weight sweep to penalize negatives (false positives)\n",
    "USE_CLASS_WEIGHT = True\n",
    "NEG_CLASS_WEIGHT_SWEEP = [1.0, 2.0, 3.0, 5.0]  # try higher if precision is still low\n",
    "\n",
    "# LightGBM base params\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=48,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.75,\n",
    "    bagging_freq=5,\n",
    "    lambda_l2=2.0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Output root and option-specific dir\n",
    "OUT_ROOT = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest\"\n",
    "OUT_DIR  = os.path.join(OUT_ROOT, \"option2_scale_pos_weight_penalize_fp\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n=== OUTPUT DIRECTORY ===\")\n",
    "print(OUT_DIR)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD & EARLY CLEAN (ONCE)\n",
    "# =====================================================\n",
    "print(f\"\\nLoading: {PARQUET_IN}\")\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "\n",
    "if \"fraction\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'fraction' in dataset.\")\n",
    "\n",
    "df[\"fraction\"] = df[\"fraction\"].astype(\"float32\").clip(0.0, 1.0)\n",
    "before = len(df)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\").copy()\n",
    "print(f\"Dropped {before - len(df):,} rows with NaNs/Â±inf; {len(df):,} remain.\")\n",
    "\n",
    "# =====================================================\n",
    "# FRACTION -> BINARY\n",
    "# =====================================================\n",
    "df[\"burned\"] = (df[\"fraction\"] > THRESH_INIT).astype(np.uint8)\n",
    "\n",
    "print(\"\\nClass counts before any splitting:\")\n",
    "print(df[\"burned\"].value_counts(dropna=False))\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE MATRIX (GLOBAL) + TYPE COERCION\n",
    "# =====================================================\n",
    "drop_cols = {\"fraction\", \"burned\", \"bin\", \"year\", \"month\", \"latitude\", \"longitude\"}\n",
    "predictors = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X_full = df[predictors].copy()\n",
    "y_full = df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# Treat 'b1' as category if present\n",
    "if \"b1\" in X_full.columns and not pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "    X_full[\"b1\"] = X_full[\"b1\"].astype(\"category\")\n",
    "    print(\"\\nTreating 'b1' as pandas 'category'.\")\n",
    "\n",
    "# Coerce non-category columns to numeric and drop rows with NaNs\n",
    "coerced = 0\n",
    "for c in X_full.columns:\n",
    "    if c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        continue\n",
    "    if not np.issubdtype(X_full[c].dtype, np.number):\n",
    "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
    "        coerced += 1\n",
    "\n",
    "if coerced:\n",
    "    pre = len(X_full)\n",
    "    num_cols = [c for c in X_full.columns if not (c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]))]\n",
    "    mask = X_full[num_cols].notna().all(axis=1)\n",
    "    if \"b1\" in X_full.columns and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        mask &= X_full[\"b1\"].notna()\n",
    "    X_full = X_full.loc[mask].copy()\n",
    "    y_full = y_full.loc[X_full.index]\n",
    "    print(f\"Coerced {coerced} column(s); dropped {pre - len(X_full):,} rows post-coercion.\")\n",
    "\n",
    "print(f\"\\nPredictor columns: {len(X_full.columns)}\")\n",
    "\n",
    "# Combine into a single DataFrame for convenient splitting\n",
    "data = X_full.copy()\n",
    "data[\"burned\"] = y_full\n",
    "\n",
    "# Capture global categorical levels for 'b1' (for inference)\n",
    "b1_categories = None\n",
    "if \"b1\" in data.columns and pd.api.types.is_categorical_dtype(data[\"b1\"]):\n",
    "    b1_categories = list(data[\"b1\"].cat.categories.astype(str))\n",
    "\n",
    "# =====================================================\n",
    "# GLOBAL TRAINVAL / TEST SPLIT (FIXED TEST SET)\n",
    "# =====================================================\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    data.index,\n",
    "    test_size=TEST_SIZE_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[\"burned\"],\n",
    ")\n",
    "\n",
    "trainval = data.loc[idx_trainval].copy()\n",
    "test     = data.loc[idx_test].copy()\n",
    "\n",
    "print(\"\\nGlobal split sizes (true distribution in test):\")\n",
    "print(f\"  Train/Val pool: {len(trainval):,}\")\n",
    "print(f\"  Test (fixed)  : {len(test):,}\")\n",
    "print(\"\\nTest set class counts (true distribution):\")\n",
    "print(test[\"burned\"].value_counts())\n",
    "\n",
    "# Extract global test X, y\n",
    "X_test = test[predictors].copy()\n",
    "y_test = test[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# =====================================================\n",
    "# TRAIN/VAL POOL: POS/NEG SPLITTING BASE\n",
    "# =====================================================\n",
    "pos_tv = trainval[trainval[\"burned\"] == 1]\n",
    "neg_tv = trainval[trainval[\"burned\"] == 0]\n",
    "\n",
    "n_pos_tv = len(pos_tv)\n",
    "n_neg_tv = len(neg_tv)\n",
    "\n",
    "print(\"\\nTrain/Val pool class counts:\")\n",
    "print(trainval[\"burned\"].value_counts())\n",
    "\n",
    "if n_pos_tv == 0 or n_neg_tv == 0:\n",
    "    raise ValueError(\"Train/Val pool has only one class; cannot proceed.\")\n",
    "\n",
    "# Fix positive sample within train/val pool (optionally capped)\n",
    "target_pos = n_pos_tv\n",
    "if MAX_SAMPLES_POS_TRAINVAL is not None:\n",
    "    target_pos = min(target_pos, MAX_SAMPLES_POS_TRAINVAL)\n",
    "\n",
    "pos_tv_s = pos_tv.sample(n=min(n_pos_tv, target_pos), random_state=RANDOM_STATE)\n",
    "n_pos_eff = len(pos_tv_s)\n",
    "print(f\"\\nEffective positive samples in train/val sweeps: {n_pos_eff:,}\")\n",
    "\n",
    "# =====================================================\n",
    "# Custom IoU metric for logging (sklearn API)\n",
    "# =====================================================\n",
    "def lgb_iou_metric_skl(y_true, y_pred):\n",
    "    y_hat = (y_pred >= THRESH_INIT).astype(np.uint8)\n",
    "    iou = jaccard_score(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    return (\"IoU\", iou, True)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# =====================================================\n",
    "# SWEEP OVER NEGATIVE RATIOS IN TRAIN/VAL POOL\n",
    "# =====================================================\n",
    "for pct in PCT_STEPS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"== Option 2: NEGATIVE PERCENT = {pct}% (100% = 2x positives in TRAIN/VAL) ==\")\n",
    "\n",
    "    # 100% -> 2 * n_pos_eff\n",
    "    # 10%  -> 0.2 * n_pos_eff\n",
    "    neg_target = int(round((pct / 100.0) * 2.0 * n_pos_eff))\n",
    "    neg_target = max(1, min(neg_target, n_neg_tv))\n",
    "\n",
    "    print(f\"Target negatives for this sweep (from train/val pool): {neg_target:,}\")\n",
    "\n",
    "    neg_tv_s = neg_tv.sample(n=neg_target, random_state=RANDOM_STATE + pct)\n",
    "\n",
    "    sweep_df_base = (\n",
    "        pd.concat([pos_tv_s, neg_tv_s], axis=0)\n",
    "          .sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"Class counts in sweep base train/val dataset:\")\n",
    "    print(sweep_df_base[\"burned\"].value_counts())\n",
    "\n",
    "    # 70/20 of the *full dataset* corresponds to 70/20 out of (1 - TEST_SIZE_GLOBAL)\n",
    "    val_size_inner = VAL_SIZE_OVERALL / (1.0 - TEST_SIZE_GLOBAL)  # e.g., 0.20 / 0.90\n",
    "\n",
    "    # =====================================================\n",
    "    # NEGATIVE CLASS WEIGHT SWEEP (penalize FPs)\n",
    "    # =====================================================\n",
    "    for neg_w in NEG_CLASS_WEIGHT_SWEEP:\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(f\"[NEG%={pct}] Training with class_weight: {{0: {neg_w}, 1: 1.0}}\")\n",
    "\n",
    "        # copy to avoid any accidental in-place mutations\n",
    "        sweep_df = sweep_df_base.copy()\n",
    "\n",
    "        # Save sweep train/val parquet for traceability\n",
    "        parquet_out = os.path.join(\n",
    "            OUT_DIR, f\"trainval_data_neg{pct:03d}pct_w{neg_w}.parquet\"\n",
    "        )\n",
    "        sweep_df.to_parquet(parquet_out)\n",
    "        print(f\"Saved sweep train/val parquet: {parquet_out}\")\n",
    "\n",
    "        # Features / target for this sweep\n",
    "        X_sweep = sweep_df[predictors].copy()\n",
    "        y_sweep = sweep_df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_sweep,\n",
    "            y_sweep,\n",
    "            test_size=val_size_inner,\n",
    "            random_state=RANDOM_STATE,\n",
    "            stratify=y_sweep,\n",
    "        )\n",
    "\n",
    "        if USE_CLASS_WEIGHT:\n",
    "            model = lgb.LGBMClassifier(\n",
    "                **LGB_PARAMS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                class_weight={0: neg_w, 1: 1.0},  # penalize FP\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to original pos-weighting if desired\n",
    "            n_pos_train = int((y_train == 1).sum())\n",
    "            n_neg_train = int((y_train == 0).sum())\n",
    "            pos_weight = n_neg_train / max(1, n_pos_train)\n",
    "            model = lgb.LGBMClassifier(\n",
    "                **LGB_PARAMS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                scale_pos_weight=pos_weight,\n",
    "            )\n",
    "\n",
    "        evals_result = {}\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_names=[\"train\", \"validation\"],\n",
    "            eval_metric=[\"aucpr\", lgb_iou_metric_skl],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(period=50),\n",
    "                lgb.record_evaluation(evals_result),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ---------------- LEARNING CURVE: IoU (TRAIN vs VAL) ----------------\n",
    "        if \"IoU\" in evals_result.get(\"train\", {}):\n",
    "            train_iou_curve = evals_result[\"train\"][\"IoU\"]\n",
    "            val_iou_curve   = evals_result[\"validation\"][\"IoU\"]\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(train_iou_curve, label=\"Train IoU\")\n",
    "            plt.plot(val_iou_curve,   label=\"Validation IoU\")\n",
    "            plt.xlabel(\"Boosting Rounds\")\n",
    "            plt.ylabel(\"IoU (Jaccard)\")\n",
    "            plt.title(\n",
    "                f\"Train vs Val IoU\\nNEG={pct}% (100% = 2x pos), \"\n",
    "                f\"THRESH_INIT={THRESH_INIT:.2f}, w_neg={neg_w}\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            iou_fig_out = os.path.join(\n",
    "                OUT_DIR, f\"iou_curve_neg{pct:03d}pct_w{neg_w}.png\"\n",
    "            )\n",
    "            plt.savefig(iou_fig_out, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"Saved IoU learning curve: {iou_fig_out}\")\n",
    "\n",
    "        # ---------------- Threshold selection with a PRECISION FLOOR ----------------\n",
    "        y_val_proba = model.predict_proba(X_val, num_iteration=model.best_iteration_)[:, 1]\n",
    "        prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "\n",
    "        # Prefer thresholds that meet the precision floor; among them choose max recall\n",
    "        mask = prec[:-1] >= PRECISION_FLOOR\n",
    "        if np.any(mask):\n",
    "            best_idx_rel = np.argmax(rec[:-1][mask])\n",
    "            best_idx = np.flatnonzero(mask)[best_idx_rel]\n",
    "        else:\n",
    "            # If nothing meets the floor, fall back to global max precision\n",
    "            best_idx = np.argmax(prec[:-1])\n",
    "\n",
    "        best_thr = float(thr[best_idx])\n",
    "        print(\n",
    "            f\"Chosen threshold (PRECâ¥{PRECISION_FLOOR:.2f}): {best_thr:.3f} \"\n",
    "            f\"(precision={prec[best_idx]:.4f}, recall={rec[best_idx]:.4f})  \"\n",
    "            f\"[RECALL_FLOOR ref={RECALL_FLOOR:.2f}]\"\n",
    "        )\n",
    "\n",
    "        # ---------------- FINAL METRICS ON FIXED GLOBAL TEST SET ----------------\n",
    "        y_test_proba = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "        y_test_hat   = (y_test_proba >= best_thr).astype(np.uint8)\n",
    "\n",
    "        test_iou  = jaccard_score(y_test, y_test_hat, average=\"binary\", zero_division=0)\n",
    "        test_prec = precision_score(y_test, y_test_hat, zero_division=0)\n",
    "        test_rec  = recall_score(y_test, y_test_hat, zero_division=0)\n",
    "        test_f1   = f1_score(y_test, y_test_hat, zero_division=0)\n",
    "\n",
    "        best_iteration = int(model.best_iteration_ if hasattr(model, \"best_iteration_\") else -1)\n",
    "\n",
    "        print(\n",
    "            f\"[NEG%={pct}, w_neg={neg_w}] TEST: IoU={test_iou:.3f}, \"\n",
    "            f\"Prec={test_prec:.3f}, Rec={test_rec:.3f}, F1={test_f1:.3f}, Thr={best_thr:.3f}\"\n",
    "        )\n",
    "\n",
    "        summary_rows.append(\n",
    "            dict(\n",
    "                neg_percent=pct,\n",
    "                neg_class_weight=neg_w if USE_CLASS_WEIGHT else 1.0,\n",
    "                threshold=round(best_thr, 3),\n",
    "                test_iou=round(test_iou, 3),\n",
    "                test_precision=round(test_prec, 3),\n",
    "                test_recall=round(test_rec, 3),\n",
    "                test_f1=round(test_f1, 3),\n",
    "                best_iteration=best_iteration,\n",
    "                precision_floor=PRECISION_FLOOR,\n",
    "                recall_floor=RECALL_FLOOR,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # ---------------- FEATURE IMPORTANCE ----------------\n",
    "        gain_imp = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "        gain_imp = gain_imp / (gain_imp.sum() + 1e-12)\n",
    "        feat_names = np.array(X_train.columns)\n",
    "\n",
    "        order = np.argsort(gain_imp)[::-1][:TOP_N_IMPORT]\n",
    "        plt.figure(figsize=(9, max(5, 0.28 * len(order))))\n",
    "        plt.barh(feat_names[order][::-1], gain_imp[order][::-1])\n",
    "        plt.xlabel(\"Relative Gain Importance\")\n",
    "        plt.title(\n",
    "            f\"Feature Importance (Top {len(order)})\\nNEG={pct}% (100% = 2x pos), w_neg={neg_w}\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fi_fig_out = os.path.join(\n",
    "            OUT_DIR, f\"feature_importance_neg{pct:03d}pct_w{neg_w}.png\"\n",
    "        )\n",
    "        plt.savefig(fi_fig_out, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved feature importance plot: {fi_fig_out}\")\n",
    "\n",
    "        # ---------------- SAVE MODEL + METADATA FOR THIS COMBO ----------------\n",
    "        w_tag = int(round(float(neg_w)))\n",
    "        save_dir = os.path.join(\n",
    "            OUT_DIR, f\"saved_model_neg{pct:03d}pct_w{w_tag}\"\n",
    "        )\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Booster text\n",
    "        booster_txt = os.path.join(\n",
    "            save_dir, f\"lgb_model_neg{pct:03d}pct_w{w_tag}.txt\"\n",
    "        )\n",
    "        model.booster_.save_model(booster_txt)\n",
    "\n",
    "        # Sklearn wrapper\n",
    "        model_pkl = os.path.join(\n",
    "            save_dir, f\"lgb_sklearn_neg{pct:03d}pct_w{w_tag}.pkl\"\n",
    "        )\n",
    "        joblib.dump(model, model_pkl)\n",
    "\n",
    "        # Feature importance CSV\n",
    "        fi_csv = os.path.join(\n",
    "            save_dir, f\"feature_importance_neg{pct:03d}pct_w{w_tag}.csv\"\n",
    "        )\n",
    "        pd.DataFrame({\n",
    "            \"feature\": feat_names[order],\n",
    "            \"gain_importance\": gain_imp[order]\n",
    "        }).to_csv(fi_csv, index=False)\n",
    "\n",
    "        # Metadata JSON\n",
    "        meta = {\n",
    "            \"option\": 2,\n",
    "            \"neg_percent\": int(pct),\n",
    "            \"neg_class_weight\": float(neg_w),\n",
    "            \"threshold\": round(float(best_thr), 6),\n",
    "            \"metrics_test\": {\n",
    "                \"iou\": round(float(test_iou), 4),\n",
    "                \"precision\": round(float(test_prec), 4),\n",
    "                \"recall\": round(float(test_rec), 4),\n",
    "                \"f1\": round(float(test_f1), 4)\n",
    "            },\n",
    "            \"best_iteration\": best_iteration,\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"precision_floor\": PRECISION_FLOOR,\n",
    "            \"recall_floor\": RECALL_FLOOR,\n",
    "            \"thresh_init_for_logging\": THRESH_INIT,\n",
    "            \"predictors\": predictors,\n",
    "            \"categorical\": {\n",
    "                \"b1_categories\": b1_categories\n",
    "            },\n",
    "            \"paths\": {\n",
    "                \"booster_txt\": booster_txt,\n",
    "                \"sklearn_pkl\": model_pkl,\n",
    "                \"feature_importance_csv\": fi_csv\n",
    "            }\n",
    "        }\n",
    "\n",
    "        meta_json = os.path.join(\n",
    "            save_dir, f\"model_meta_neg{pct:03d}pct_w{w_tag}.json\"\n",
    "        )\n",
    "        with open(meta_json, \"w\") as f:\n",
    "            json.dump(meta, f, indent=2)\n",
    "\n",
    "        print(f\"[Saved model artifacts for NEG={pct}%, w={w_tag}] -> {save_dir}\")\n",
    "\n",
    "# =====================================================\n",
    "# SAVE SUMMARY CSV (rounded metrics)\n",
    "# =====================================================\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv = os.path.join(\n",
    "        OUT_DIR, f\"option2_neg_ratio_sweep_globaltest_metrics_pf{str(PRECISION_FLOOR).replace('.', '')}.csv\"\n",
    "    )\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSaved Option 2 global-test sweep summary to:\\n{summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo sweeps were run; summary not saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc2d7b6-5b3c-439e-9011-3bf0286c6ea3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTPUT DIRECTORY ===\n",
      "/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp\n",
      "\n",
      "Loading: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction_balanced.parquet\n",
      "Dropped 0 rows with NaNs/Â±inf; 172,072 remain.\n",
      "\n",
      "Class counts before any splitting:\n",
      "0    112224\n",
      "1     59848\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Treating 'b1' as pandas 'category'.\n",
      "\n",
      "Predictor columns: 15\n",
      "\n",
      "Global split sizes (true distribution in test):\n",
      "  Train/Val pool: 154,864\n",
      "  Test (fixed)  : 17,208\n",
      "\n",
      "Test set class counts (true distribution):\n",
      "0    11223\n",
      "1     5985\n",
      "Name: burned, dtype: int64\n",
      "[SAVE] y_test -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test.npy\n",
      "\n",
      "Train/Val pool class counts:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Effective positive samples in train/val sweeps: 53,863\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 10% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 10,773\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    10773\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.833327 -> initscore=1.609390\n",
      "[LightGBM] [Info] Start training from score 1.609390\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.312667\ttrain's IoU: 0.878394\tvalidation's binary_logloss: 0.33238\tvalidation's IoU: 0.874669\n",
      "[100]\ttrain's binary_logloss: 0.291151\ttrain's IoU: 0.882799\tvalidation's binary_logloss: 0.324587\tvalidation's IoU: 0.876995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.291151\ttrain's IoU: 0.882799\tvalidation's binary_logloss: 0.324587\tvalidation's IoU: 0.876995\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.008 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg010_w1.0.npy\n",
      "[NEG%=10, w_neg=1.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.008\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.714276 -> initscore=0.916243\n",
      "[LightGBM] [Info] Start training from score 0.916243\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.417412\ttrain's IoU: 0.877423\tvalidation's binary_logloss: 0.358709\tvalidation's IoU: 0.871583\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttrain's binary_logloss: 0.47191\ttrain's IoU: 0.874681\tvalidation's binary_logloss: 0.395772\tvalidation's IoU: 0.873244\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.290 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg010_w2.0.npy\n",
      "[NEG%=10, w_neg=2.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.290\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624989 -> initscore=0.510778\n",
      "[LightGBM] [Info] Start training from score 0.510778\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.464275\ttrain's IoU: 0.865112\tvalidation's binary_logloss: 0.402302\tvalidation's IoU: 0.85478\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttrain's binary_logloss: 0.578427\ttrain's IoU: 0.873436\tvalidation's binary_logloss: 0.491062\tvalidation's IoU: 0.872219\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.419 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg010_w3.0.npy\n",
      "[NEG%=10, w_neg=3.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.419\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=10] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg010pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 8379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3658\n",
      "[LightGBM] [Info] Number of data points in the train set: 50272, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499988 -> initscore=-0.000048\n",
      "[LightGBM] [Info] Start training from score -0.000048\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.491681\ttrain's IoU: 0.796687\tvalidation's binary_logloss: 0.492728\tvalidation's IoU: 0.776944\n",
      "[100]\ttrain's binary_logloss: 0.453334\ttrain's IoU: 0.810593\tvalidation's binary_logloss: 0.467654\tvalidation's IoU: 0.785415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.453334\ttrain's IoU: 0.810593\tvalidation's binary_logloss: 0.467654\tvalidation's IoU: 0.785415\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg010pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.005 (precision=0.8333, recall=1.0000)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg010_w5.0.npy\n",
      "[NEG%=10, w_neg=5.0] TEST: IoU=0.348, Prec=0.348, Rec=1.000, F1=0.516, Thr=0.005\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg010pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 20% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 21,545\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    21545\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.714288 -> initscore=0.916303\n",
      "[LightGBM] [Info] Start training from score 0.916303\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.425104\ttrain's IoU: 0.793313\tvalidation's binary_logloss: 0.440951\tvalidation's IoU: 0.789144\n",
      "[100]\ttrain's binary_logloss: 0.400091\ttrain's IoU: 0.802163\tvalidation's binary_logloss: 0.428102\tvalidation's IoU: 0.789527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.400091\ttrain's IoU: 0.802163\tvalidation's binary_logloss: 0.428102\tvalidation's IoU: 0.789527\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.414 (precision=0.8000, recall=0.9843)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg020_w1.0.npy\n",
      "[NEG%=20, w_neg=1.0] TEST: IoU=0.457, Prec=0.462, Rec=0.980, F1=0.628, Thr=0.414\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555559 -> initscore=0.223155\n",
      "[LightGBM] [Info] Start training from score 0.223155\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.495306\ttrain's IoU: 0.775199\tvalidation's binary_logloss: 0.479492\tvalidation's IoU: 0.75979\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttrain's binary_logloss: 0.621262\ttrain's IoU: 0.784119\tvalidation's binary_logloss: 0.591681\tvalidation's IoU: 0.782827\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.503 (precision=0.8000, recall=0.9728)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg020_w2.0.npy\n",
      "[NEG%=20, w_neg=2.0] TEST: IoU=0.456, Prec=0.462, Rec=0.971, F1=0.626, Thr=0.503\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454548 -> initscore=-0.182310\n",
      "[LightGBM] [Info] Start training from score -0.182310\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.502348\ttrain's IoU: 0.70028\tvalidation's binary_logloss: 0.538316\tvalidation's IoU: 0.674533\n",
      "[100]\ttrain's binary_logloss: 0.471344\ttrain's IoU: 0.726745\tvalidation's binary_logloss: 0.516278\tvalidation's IoU: 0.688704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.471344\ttrain's IoU: 0.726745\tvalidation's binary_logloss: 0.516278\tvalidation's IoU: 0.688704\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.218 (precision=0.8000, recall=0.9814)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg020_w3.0.npy\n",
      "[NEG%=20, w_neg=3.0] TEST: IoU=0.457, Prec=0.462, Rec=0.978, F1=0.627, Thr=0.218\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=20] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg020pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 16757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3659\n",
      "[LightGBM] [Info] Number of data points in the train set: 58650, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333336 -> initscore=-0.693135\n",
      "[LightGBM] [Info] Start training from score -0.693135\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.471405\ttrain's IoU: 0.484703\tvalidation's binary_logloss: 0.654952\tvalidation's IoU: 0.460149\n",
      "[100]\ttrain's binary_logloss: 0.442236\ttrain's IoU: 0.556216\tvalidation's binary_logloss: 0.623806\tvalidation's IoU: 0.517504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.442236\ttrain's IoU: 0.556216\tvalidation's binary_logloss: 0.623806\tvalidation's IoU: 0.517504\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg020pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.150 (precision=0.8000, recall=0.9821)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg020_w5.0.npy\n",
      "[NEG%=20, w_neg=5.0] TEST: IoU=0.456, Prec=0.461, Rec=0.977, F1=0.626, Thr=0.150\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg020pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 30% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 32,318\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    32318\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.624998 -> initscore=0.510818\n",
      "[LightGBM] [Info] Start training from score 0.510818\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.476096\ttrain's IoU: 0.730202\tvalidation's binary_logloss: 0.492316\tvalidation's IoU: 0.717233\n",
      "[100]\ttrain's binary_logloss: 0.450173\ttrain's IoU: 0.73771\tvalidation's binary_logloss: 0.477307\tvalidation's IoU: 0.719861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.450173\ttrain's IoU: 0.73771\tvalidation's binary_logloss: 0.477307\tvalidation's IoU: 0.719861\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.629 (precision=0.8000, recall=0.8219)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg030_w1.0.npy\n",
      "[NEG%=30, w_neg=1.0] TEST: IoU=0.502, Prec=0.564, Rec=0.821, F1=0.669, Thr=0.629\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454543 -> initscore=-0.182330\n",
      "[LightGBM] [Info] Start training from score -0.182330\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.505212\ttrain's IoU: 0.661583\tvalidation's binary_logloss: 0.534636\tvalidation's IoU: 0.643529\n",
      "[100]\ttrain's binary_logloss: 0.477319\ttrain's IoU: 0.682656\tvalidation's binary_logloss: 0.516111\tvalidation's IoU: 0.652257\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.477319\ttrain's IoU: 0.682656\tvalidation's binary_logloss: 0.516111\tvalidation's IoU: 0.652257\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.470 (precision=0.8000, recall=0.8104)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg030_w2.0.npy\n",
      "[NEG%=30, w_neg=2.0] TEST: IoU=0.502, Prec=0.567, Rec=0.813, F1=0.668, Thr=0.470\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357141 -> initscore=-0.587795\n",
      "[LightGBM] [Info] Start training from score -0.587795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.484024\ttrain's IoU: 0.507906\tvalidation's binary_logloss: 0.597955\tvalidation's IoU: 0.480278\n",
      "[100]\ttrain's binary_logloss: 0.458087\ttrain's IoU: 0.565049\tvalidation's binary_logloss: 0.575646\tvalidation's IoU: 0.5306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.458087\ttrain's IoU: 0.565049\tvalidation's binary_logloss: 0.575646\tvalidation's IoU: 0.5306\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.370 (precision=0.8000, recall=0.8143)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg030_w3.0.npy\n",
      "[NEG%=30, w_neg=3.0] TEST: IoU=0.504, Prec=0.566, Rec=0.820, F1=0.670, Thr=0.370\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=30] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg030pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 25136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3665\n",
      "[LightGBM] [Info] Number of data points in the train set: 67029, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.249999 -> initscore=-1.098620\n",
      "[LightGBM] [Info] Start training from score -1.098620\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.424891\ttrain's IoU: 0.27894\tvalidation's binary_logloss: 0.719065\tvalidation's IoU: 0.260353\n",
      "[100]\ttrain's binary_logloss: 0.402903\ttrain's IoU: 0.353057\tvalidation's binary_logloss: 0.6903\tvalidation's IoU: 0.324326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.402903\ttrain's IoU: 0.353057\tvalidation's binary_logloss: 0.6903\tvalidation's IoU: 0.324326\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg030pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.267 (precision=0.8000, recall=0.8048)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg030_w5.0.npy\n",
      "[NEG%=30, w_neg=5.0] TEST: IoU=0.501, Prec=0.568, Rec=0.810, F1=0.668, Thr=0.267\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg030pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 40% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 43,090\n",
      "Class counts in sweep base train/val dataset:\n",
      "1    53863\n",
      "0    43090\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.555559 -> initscore=0.223155\n",
      "[LightGBM] [Info] Start training from score 0.223155\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.500125\ttrain's IoU: 0.674971\tvalidation's binary_logloss: 0.512931\tvalidation's IoU: 0.660163\n",
      "[100]\ttrain's binary_logloss: 0.473772\ttrain's IoU: 0.684949\tvalidation's binary_logloss: 0.496627\tvalidation's IoU: 0.665042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.473772\ttrain's IoU: 0.684949\tvalidation's binary_logloss: 0.496627\tvalidation's IoU: 0.665042\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.677 (precision=0.8000, recall=0.6166)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg040_w1.0.npy\n",
      "[NEG%=40, w_neg=1.0] TEST: IoU=0.460, Prec=0.641, Rec=0.620, F1=0.630, Thr=0.677\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384618 -> initscore=-0.469992\n",
      "[LightGBM] [Info] Start training from score -0.469992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.49571\ttrain's IoU: 0.540988\tvalidation's binary_logloss: 0.556202\tvalidation's IoU: 0.521789\n",
      "[100]\ttrain's binary_logloss: 0.469726\ttrain's IoU: 0.588622\tvalidation's binary_logloss: 0.536023\tvalidation's IoU: 0.555516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.469726\ttrain's IoU: 0.588622\tvalidation's binary_logloss: 0.536023\tvalidation's IoU: 0.555516\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.519 (precision=0.8001, recall=0.6108)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg040_w2.0.npy\n",
      "[NEG%=40, w_neg=2.0] TEST: IoU=0.457, Prec=0.642, Rec=0.613, F1=0.627, Thr=0.519\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294120 -> initscore=-0.875457\n",
      "[LightGBM] [Info] Start training from score -0.875457\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.4572\ttrain's IoU: 0.355822\tvalidation's binary_logloss: 0.619887\tvalidation's IoU: 0.344819\n",
      "[100]\ttrain's binary_logloss: 0.434368\ttrain's IoU: 0.433483\tvalidation's binary_logloss: 0.596436\tvalidation's IoU: 0.410288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.434368\ttrain's IoU: 0.433483\tvalidation's binary_logloss: 0.596436\tvalidation's IoU: 0.410288\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.414 (precision=0.8000, recall=0.6239)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg040_w3.0.npy\n",
      "[NEG%=40, w_neg=3.0] TEST: IoU=0.459, Prec=0.637, Rec=0.621, F1=0.629, Thr=0.414\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=40] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg040pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 33514\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 75407, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200002 -> initscore=-1.386282\n",
      "[LightGBM] [Info] Start training from score -1.386282\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.384899\ttrain's IoU: 0.159674\tvalidation's binary_logloss: 0.740245\tvalidation's IoU: 0.151838\n",
      "[100]\ttrain's binary_logloss: 0.366499\ttrain's IoU: 0.230307\tvalidation's binary_logloss: 0.710695\tvalidation's IoU: 0.218541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.366499\ttrain's IoU: 0.230307\tvalidation's binary_logloss: 0.710695\tvalidation's IoU: 0.218541\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg040pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.299 (precision=0.8000, recall=0.6260)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg040_w5.0.npy\n",
      "[NEG%=40, w_neg=5.0] TEST: IoU=0.460, Prec=0.635, Rec=0.625, F1=0.630, Thr=0.299\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg040pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 50% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 53,863\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    53863\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.507913\ttrain's IoU: 0.624373\tvalidation's binary_logloss: 0.516911\tvalidation's IoU: 0.615621\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.482193\ttrain's IoU: 0.638657\tvalidation's binary_logloss: 0.498956\tvalidation's IoU: 0.620368\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.678 (precision=0.8000, recall=0.5007)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg050_w1.0.npy\n",
      "[NEG%=50, w_neg=1.0] TEST: IoU=0.400, Prec=0.680, Rec=0.493, F1=0.571, Thr=0.678\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.478066\ttrain's IoU: 0.437838\tvalidation's binary_logloss: 0.560591\tvalidation's IoU: 0.422161\n",
      "[100]\ttrain's binary_logloss: 0.454367\ttrain's IoU: 0.500032\tvalidation's binary_logloss: 0.539757\tvalidation's IoU: 0.473873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.454367\ttrain's IoU: 0.500032\tvalidation's binary_logloss: 0.539757\tvalidation's IoU: 0.473873\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.516 (precision=0.8001, recall=0.5081)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg050_w2.0.npy\n",
      "[NEG%=50, w_neg=2.0] TEST: IoU=0.410, Prec=0.683, Rec=0.506, F1=0.582, Thr=0.516\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.250000 -> initscore=-1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.428734\ttrain's IoU: 0.257159\tvalidation's binary_logloss: 0.623652\tvalidation's IoU: 0.253143\n",
      "[100]\ttrain's binary_logloss: 0.408386\ttrain's IoU: 0.33467\tvalidation's binary_logloss: 0.599952\tvalidation's IoU: 0.320446\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.408386\ttrain's IoU: 0.33467\tvalidation's binary_logloss: 0.599952\tvalidation's IoU: 0.320446\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.412 (precision=0.8001, recall=0.5195)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg050_w3.0.npy\n",
      "[NEG%=50, w_neg=3.0] TEST: IoU=0.412, Prec=0.680, Rec=0.512, F1=0.584, Thr=0.412\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=50] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg050pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166667 -> initscore=-1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.350387\ttrain's IoU: 0.0912944\tvalidation's binary_logloss: 0.740613\tvalidation's IoU: 0.0875477\n",
      "[100]\ttrain's binary_logloss: 0.334409\ttrain's IoU: 0.157414\tvalidation's binary_logloss: 0.712321\tvalidation's IoU: 0.146518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.334409\ttrain's IoU: 0.157414\tvalidation's binary_logloss: 0.712321\tvalidation's IoU: 0.146518\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg050pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.297 (precision=0.8000, recall=0.5253)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg050_w5.0.npy\n",
      "[NEG%=50, w_neg=5.0] TEST: IoU=0.418, Prec=0.681, Rec=0.519, F1=0.589, Thr=0.297\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg050pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 60% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 64,636\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    64636\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.454543 -> initscore=-0.182330\n",
      "[LightGBM] [Info] Start training from score -0.182330\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.508943\ttrain's IoU: 0.576704\tvalidation's binary_logloss: 0.519326\tvalidation's IoU: 0.559007\n",
      "[100]\ttrain's binary_logloss: 0.484167\ttrain's IoU: 0.594797\tvalidation's binary_logloss: 0.502782\tvalidation's IoU: 0.569416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.484167\ttrain's IoU: 0.594797\tvalidation's binary_logloss: 0.502782\tvalidation's IoU: 0.569416\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.701 (precision=0.8000, recall=0.3439)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg060_w1.0.npy\n",
      "[NEG%=60, w_neg=1.0] TEST: IoU=0.303, Prec=0.734, Rec=0.340, F1=0.465, Thr=0.701\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294116 -> initscore=-0.875477\n",
      "[LightGBM] [Info] Start training from score -0.875477\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.45902\ttrain's IoU: 0.344018\tvalidation's binary_logloss: 0.560621\tvalidation's IoU: 0.333485\n",
      "[100]\ttrain's binary_logloss: 0.43732\ttrain's IoU: 0.416111\tvalidation's binary_logloss: 0.541359\tvalidation's IoU: 0.390383\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.43732\ttrain's IoU: 0.416111\tvalidation's binary_logloss: 0.541359\tvalidation's IoU: 0.390383\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.538 (precision=0.8000, recall=0.3609)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg060_w2.0.npy\n",
      "[NEG%=60, w_neg=2.0] TEST: IoU=0.313, Prec=0.735, Rec=0.353, F1=0.477, Thr=0.538\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217390 -> initscore=-1.280942\n",
      "[LightGBM] [Info] Start training from score -1.280942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.402913\ttrain's IoU: 0.183958\tvalidation's binary_logloss: 0.621164\tvalidation's IoU: 0.185766\n",
      "[100]\ttrain's binary_logloss: 0.384573\ttrain's IoU: 0.260119\tvalidation's binary_logloss: 0.599078\tvalidation's IoU: 0.248031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.384573\ttrain's IoU: 0.260119\tvalidation's binary_logloss: 0.599078\tvalidation's IoU: 0.248031\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.431 (precision=0.8001, recall=0.3835)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg060_w3.0.npy\n",
      "[NEG%=60, w_neg=3.0] TEST: IoU=0.328, Prec=0.728, Rec=0.373, F1=0.494, Thr=0.431\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=60] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg060pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 50272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 92165, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142856 -> initscore=-1.791767\n",
      "[LightGBM] [Info] Start training from score -1.791767\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.321792\ttrain's IoU: 0.0633507\tvalidation's binary_logloss: 0.732169\tvalidation's IoU: 0.06193\n",
      "[100]\ttrain's binary_logloss: 0.307898\ttrain's IoU: 0.116132\tvalidation's binary_logloss: 0.705831\tvalidation's IoU: 0.110709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.307898\ttrain's IoU: 0.116132\tvalidation's binary_logloss: 0.705831\tvalidation's IoU: 0.110709\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg060pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.318 (precision=0.8000, recall=0.3803)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg060_w5.0.npy\n",
      "[NEG%=60, w_neg=5.0] TEST: IoU=0.332, Prec=0.735, Rec=0.377, F1=0.498, Thr=0.318\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg060pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 70% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 75,408\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    75408\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.416663 -> initscore=-0.336486\n",
      "[LightGBM] [Info] Start training from score -0.336486\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.504044\ttrain's IoU: 0.529569\tvalidation's binary_logloss: 0.513944\tvalidation's IoU: 0.510898\n",
      "[100]\ttrain's binary_logloss: 0.48035\ttrain's IoU: 0.553552\tvalidation's binary_logloss: 0.497136\tvalidation's IoU: 0.530004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.48035\ttrain's IoU: 0.553552\tvalidation's binary_logloss: 0.497136\tvalidation's IoU: 0.530004\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.696 (precision=0.8001, recall=0.2792)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg070_w1.0.npy\n",
      "[NEG%=70, w_neg=1.0] TEST: IoU=0.253, Prec=0.757, Rec=0.276, F1=0.404, Thr=0.696\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.263155 -> initscore=-1.029633\n",
      "[LightGBM] [Info] Start training from score -1.029633\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.438632\ttrain's IoU: 0.276565\tvalidation's binary_logloss: 0.55393\tvalidation's IoU: 0.264587\n",
      "[100]\ttrain's binary_logloss: 0.418494\ttrain's IoU: 0.35274\tvalidation's binary_logloss: 0.533818\tvalidation's IoU: 0.330532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.418494\ttrain's IoU: 0.35274\tvalidation's binary_logloss: 0.533818\tvalidation's IoU: 0.330532\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.529 (precision=0.8001, recall=0.3123)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg070_w2.0.npy\n",
      "[NEG%=70, w_neg=2.0] TEST: IoU=0.283, Prec=0.761, Rec=0.310, F1=0.441, Thr=0.529\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.192306 -> initscore=-1.435098\n",
      "[LightGBM] [Info] Start training from score -1.435098\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.378844\ttrain's IoU: 0.140837\tvalidation's binary_logloss: 0.612792\tvalidation's IoU: 0.137611\n",
      "[100]\ttrain's binary_logloss: 0.362398\ttrain's IoU: 0.206282\tvalidation's binary_logloss: 0.590272\tvalidation's IoU: 0.200322\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.362398\ttrain's IoU: 0.206282\tvalidation's binary_logloss: 0.590272\tvalidation's IoU: 0.200322\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.438 (precision=0.8000, recall=0.3038)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg070_w3.0.npy\n",
      "[NEG%=70, w_neg=3.0] TEST: IoU=0.274, Prec=0.762, Rec=0.300, F1=0.430, Thr=0.438\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=70] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg070pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 58651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 100544, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.124999 -> initscore=-1.945924\n",
      "[LightGBM] [Info] Start training from score -1.945924\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.297211\ttrain's IoU: 0.0412523\tvalidation's binary_logloss: 0.719138\tvalidation's IoU: 0.0405124\n",
      "[100]\ttrain's binary_logloss: 0.285068\ttrain's IoU: 0.0877392\tvalidation's binary_logloss: 0.692039\tvalidation's IoU: 0.0801158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.285068\ttrain's IoU: 0.0877392\tvalidation's binary_logloss: 0.692039\tvalidation's IoU: 0.0801158\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg070pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.314 (precision=0.8000, recall=0.3308)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg070_w5.0.npy\n",
      "[NEG%=70, w_neg=5.0] TEST: IoU=0.295, Prec=0.759, Rec=0.326, F1=0.456, Thr=0.314\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg070pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 80% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 86,181\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    86181\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.384611 -> initscore=-0.470022\n",
      "[LightGBM] [Info] Start training from score -0.470022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.496954\ttrain's IoU: 0.484719\tvalidation's binary_logloss: 0.507188\tvalidation's IoU: 0.462457\n",
      "[100]\ttrain's binary_logloss: 0.472908\ttrain's IoU: 0.51571\tvalidation's binary_logloss: 0.490378\tvalidation's IoU: 0.487683\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.472908\ttrain's IoU: 0.51571\tvalidation's binary_logloss: 0.490378\tvalidation's IoU: 0.487683\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.699 (precision=0.8001, recall=0.2183)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg080_w1.0.npy\n",
      "[NEG%=80, w_neg=1.0] TEST: IoU=0.203, Prec=0.784, Rec=0.215, F1=0.337, Thr=0.699\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238092 -> initscore=-1.163169\n",
      "[LightGBM] [Info] Start training from score -1.163169\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.420106\ttrain's IoU: 0.217661\tvalidation's binary_logloss: 0.545988\tvalidation's IoU: 0.212627\n",
      "[100]\ttrain's binary_logloss: 0.400958\ttrain's IoU: 0.295423\tvalidation's binary_logloss: 0.527386\tvalidation's IoU: 0.278857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.400958\ttrain's IoU: 0.295423\tvalidation's binary_logloss: 0.527386\tvalidation's IoU: 0.278857\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.536 (precision=0.8000, recall=0.2379)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg080_w2.0.npy\n",
      "[NEG%=80, w_neg=2.0] TEST: IoU=0.221, Prec=0.782, Rec=0.235, F1=0.361, Thr=0.536\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.172411 -> initscore=-1.568634\n",
      "[LightGBM] [Info] Start training from score -1.568634\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.357789\ttrain's IoU: 0.100665\tvalidation's binary_logloss: 0.603483\tvalidation's IoU: 0.0954255\n",
      "[100]\ttrain's binary_logloss: 0.342489\ttrain's IoU: 0.160708\tvalidation's binary_logloss: 0.582745\tvalidation's IoU: 0.150125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.342489\ttrain's IoU: 0.160708\tvalidation's binary_logloss: 0.582745\tvalidation's IoU: 0.150125\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.439 (precision=0.8001, recall=0.2414)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg080_w3.0.npy\n",
      "[NEG%=80, w_neg=3.0] TEST: IoU=0.223, Prec=0.785, Rec=0.238, F1=0.365, Thr=0.439\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=80] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg080pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 67030\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 108923, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.111109 -> initscore=-2.079459\n",
      "[LightGBM] [Info] Start training from score -2.079459\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.276991\ttrain's IoU: 0.0173787\tvalidation's binary_logloss: 0.705097\tvalidation's IoU: 0.014663\n",
      "[100]\ttrain's binary_logloss: 0.265808\ttrain's IoU: 0.06056\tvalidation's binary_logloss: 0.680637\tvalidation's IoU: 0.0549896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.265808\ttrain's IoU: 0.06056\tvalidation's binary_logloss: 0.680637\tvalidation's IoU: 0.0549896\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg080pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.319 (precision=0.8000, recall=0.2613)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg080_w5.0.npy\n",
      "[NEG%=80, w_neg=5.0] TEST: IoU=0.240, Prec=0.784, Rec=0.256, F1=0.387, Thr=0.319\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg080pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 90% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 96,953\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    96953\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.357141 -> initscore=-0.587795\n",
      "[LightGBM] [Info] Start training from score -0.587795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.490284\ttrain's IoU: 0.428068\tvalidation's binary_logloss: 0.496384\tvalidation's IoU: 0.415469\n",
      "[100]\ttrain's binary_logloss: 0.466721\ttrain's IoU: 0.476299\tvalidation's binary_logloss: 0.478834\tvalidation's IoU: 0.450685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.466721\ttrain's IoU: 0.476299\tvalidation's binary_logloss: 0.478834\tvalidation's IoU: 0.450685\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.700 (precision=0.8001, recall=0.1752)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg090_w1.0.npy\n",
      "[NEG%=90, w_neg=1.0] TEST: IoU=0.165, Prec=0.806, Rec=0.172, F1=0.283, Thr=0.700\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.217390 -> initscore=-1.280942\n",
      "[LightGBM] [Info] Start training from score -1.280942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.404415\ttrain's IoU: 0.182548\tvalidation's binary_logloss: 0.535852\tvalidation's IoU: 0.176982\n",
      "[100]\ttrain's binary_logloss: 0.386679\ttrain's IoU: 0.244397\tvalidation's binary_logloss: 0.516955\tvalidation's IoU: 0.232491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.386679\ttrain's IoU: 0.244397\tvalidation's binary_logloss: 0.516955\tvalidation's IoU: 0.232491\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.536 (precision=0.8002, recall=0.1967)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg090_w2.0.npy\n",
      "[NEG%=90, w_neg=2.0] TEST: IoU=0.185, Prec=0.797, Rec=0.194, F1=0.312, Thr=0.536\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.156249 -> initscore=-1.686407\n",
      "[LightGBM] [Info] Start training from score -1.686407\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.340024\ttrain's IoU: 0.0771245\tvalidation's binary_logloss: 0.591117\tvalidation's IoU: 0.070187\n",
      "[100]\ttrain's binary_logloss: 0.325818\ttrain's IoU: 0.136323\tvalidation's binary_logloss: 0.570078\tvalidation's IoU: 0.124786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.325818\ttrain's IoU: 0.136323\tvalidation's binary_logloss: 0.570078\tvalidation's IoU: 0.124786\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.425 (precision=0.8001, recall=0.2224)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg090_w3.0.npy\n",
      "[NEG%=90, w_neg=3.0] TEST: IoU=0.208, Prec=0.795, Rec=0.220, F1=0.345, Thr=0.425\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=90] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg090pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 75408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 117301, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099999 -> initscore=-2.197233\n",
      "[LightGBM] [Info] Start training from score -2.197233\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.260212\ttrain's IoU: 0.00644407\tvalidation's binary_logloss: 0.688904\tvalidation's IoU: 0.00509437\n",
      "[100]\ttrain's binary_logloss: 0.249908\ttrain's IoU: 0.0359532\tvalidation's binary_logloss: 0.663909\tvalidation's IoU: 0.0335275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.249908\ttrain's IoU: 0.0359532\tvalidation's binary_logloss: 0.663909\tvalidation's IoU: 0.0335275\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg090pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.303 (precision=0.8001, recall=0.2460)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg090_w5.0.npy\n",
      "[NEG%=90, w_neg=5.0] TEST: IoU=0.226, Prec=0.790, Rec=0.241, F1=0.369, Thr=0.303\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg090pct_w5.0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 2: NEGATIVE PERCENT = 100% (100% = 2x positives in TRAIN/VAL) ==\n",
      "Target negatives for this sweep (from train/val pool): 101,001\n",
      "Class counts in sweep base train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 1.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w1.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.347807 -> initscore=-0.628693\n",
      "[LightGBM] [Info] Start training from score -0.628693\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.485917\ttrain's IoU: 0.413301\tvalidation's binary_logloss: 0.492194\tvalidation's IoU: 0.395111\n",
      "[100]\ttrain's binary_logloss: 0.463763\ttrain's IoU: 0.460246\tvalidation's binary_logloss: 0.475826\tvalidation's IoU: 0.432457\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.463763\ttrain's IoU: 0.460246\tvalidation's binary_logloss: 0.475826\tvalidation's IoU: 0.432457\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w1.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.691 (precision=0.8002, recall=0.1713)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg100_w1.0.npy\n",
      "[NEG%=100, w_neg=1.0] TEST: IoU=0.159, Prec=0.798, Rec=0.165, F1=0.274, Thr=0.691\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w1.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 2.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w2.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.210512 -> initscore=-1.321840\n",
      "[LightGBM] [Info] Start training from score -1.321840\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.397472\ttrain's IoU: 0.163387\tvalidation's binary_logloss: 0.530341\tvalidation's IoU: 0.157162\n",
      "[100]\ttrain's binary_logloss: 0.38062\ttrain's IoU: 0.232469\tvalidation's binary_logloss: 0.512294\tvalidation's IoU: 0.218473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.38062\ttrain's IoU: 0.232469\tvalidation's binary_logloss: 0.512294\tvalidation's IoU: 0.218473\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w2.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.517 (precision=0.8001, recall=0.2094)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg100_w2.0.npy\n",
      "[NEG%=100, w_neg=2.0] TEST: IoU=0.195, Prec=0.796, Rec=0.205, F1=0.326, Thr=0.517\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w2.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 3.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w3.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.150933 -> initscore=-1.727305\n",
      "[LightGBM] [Info] Start training from score -1.727305\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.333127\ttrain's IoU: 0.0750584\tvalidation's binary_logloss: 0.584556\tvalidation's IoU: 0.0723945\n",
      "[100]\ttrain's binary_logloss: 0.319543\ttrain's IoU: 0.125938\tvalidation's binary_logloss: 0.564229\tvalidation's IoU: 0.11616\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.319543\ttrain's IoU: 0.125938\tvalidation's binary_logloss: 0.564229\tvalidation's IoU: 0.11616\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w3.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.425 (precision=0.8001, recall=0.2053)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg100_w3.0.npy\n",
      "[NEG%=100, w_neg=3.0] TEST: IoU=0.193, Prec=0.801, Rec=0.203, F1=0.323, Thr=0.425\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w3.0.png\n",
      "\n",
      "--------------------------------------------------\n",
      "[NEG%=100] Training with class_weight: {0: 5.0, 1: 1.0}\n",
      "Saved sweep train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/trainval_data_neg100pct_w5.0.parquet\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 78556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3669\n",
      "[LightGBM] [Info] Number of data points in the train set: 120449, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.096378 -> initscore=-2.238131\n",
      "[LightGBM] [Info] Start training from score -2.238131\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.25386\ttrain's IoU: 0.00443935\tvalidation's binary_logloss: 0.680853\tvalidation's IoU: 0.00359111\n",
      "[100]\ttrain's binary_logloss: 0.244324\ttrain's IoU: 0.0317702\tvalidation's binary_logloss: 0.658005\tvalidation's IoU: 0.0268222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.244324\ttrain's IoU: 0.0317702\tvalidation's binary_logloss: 0.658005\tvalidation's IoU: 0.0268222\n",
      "Saved IoU learning curve: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/iou_curve_neg100pct_w5.0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "Chosen threshold (PRECâ¥0.80): 0.319 (precision=0.8001, recall=0.1983)  [RECALL_FLOOR ref=0.80]\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[SAVE] y_test_proba -> /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/y_test_proba_neg100_w5.0.npy\n",
      "[NEG%=100, w_neg=5.0] TEST: IoU=0.185, Prec=0.808, Rec=0.193, F1=0.312, Thr=0.319\n",
      "Saved feature importance plot: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/feature_importance_neg100pct_w5.0.png\n",
      "\n",
      "Saved Option 2 global-test sweep summary to:\n",
      "/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option2_scale_pos_weight_penalize_fp/option2_neg_ratio_sweep_globaltest_metrics_pf08.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Option 2 (global fixed test set) â Penalize False Positives:\n",
    "- Read full cems_with_fraction_balanced.parquet\n",
    "- Build features, coerce to numeric, drop bad rows\n",
    "- Create a single global test set (10%) with true 0/1 distribution (no resampling)\n",
    "- Use the remaining 90% as a train/val pool\n",
    "- Fix a positive sample set once\n",
    "- Sweep negative ratios (10..100%, where 100% = 2x positives)\n",
    "- For each neg% sweep, ALSO sweep negative class weights to penalize false positives\n",
    "- Train LightGBM (sklearn API)\n",
    "- Choose threshold on validation by maximizing RECALL subject to PRECISION â¥ floor\n",
    "  (fall back to max precision if no point meets the floor)\n",
    "- Evaluate on the SAME fixed global test set\n",
    "- Save:\n",
    "    - Balanced train/val parquet per (neg%, neg_class_weight) sweep\n",
    "    - IoU learning curve PNG per sweep\n",
    "    - Feature importance PNG per sweep\n",
    "    - Per-sweep y_test_proba_*.npy for PR curves\n",
    "    - Global y_test.npy once for PR curves\n",
    "    - Summary CSV (rounded) across all sweeps\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    jaccard_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "PARQUET_IN    = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction.parquet\"\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "# Overall split: global test set (10%), rest train/val pool (90%)\n",
    "TEST_SIZE_GLOBAL = 0.10\n",
    "VAL_SIZE_OVERALL = 0.20   # overall val fraction of full dataset; derive inner val from this\n",
    "\n",
    "THRESH_INIT   = 0.50      # used for IoU logging metric\n",
    "RECALL_FLOOR  = 0.80      # legacy recall requirement (still printed)\n",
    "PRECISION_FLOOR = 0.80    # precision floor to penalize false positives (tighten to 0.85â0.90 if desired)\n",
    "\n",
    "TOP_N_IMPORT  = 30\n",
    "\n",
    "# Negative ratio sweep within the train/val pool:\n",
    "# 100% = 2x positives, 10% = 0.2x positives, etc.\n",
    "PCT_STEPS = list(range(10, 101, 10))\n",
    "\n",
    "# Optional: cap positives in train/val pool for speed (None = use all)\n",
    "MAX_SAMPLES_POS_TRAINVAL = None\n",
    "\n",
    "# Class-weight sweep to penalize negatives (false positives)\n",
    "USE_CLASS_WEIGHT = True\n",
    "NEG_CLASS_WEIGHT_SWEEP = [1.0, 2.0, 3.0, 5.0]  # try higher if precision is still low\n",
    "\n",
    "# LightGBM base params\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=48,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.75,\n",
    "    bagging_freq=5,\n",
    "    lambda_l2=2.0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Output root and option-specific dir\n",
    "OUT_ROOT = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest\"\n",
    "OUT_DIR  = os.path.join(OUT_ROOT, \"option2_scale_pos_weight_penalize_fp\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\n=== OUTPUT DIRECTORY ===\")\n",
    "print(OUT_DIR)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD & EARLY CLEAN (ONCE)\n",
    "# =====================================================\n",
    "print(f\"\\nLoading: {PARQUET_IN}\")\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "\n",
    "if \"fraction\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'fraction' in dataset.\")\n",
    "\n",
    "df[\"fraction\"] = df[\"fraction\"].astype(\"float32\").clip(0.0, 1.0)\n",
    "before = len(df)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\").copy()\n",
    "print(f\"Dropped {before - len(df):,} rows with NaNs/Â±inf; {len(df):,} remain.\")\n",
    "\n",
    "# =====================================================\n",
    "# FRACTION -> BINARY\n",
    "# =====================================================\n",
    "df[\"burned\"] = (df[\"fraction\"] > THRESH_INIT).astype(np.uint8)\n",
    "\n",
    "print(\"\\nClass counts before any splitting:\")\n",
    "print(df[\"burned\"].value_counts(dropna=False))\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE MATRIX (GLOBAL) + TYPE COERCION\n",
    "# =====================================================\n",
    "drop_cols = {\"fraction\", \"burned\", \"bin\", \"year\", \"month\", \"latitude\", \"longitude\"}\n",
    "predictors = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X_full = df[predictors].copy()\n",
    "y_full = df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# Treat 'b1' as category if present\n",
    "if \"b1\" in X_full.columns and not pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "    X_full[\"b1\"] = X_full[\"b1\"].astype(\"category\")\n",
    "    print(\"\\nTreating 'b1' as pandas 'category'.\")\n",
    "\n",
    "# Coerce non-category columns to numeric and drop rows with NaNs\n",
    "coerced = 0\n",
    "for c in X_full.columns:\n",
    "    if c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        continue\n",
    "    if not np.issubdtype(X_full[c].dtype, np.number):\n",
    "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
    "        coerced += 1\n",
    "\n",
    "if coerced:\n",
    "    pre = len(X_full)\n",
    "    num_cols = [c for c in X_full.columns if not (c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]))]\n",
    "    mask = X_full[num_cols].notna().all(axis=1)\n",
    "    if \"b1\" in X_full.columns and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        mask &= X_full[\"b1\"].notna()\n",
    "    X_full = X_full.loc[mask].copy()\n",
    "    y_full = y_full.loc[X_full.index]\n",
    "    print(f\"Coerced {coerced} column(s); dropped {pre - len(X_full):,} rows post-coercion.\")\n",
    "\n",
    "print(f\"\\nPredictor columns: {len(X_full.columns)}\")\n",
    "\n",
    "# Combine into a single DataFrame for convenient splitting\n",
    "data = X_full.copy()\n",
    "data[\"burned\"] = y_full\n",
    "\n",
    "# =====================================================\n",
    "# GLOBAL TRAINVAL / TEST SPLIT (FIXED TEST SET)\n",
    "# =====================================================\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    data.index,\n",
    "    test_size=TEST_SIZE_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[\"burned\"],\n",
    ")\n",
    "\n",
    "trainval = data.loc[idx_trainval].copy()\n",
    "test     = data.loc[idx_test].copy()\n",
    "\n",
    "print(\"\\nGlobal split sizes (true distribution in test):\")\n",
    "print(f\"  Train/Val pool: {len(trainval):,}\")\n",
    "print(f\"  Test (fixed)  : {len(test):,}\")\n",
    "print(\"\\nTest set class counts (true distribution):\")\n",
    "print(test[\"burned\"].value_counts())\n",
    "\n",
    "# Extract global test X, y\n",
    "X_test = test[predictors].copy()\n",
    "y_test = test[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# --- NEW: save global test labels once for PR curves ---\n",
    "np.save(os.path.join(OUT_DIR, \"y_test.npy\"), y_test.values)\n",
    "print(f\"[SAVE] y_test -> {os.path.join(OUT_DIR, 'y_test.npy')}\")\n",
    "\n",
    "# =====================================================\n",
    "# TRAIN/VAL POOL: POS/NEG SPLITTING BASE\n",
    "# =====================================================\n",
    "pos_tv = trainval[trainval[\"burned\"] == 1]\n",
    "neg_tv = trainval[trainval[\"burned\"] == 0]\n",
    "\n",
    "n_pos_tv = len(pos_tv)\n",
    "n_neg_tv = len(neg_tv)\n",
    "\n",
    "print(\"\\nTrain/Val pool class counts:\")\n",
    "print(trainval[\"burned\"].value_counts())\n",
    "\n",
    "if n_pos_tv == 0 or n_neg_tv == 0:\n",
    "    raise ValueError(\"Train/Val pool has only one class; cannot proceed.\")\n",
    "\n",
    "# Fix positive sample within train/val pool (optionally capped)\n",
    "target_pos = n_pos_tv\n",
    "if MAX_SAMPLES_POS_TRAINVAL is not None:\n",
    "    target_pos = min(target_pos, MAX_SAMPLES_POS_TRAINVAL)\n",
    "\n",
    "pos_tv_s = pos_tv.sample(n=min(n_pos_tv, target_pos), random_state=RANDOM_STATE)\n",
    "n_pos_eff = len(pos_tv_s)\n",
    "print(f\"\\nEffective positive samples in train/val sweeps: {n_pos_eff:,}\")\n",
    "\n",
    "# =====================================================\n",
    "# Custom IoU metric for logging (sklearn API)\n",
    "# =====================================================\n",
    "def lgb_iou_metric_skl(y_true, y_pred):\n",
    "    y_hat = (y_pred >= THRESH_INIT).astype(np.uint8)\n",
    "    iou = jaccard_score(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    return (\"IoU\", iou, True)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# =====================================================\n",
    "# SWEEP OVER NEGATIVE RATIOS IN TRAIN/VAL POOL\n",
    "# =====================================================\n",
    "for pct in PCT_STEPS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"== Option 2: NEGATIVE PERCENT = {pct}% (100% = 2x positives in TRAIN/VAL) ==\")\n",
    "\n",
    "    # 100% -> 2 * n_pos_eff\n",
    "    # 10%  -> 0.2 * n_pos_eff\n",
    "    neg_target = int(round((pct / 100.0) * 2.0 * n_pos_eff))\n",
    "    neg_target = max(1, min(neg_target, n_neg_tv))\n",
    "\n",
    "    print(f\"Target negatives for this sweep (from train/val pool): {neg_target:,}\")\n",
    "\n",
    "    neg_tv_s = neg_tv.sample(n=neg_target, random_state=RANDOM_STATE + pct)\n",
    "\n",
    "    sweep_df_base = (\n",
    "        pd.concat([pos_tv_s, neg_tv_s], axis=0)\n",
    "          .sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"Class counts in sweep base train/val dataset:\")\n",
    "    print(sweep_df_base[\"burned\"].value_counts())\n",
    "\n",
    "    # 70/20 of the *full dataset* corresponds to 70/20 out of (1 - TEST_SIZE_GLOBAL)\n",
    "    val_size_inner = VAL_SIZE_OVERALL / (1.0 - TEST_SIZE_GLOBAL)  # e.g., 0.20 / 0.90\n",
    "\n",
    "    # =====================================================\n",
    "    # NEGATIVE CLASS WEIGHT SWEEP (penalize FPs)\n",
    "    # =====================================================\n",
    "    for neg_w in NEG_CLASS_WEIGHT_SWEEP:\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(f\"[NEG%={pct}] Training with class_weight: {{0: {neg_w}, 1: 1.0}}\")\n",
    "\n",
    "        # copy to avoid any accidental in-place mutations\n",
    "        sweep_df = sweep_df_base.copy()\n",
    "\n",
    "        # Save sweep train/val parquet for traceability\n",
    "        parquet_out = os.path.join(\n",
    "            OUT_DIR, f\"trainval_data_neg{pct:03d}pct_w{neg_w}.parquet\"\n",
    "        )\n",
    "        sweep_df.to_parquet(parquet_out)\n",
    "        print(f\"Saved sweep train/val parquet: {parquet_out}\")\n",
    "\n",
    "        # Features / target for this sweep\n",
    "        X_sweep = sweep_df[predictors].copy()\n",
    "        y_sweep = sweep_df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_sweep,\n",
    "            y_sweep,\n",
    "            test_size=val_size_inner,\n",
    "            random_state=RANDOM_STATE,\n",
    "            stratify=y_sweep,\n",
    "        )\n",
    "\n",
    "        if USE_CLASS_WEIGHT:\n",
    "            model = lgb.LGBMClassifier(\n",
    "                **LGB_PARAMS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                class_weight={0: neg_w, 1: 1.0},  # penalize FP\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to original pos-weighting if desired\n",
    "            n_pos_train = int((y_train == 1).sum())\n",
    "            n_neg_train = int((y_train == 0).sum())\n",
    "            pos_weight = n_neg_train / max(1, n_pos_train)\n",
    "            model = lgb.LGBMClassifier(\n",
    "                **LGB_PARAMS,\n",
    "                random_state=RANDOM_STATE,\n",
    "                scale_pos_weight=pos_weight,\n",
    "            )\n",
    "\n",
    "        evals_result = {}\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_names=[\"train\", \"validation\"],\n",
    "            eval_metric=[\"aucpr\", lgb_iou_metric_skl],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(period=50),\n",
    "                lgb.record_evaluation(evals_result),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ---------------- LEARNING CURVE: IoU (TRAIN vs VAL) ----------------\n",
    "        if \"IoU\" in evals_result.get(\"train\", {}):\n",
    "            train_iou_curve = evals_result[\"train\"][\"IoU\"]\n",
    "            val_iou_curve   = evals_result[\"validation\"][\"IoU\"]\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(train_iou_curve, label=\"Train IoU\")\n",
    "            plt.plot(val_iou_curve,   label=\"Validation IoU\")\n",
    "            plt.xlabel(\"Boosting Rounds\")\n",
    "            plt.ylabel(\"IoU (Jaccard)\")\n",
    "            plt.title(\n",
    "                f\"Train vs Val IoU\\nNEG={pct}% (100% = 2x pos), THRESH_INIT={THRESH_INIT:.2f}, w_neg={neg_w}\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            iou_fig_out = os.path.join(\n",
    "                OUT_DIR, f\"iou_curve_neg{pct:03d}pct_w{neg_w}.png\"\n",
    "            )\n",
    "            plt.savefig(iou_fig_out, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"Saved IoU learning curve: {iou_fig_out}\")\n",
    "\n",
    "        # ---------------- Threshold selection with a PRECISION FLOOR ----------------\n",
    "        y_val_proba = model.predict_proba(X_val, num_iteration=model.best_iteration_)[:, 1]\n",
    "        prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "\n",
    "        # Prefer thresholds that meet the precision floor; among them choose max recall\n",
    "        mask = prec[:-1] >= PRECISION_FLOOR\n",
    "        if np.any(mask):\n",
    "            best_idx_rel = np.argmax(rec[:-1][mask])\n",
    "            best_idx = np.flatnonzero(mask)[best_idx_rel]\n",
    "        else:\n",
    "            # If nothing meets the floor, fall back to global max precision\n",
    "            best_idx = np.argmax(prec[:-1])\n",
    "\n",
    "        best_thr = float(thr[best_idx])\n",
    "        print(f\"Chosen threshold (PRECâ¥{PRECISION_FLOOR:.2f}): {best_thr:.3f} \"\n",
    "              f\"(precision={prec[best_idx]:.4f}, recall={rec[best_idx]:.4f})  \"\n",
    "              f\"[RECALL_FLOOR ref={RECALL_FLOOR:.2f}]\")\n",
    "\n",
    "        # ---------------- FINAL METRICS ON FIXED GLOBAL TEST SET ----------------\n",
    "        y_test_proba = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "        y_test_hat   = (y_test_proba >= best_thr).astype(np.uint8)\n",
    "\n",
    "        # --- NEW: save per-sweep probabilities for PR curves later ---\n",
    "        proba_path = os.path.join(OUT_DIR, f\"y_test_proba_neg{pct:03d}_w{neg_w}.npy\")\n",
    "        np.save(proba_path, y_test_proba)\n",
    "        print(f\"[SAVE] y_test_proba -> {proba_path}\")\n",
    "\n",
    "        test_iou  = jaccard_score(y_test, y_test_hat, average=\"binary\", zero_division=0)\n",
    "        test_prec = precision_score(y_test, y_test_hat, zero_division=0)\n",
    "        test_rec  = recall_score(y_test, y_test_hat, zero_division=0)\n",
    "        test_f1   = f1_score(y_test, y_test_hat, zero_division=0)\n",
    "\n",
    "        print(f\"[NEG%={pct}, w_neg={neg_w}] TEST: IoU={test_iou:.3f}, \"\n",
    "              f\"Prec={test_prec:.3f}, Rec={test_rec:.3f}, F1={test_f1:.3f}, Thr={best_thr:.3f}\")\n",
    "\n",
    "        summary_rows.append(\n",
    "            dict(\n",
    "                neg_percent=pct,\n",
    "                neg_class_weight=neg_w if USE_CLASS_WEIGHT else 1.0,\n",
    "                threshold=round(best_thr, 3),\n",
    "                test_iou=round(test_iou, 3),\n",
    "                test_precision=round(test_prec, 3),\n",
    "                test_recall=round(test_rec, 3),\n",
    "                test_f1=round(test_f1, 3),\n",
    "                best_iteration=int(model.best_iteration_ if hasattr(model, \"best_iteration_\") else -1),\n",
    "                precision_floor=PRECISION_FLOOR,\n",
    "                recall_floor=RECALL_FLOOR,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # ---------------- FEATURE IMPORTANCE ----------------\n",
    "        gain_imp = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "        gain_imp = gain_imp / (gain_imp.sum() + 1e-12)\n",
    "        feat_names = np.array(X_train.columns)\n",
    "\n",
    "        order = np.argsort(gain_imp)[::-1][:TOP_N_IMPORT]\n",
    "        plt.figure(figsize=(9, max(5, 0.28 * len(order))))\n",
    "        plt.barh(feat_names[order][::-1], gain_imp[order][::-1])\n",
    "        plt.xlabel(\"Relative Gain Importance\")\n",
    "        plt.title(\n",
    "            f\"Feature Importance (Top {len(order)})\\nNEG={pct}% (100% = 2x pos), w_neg={neg_w}\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fi_fig_out = os.path.join(\n",
    "            OUT_DIR, f\"feature_importance_neg{pct:03d}pct_w{neg_w}.png\"\n",
    "        )\n",
    "        plt.savefig(fi_fig_out, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved feature importance plot: {fi_fig_out}\")\n",
    "\n",
    "# =====================================================\n",
    "# SAVE SUMMARY CSV (rounded metrics)\n",
    "# =====================================================\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv = os.path.join(\n",
    "        OUT_DIR, f\"option2_neg_ratio_sweep_globaltest_metrics_pf{str(PRECISION_FLOOR).replace('.', '')}.csv\"\n",
    "    )\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSaved Option 2 global-test sweep summary to:\\n{summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo sweeps were run; summary not saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c881a-226e-4ba3-aeb7-5ebc3839301a",
   "metadata": {},
   "source": [
    "Option 3. Fixed train/val ratio, sweep scale_pos_weight, same global test set\n",
    "\n",
    "Here we:\n",
    "\n",
    "Use the same global splits logic as above.\n",
    "\n",
    "In the train/val pool, build a single fixed-ratio dataset (e.g., 1:1 0:1).\n",
    "\n",
    "Sweep scale_pos_weight values on that same dataset.\n",
    "\n",
    "Always evaluate on the same global test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad36492-c042-40da-9544-117b69f1f31f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction_balanced.parquet\n",
      "Dropped 0 rows with NaNs/Â±inf; 172,072 remain.\n",
      "\n",
      "Class counts before any splitting:\n",
      "0    112224\n",
      "1     59848\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Treating 'b1' as pandas 'category'.\n",
      "\n",
      "Predictor columns: 15\n",
      "\n",
      "Global split sizes (true distribution in test):\n",
      "  Train/Val pool: 154,864\n",
      "  Test (fixed)  : 17,208\n",
      "\n",
      "Test set class counts:\n",
      "0    11223\n",
      "1     5985\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Train/Val pool class counts:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Effective positive samples in train/val fixed dataset: 53,863\n",
      "Fixed negative target in train/val (NEG_MULT=1.0): 53,863\n",
      "\n",
      "Class counts in fixed train/val dataset:\n",
      "0    53863\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved fixed-ratio train/val parquet: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/trainval_data_fixed_ratio.parquet\n",
      "\n",
      "Predictor columns (train/val fixed): 15\n",
      "\n",
      "======================================================================\n",
      "== Option 3: scale_pos_weight = 1.000 on fixed train/val dataset ==\n",
      "Sweep split sizes (fixed dataset):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.509691\ttrain's IoU: 0.622173\tvalidation's binary_logloss: 0.520741\tvalidation's IoU: 0.611625\n",
      "[100]\ttrain's binary_logloss: 0.484193\ttrain's IoU: 0.636473\tvalidation's binary_logloss: 0.503272\tvalidation's IoU: 0.615718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.484193\ttrain's IoU: 0.636473\tvalidation's binary_logloss: 0.503272\tvalidation's IoU: 0.615718\n",
      "Saved IoU curve for pw=1.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/iou_curve_scale_pos_weight_1p0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (scale_pos_weight=1.000): 0.524  (precision=0.7140, recall=0.8003)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "scale_pos_weight: 1.000\n",
      "Threshold      : 0.524\n",
      "IoU (Jaccard)  : 0.501726\n",
      "Precision      : 0.572999\n",
      "Recall         : 0.801337\n",
      "F1 Score       : 0.668199\n",
      "Saved feature importance plot for pw=1.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/feature_importance_scale_pos_weight_1p0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 3: scale_pos_weight = 2.000 on fixed train/val dataset ==\n",
      "Sweep split sizes (fixed dataset):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.539547\ttrain's IoU: 0.625788\tvalidation's binary_logloss: 0.549816\tvalidation's IoU: 0.619636\n",
      "[100]\ttrain's binary_logloss: 0.519983\ttrain's IoU: 0.636827\tvalidation's binary_logloss: 0.538403\tvalidation's IoU: 0.626284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's binary_logloss: 0.519983\ttrain's IoU: 0.636827\tvalidation's binary_logloss: 0.538403\tvalidation's IoU: 0.626284\n",
      "Saved IoU curve for pw=2.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/iou_curve_scale_pos_weight_2p0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (scale_pos_weight=2.000): 0.685  (precision=0.7138, recall=0.8023)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "scale_pos_weight: 2.000\n",
      "Threshold      : 0.685\n",
      "IoU (Jaccard)  : 0.501464\n",
      "Precision      : 0.572828\n",
      "Recall         : 0.801003\n",
      "F1 Score       : 0.667967\n",
      "Saved feature importance plot for pw=2.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/feature_importance_scale_pos_weight_2p0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 3: scale_pos_weight = 4.000 on fixed train/val dataset ==\n",
      "Sweep split sizes (fixed dataset):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.623716\ttrain's IoU: 0.605626\tvalidation's binary_logloss: 0.633122\tvalidation's IoU: 0.600804\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's binary_logloss: 0.601036\ttrain's IoU: 0.599304\tvalidation's binary_logloss: 0.604764\tvalidation's IoU: 0.595962\n",
      "Saved IoU curve for pw=4.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/iou_curve_scale_pos_weight_4p0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (scale_pos_weight=4.000): 0.693  (precision=0.6917, recall=0.8003)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "scale_pos_weight: 4.000\n",
      "Threshold      : 0.693\n",
      "IoU (Jaccard)  : 0.483972\n",
      "Precision      : 0.549565\n",
      "Recall         : 0.802172\n",
      "F1 Score       : 0.652265\n",
      "Saved feature importance plot for pw=4.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/feature_importance_scale_pos_weight_4p0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 3: scale_pos_weight = 8.000 on fixed train/val dataset ==\n",
      "Sweep split sizes (fixed dataset):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.738241\ttrain's IoU: 0.593796\tvalidation's binary_logloss: 0.747094\tvalidation's IoU: 0.589633\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttrain's binary_logloss: 0.629077\ttrain's IoU: 0.588496\tvalidation's binary_logloss: 0.631042\tvalidation's IoU: 0.585937\n",
      "Saved IoU curve for pw=8.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/iou_curve_scale_pos_weight_8p0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (scale_pos_weight=8.000): 0.670  (precision=0.6838, recall=0.8003)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "scale_pos_weight: 8.000\n",
      "Threshold      : 0.670\n",
      "IoU (Jaccard)  : 0.478257\n",
      "Precision      : 0.540993\n",
      "Recall         : 0.804845\n",
      "F1 Score       : 0.647055\n",
      "Saved feature importance plot for pw=8.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/feature_importance_scale_pos_weight_8p0.png\n",
      "\n",
      "======================================================================\n",
      "== Option 3: scale_pos_weight = 16.000 on fixed train/val dataset ==\n",
      "Sweep split sizes (fixed dataset):\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] Number of positive: 41893, number of negative: 41893\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3668\n",
      "[LightGBM] [Info] Number of data points in the train set: 83786, number of used features: 15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttrain's binary_logloss: 0.858423\ttrain's IoU: 0.585841\tvalidation's binary_logloss: 0.86676\tvalidation's IoU: 0.58228\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttrain's binary_logloss: 0.644425\ttrain's IoU: 0.58058\tvalidation's binary_logloss: 0.646242\tvalidation's IoU: 0.577633\n",
      "Saved IoU curve for pw=16.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/iou_curve_scale_pos_weight_16p0.png\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "Chosen threshold on VALID (scale_pos_weight=16.000): 0.649  (precision=0.6789, recall=0.8008)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.75, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "\n",
      "==== FINAL TEST METRICS (fixed global test set) ====\n",
      "scale_pos_weight: 16.000\n",
      "Threshold      : 0.649\n",
      "IoU (Jaccard)  : 0.473353\n",
      "Precision      : 0.534948\n",
      "Recall         : 0.804344\n",
      "F1 Score       : 0.642552\n",
      "Saved feature importance plot for pw=16.000: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/feature_importance_scale_pos_weight_16p0.png\n",
      "\n",
      "Saved Option 3 global-test sweep summary to: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option3_weight_sweeps/option3_weight_sweeps_globaltest_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Option 3 (global fixed test set, fixed train/val ratio, sweep scale_pos_weight):\n",
    "- Same global preprocessing & test split as Option 2\n",
    "- In train/val pool:\n",
    "    - Build a fixed-ratio dataset (NEG_MULT * positives)\n",
    "    - Use that same dataset for all runs\n",
    "- Sweep scale_pos_weight over POS_WEIGHTS\n",
    "- For each weight:\n",
    "    - Train model, pick threshold on val (max precision with recall â¥ floor)\n",
    "    - Evaluate on the fixed global test set\n",
    "- Save:\n",
    "    - Fixed train/val parquet\n",
    "    - IoU learning curves per weight\n",
    "    - Feature importance per weight\n",
    "    - Summary CSV of test metrics over weights (rounded)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    jaccard_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "PARQUET_IN    = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction.parquet\"\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "TEST_SIZE_GLOBAL = 0.10\n",
    "VAL_SIZE_OVERALL = 0.20\n",
    "\n",
    "THRESH_INIT   = 0.50          # for IoU logging during training\n",
    "RECALL_FLOOR  = 0.80\n",
    "TOP_N_IMPORT  = 30\n",
    "\n",
    "# Fixed negative:positive ratio in train/val pool\n",
    "NEG_MULT = 1.0   # 1.0 => 1:1, 2.0 => 2:1, etc.\n",
    "\n",
    "# Sweep of scale_pos_weight on that fixed dataset\n",
    "POS_WEIGHTS = [1.0, 2.0, 4.0, 8.0, 16.0]\n",
    "\n",
    "# Optionally cap positives in train/val pool for speed (None = use all)\n",
    "MAX_SAMPLES_POS_TRAINVAL = None\n",
    "\n",
    "LGB_PARAMS = dict(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=48,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.75,\n",
    "    bagging_freq=5,\n",
    "    lambda_l2=2.0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "OUT_ROOT = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest\"\n",
    "OUT_DIR  = os.path.join(OUT_ROOT, \"option3_weight_sweeps\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# LOAD & PREP (SAME AS OPTION 2)\n",
    "# =====================================================\n",
    "print(f\"Loading: {PARQUET_IN}\")\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "\n",
    "if \"fraction\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'fraction' in dataset.\")\n",
    "\n",
    "df[\"fraction\"] = df[\"fraction\"].astype(\"float32\").clip(0.0, 1.0)\n",
    "before = len(df)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\").copy()\n",
    "print(f\"Dropped {before - len(df):,} rows with NaNs/Â±inf; {len(df):,} remain.\")\n",
    "\n",
    "df[\"burned\"] = (df[\"fraction\"] > THRESH_INIT).astype(np.uint8)\n",
    "\n",
    "print(\"\\nClass counts before any splitting:\")\n",
    "print(df[\"burned\"].value_counts(dropna=False))\n",
    "\n",
    "drop_cols = {\"fraction\", \"burned\", \"bin\", \"year\", \"month\", \"latitude\", \"longitude\"}\n",
    "predictors = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X_full = df[predictors].copy()\n",
    "y_full = df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "if \"b1\" in X_full.columns and not pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "    X_full[\"b1\"] = X_full[\"b1\"].astype(\"category\")\n",
    "    print(\"\\nTreating 'b1' as pandas 'category'.\")\n",
    "\n",
    "coerced = 0\n",
    "for c in X_full.columns:\n",
    "    if c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[c]):\n",
    "        continue\n",
    "    if not np.issubdtype(X_full[c].dtype, np.number):\n",
    "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
    "        coerced += 1\n",
    "\n",
    "if coerced:\n",
    "    pre = len(X_full)\n",
    "    num_cols = [c for c in X_full.columns if not (c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]))]\n",
    "    mask = X_full[num_cols].notna().all(axis=1)\n",
    "    if \"b1\" in X_full.columns and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        mask &= X_full[\"b1\"].notna()\n",
    "    X_full = X_full.loc[mask].copy()\n",
    "    y_full = y_full.loc[X_full.index]\n",
    "    print(f\"Coerced {coerced} column(s); dropped {pre - len(X_full):,} rows post-coercion.\")\n",
    "\n",
    "print(f\"\\nPredictor columns: {len(X_full.columns)}\")\n",
    "\n",
    "data = X_full.copy()\n",
    "data[\"burned\"] = y_full\n",
    "\n",
    "# Global split\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    data.index,\n",
    "    test_size=TEST_SIZE_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[\"burned\"],\n",
    ")\n",
    "\n",
    "trainval = data.loc[idx_trainval].copy()\n",
    "test     = data.loc[idx_test].copy()\n",
    "\n",
    "print(\"\\nGlobal split sizes (true distribution in test):\")\n",
    "print(f\"  Train/Val pool: {len(trainval):,}\")\n",
    "print(f\"  Test (fixed)  : {len(test):,}\")\n",
    "print(\"\\nTest set class counts:\")\n",
    "print(test[\"burned\"].value_counts())\n",
    "\n",
    "X_test = test[predictors].copy()\n",
    "y_test = test[\"burned\"].astype(np.uint8)\n",
    "\n",
    "pos_tv = trainval[trainval[\"burned\"] == 1]\n",
    "neg_tv = trainval[trainval[\"burned\"] == 0]\n",
    "\n",
    "n_pos_tv = len(pos_tv)\n",
    "n_neg_tv = len(neg_tv)\n",
    "print(\"\\nTrain/Val pool class counts:\")\n",
    "print(trainval[\"burned\"].value_counts())\n",
    "\n",
    "if n_pos_tv == 0 or n_neg_tv == 0:\n",
    "    raise ValueError(\"Train/Val pool has only one class; cannot proceed.\")\n",
    "\n",
    "target_pos = n_pos_tv\n",
    "if MAX_SAMPLES_POS_TRAINVAL is not None:\n",
    "    target_pos = min(target_pos, MAX_SAMPLES_POS_TRAINVAL)\n",
    "\n",
    "pos_tv_s = pos_tv.sample(n=min(n_pos_tv, target_pos), random_state=RANDOM_STATE)\n",
    "n_pos_eff = len(pos_tv_s)\n",
    "print(f\"\\nEffective positive samples in train/val fixed dataset: {n_pos_eff:,}\")\n",
    "\n",
    "neg_target = int(round(NEG_MULT * n_pos_eff))\n",
    "neg_target = max(1, min(neg_target, n_neg_tv))\n",
    "print(f\"Fixed negative target in train/val (NEG_MULT={NEG_MULT}): {neg_target:,}\")\n",
    "\n",
    "neg_tv_s = neg_tv.sample(n=neg_target, random_state=RANDOM_STATE + 1)\n",
    "\n",
    "fixed_tv_df = (\n",
    "    pd.concat([pos_tv_s, neg_tv_s], axis=0)\n",
    "      .sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nClass counts in fixed train/val dataset:\")\n",
    "print(fixed_tv_df[\"burned\"].value_counts())\n",
    "\n",
    "# Save base train/val dataset\n",
    "base_parquet = os.path.join(OUT_DIR, \"trainval_data_fixed_ratio.parquet\")\n",
    "fixed_tv_df.to_parquet(base_parquet)\n",
    "print(f\"Saved fixed-ratio train/val parquet: {base_parquet}\")\n",
    "\n",
    "# =====================================================\n",
    "# FEATURES / TARGET (train/val fixed dataset)\n",
    "# =====================================================\n",
    "X_tv_full = fixed_tv_df[predictors].copy()\n",
    "y_tv_full = fixed_tv_df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "print(f\"\\nPredictor columns (train/val fixed): {len(X_tv_full.columns)}\")\n",
    "\n",
    "# Custom IoU metric\n",
    "def lgb_iou_metric_skl(y_true, y_pred):\n",
    "    y_hat = (y_pred >= THRESH_INIT).astype(np.uint8)\n",
    "    iou = jaccard_score(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    return (\"IoU\", iou, True)\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# =====================================================\n",
    "# SWEEP OVER scale_pos_weight\n",
    "# =====================================================\n",
    "for pw in POS_WEIGHTS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"== Option 3: scale_pos_weight = {pw:.3f} on fixed train/val dataset ==\")\n",
    "\n",
    "    # inner val fraction so that overall val â VAL_SIZE_OVERALL\n",
    "    val_size_inner = VAL_SIZE_OVERALL / (1.0 - TEST_SIZE_GLOBAL)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_tv_full,\n",
    "        y_tv_full,\n",
    "        test_size=val_size_inner,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_tv_full,\n",
    "    )\n",
    "\n",
    "    print(\"Sweep split sizes (fixed dataset):\")\n",
    "    print(f\"  Train: {len(X_train):,}\")\n",
    "    print(f\"  Val  : {len(X_val):,}\")\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        **LGB_PARAMS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scale_pos_weight=pw,\n",
    "    )\n",
    "\n",
    "    evals_result = {}\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_names=[\"train\", \"validation\"],\n",
    "        eval_metric=[\"aucpr\", lgb_iou_metric_skl],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=50),\n",
    "            lgb.record_evaluation(evals_result),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # IoU learning curve\n",
    "    if \"IoU\" in evals_result.get(\"train\", {}):\n",
    "        train_iou_curve = evals_result[\"train\"][\"IoU\"]\n",
    "        val_iou_curve   = evals_result[\"validation\"][\"IoU\"]\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(train_iou_curve, label=\"Train IoU\")\n",
    "        plt.plot(val_iou_curve,   label=\"Validation IoU\")\n",
    "        plt.xlabel(\"Boosting Rounds\")\n",
    "        plt.ylabel(\"IoU (Jaccard)\")\n",
    "        plt.title(\n",
    "            f\"Option 3: Train vs Val IoU\\n\"\n",
    "            f\"scale_pos_weight={pw:.3f}, THRESH_INIT={THRESH_INIT:.2f}\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        safe_pw = str(pw).replace(\".\", \"p\")\n",
    "        iou_fig_out = os.path.join(\n",
    "            OUT_DIR, f\"iou_curve_scale_pos_weight_{safe_pw}.png\"\n",
    "        )\n",
    "        plt.savefig(iou_fig_out, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved IoU curve for pw={pw:.3f}: {iou_fig_out}\")\n",
    "\n",
    "    # Threshold on validation\n",
    "    y_val_proba = model.predict_proba(X_val, num_iteration=model.best_iteration_)[:, 1]\n",
    "    prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "    mask = rec[:-1] >= RECALL_FLOOR\n",
    "\n",
    "    if not np.any(mask):\n",
    "        print(f\"\\nNo threshold meets recall >= {RECALL_FLOOR:.2f}; using global max precision.\")\n",
    "        best_idx = np.argmax(prec[:-1])\n",
    "    else:\n",
    "        best_idx_rel = np.argmax(prec[:-1][mask])\n",
    "        best_idx = np.flatnonzero(mask)[best_idx_rel]\n",
    "\n",
    "    best_thr = float(thr[best_idx])  # probability threshold in [0,1]\n",
    "    print(\n",
    "        f\"\\nChosen threshold on VALID (scale_pos_weight={pw:.3f}): {best_thr:.3f}  \"\n",
    "        f\"(precision={prec[best_idx]:.4f}, recall={rec[best_idx]:.4f})\"\n",
    "    )\n",
    "\n",
    "    # Final metrics on fixed global test\n",
    "    y_test_proba = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "    y_test_hat   = (y_test_proba >= best_thr).astype(np.uint8)\n",
    "\n",
    "    test_iou  = jaccard_score(y_test, y_test_hat, average=\"binary\", zero_division=0)\n",
    "    test_prec = precision_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_rec  = recall_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_f1   = f1_score(y_test, y_test_hat, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== FINAL TEST METRICS (fixed global test set) ====\")\n",
    "    print(f\"scale_pos_weight: {pw:.3f}\")\n",
    "    print(f\"Threshold      : {best_thr:.3f}\")\n",
    "    print(f\"IoU (Jaccard)  : {test_iou:.2f}\")\n",
    "    print(f\"Precision      : {test_prec:.2f}\")\n",
    "    print(f\"Recall         : {test_rec:.2f}\")\n",
    "    print(f\"F1 Score       : {test_f1:.2f}\")\n",
    "\n",
    "    # counts from the fixed train/val dataset (same for all weights)\n",
    "    n_pos_tv_fixed = int((y_tv_full == 1).sum())\n",
    "    n_neg_tv_fixed = int((y_tv_full == 0).sum())\n",
    "\n",
    "    summary_rows.append(\n",
    "        dict(\n",
    "            scale_pos_weight=pw,\n",
    "            n_pos_trainval=n_pos_tv_fixed,\n",
    "            n_neg_trainval=n_neg_tv_fixed,\n",
    "            threshold=round(best_thr, 3),\n",
    "            test_iou=round(test_iou, 2),\n",
    "            test_precision=round(test_prec, 2),\n",
    "            test_recall=round(test_rec, 2),\n",
    "            test_f1=round(test_f1, 2),\n",
    "            best_iteration=int(model.best_iteration_ if hasattr(model, \"best_iteration_\") else -1),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Feature importance\n",
    "    gain_imp = model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    gain_imp = gain_imp / (gain_imp.sum() + 1e-12)\n",
    "    feat_names = np.array(X_train.columns)\n",
    "\n",
    "    order = np.argsort(gain_imp)[::-1][:TOP_N_IMPORT]\n",
    "    plt.figure(figsize=(9, max(5, 0.28 * len(order))))\n",
    "    plt.barh(feat_names[order][::-1], gain_imp[order][::-1])\n",
    "    plt.xlabel(\"Relative Gain Importance\")\n",
    "    plt.title(\n",
    "        f\"Option 3: Feature Importance (Top {len(order)})\\n\"\n",
    "        f\"scale_pos_weight={pw:.3f}\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fi_fig_out = os.path.join(\n",
    "        OUT_DIR, f\"feature_importance_scale_pos_weight_{safe_pw}.png\"\n",
    "    )\n",
    "    plt.savefig(fi_fig_out, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved feature importance plot for pw={pw:.3f}: {fi_fig_out}\")\n",
    "\n",
    "# Summary CSV (rounded metrics)\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv = os.path.join(OUT_DIR, \"option3_weight_sweeps_globaltest_metrics.csv\")\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSaved Option 3 global-test sweep summary to: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo sweeps were run; summary not saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdabe6-999b-48a0-b30f-d11036567cfa",
   "metadata": {},
   "source": [
    "Option 4 â Negative-ratio sweeps + focal loss, same global test set\n",
    "\n",
    "This mirrors Option 2âs negative-ratio sweeps in the train/val pool, but uses a focal loss custom objective via LightGBMâs train API. It shares the same global test split logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311be642-7358-4d2d-ac25-118bcb9cf8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction_balanced.parquet\n",
      "Dropped 0 rows with NaNs/Â±inf; 172,072 remain.\n",
      "\n",
      "Class counts before any splitting:\n",
      "0    112224\n",
      "1     59848\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Treating 'b1' as pandas 'category'.\n",
      "\n",
      "Predictor columns: 15\n",
      "\n",
      "Global split sizes (true distribution in test):\n",
      "  Train/Val pool: 154,864\n",
      "  Test (fixed)  : 17,208\n",
      "\n",
      "Test set class counts:\n",
      "0    11223\n",
      "1     5985\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Test set positives (1): 5,985\n",
      "Test set negatives (0): 11,223\n",
      "\n",
      "Train/Val pool class counts:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "\n",
      "Effective positive samples in train/val sweeps: 53,863\n",
      "\n",
      "[INFO] LightGBM build lacks `fobj` support on train(); falling back to XGBoost for weighted log loss.\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 10% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 10,773\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    10773\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 10%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg010pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 50,272\n",
      "  Val  : 14,364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.91805\ttrain-IoU:0.87133\tvalidation-aucpr:0.91032\tvalidation-IoU:0.86775\n",
      "[49]\ttrain-aucpr:0.94049\ttrain-IoU:0.87184\tvalidation-aucpr:0.93016\tvalidation-IoU:0.86892\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 10\n",
      "Threshold    : 0.628\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.47\n",
      "Recall       : 0.92\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 10%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg010pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 20% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 21,545\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    21545\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 20%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg020pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 58,650\n",
      "  Val  : 16,758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.84879\ttrain-IoU:0.77326\tvalidation-aucpr:0.84571\tvalidation-IoU:0.76851\n",
      "[50]\ttrain-aucpr:0.88947\ttrain-IoU:0.77560\tvalidation-aucpr:0.88136\tvalidation-IoU:0.77188\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 20\n",
      "Threshold    : 0.628\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.49\n",
      "Recall       : 0.84\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 20%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg020pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 30% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 32,318\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    32318\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 30%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg030pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 67,029\n",
      "  Val  : 19,152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.80539\ttrain-IoU:0.69482\tvalidation-aucpr:0.79908\tvalidation-IoU:0.69228\n",
      "[50]\ttrain-aucpr:0.84721\ttrain-IoU:0.69868\tvalidation-aucpr:0.83032\tvalidation-IoU:0.69641\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 30\n",
      "Threshold    : 0.628\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 30%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg030pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 40% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 43,090\n",
      "Class counts in sweep train/val dataset:\n",
      "1    53863\n",
      "0    43090\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 40%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg040pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 75,407\n",
      "  Val  : 21,546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.76568\ttrain-IoU:0.63007\tvalidation-aucpr:0.75925\tvalidation-IoU:0.62739\n",
      "[49]\ttrain-aucpr:0.80423\ttrain-IoU:0.63780\tvalidation-aucpr:0.79567\tvalidation-IoU:0.63540\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 40\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.47\n",
      "Recall       : 0.91\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 40%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg040pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 50% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 53,863\n",
      "Class counts in sweep train/val dataset:\n",
      "0    53863\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 50%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg050pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 83,786\n",
      "  Val  : 23,940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.71451\ttrain-IoU:0.57899\tvalidation-aucpr:0.71733\tvalidation-IoU:0.57579\n",
      "[50]\ttrain-aucpr:0.76831\ttrain-IoU:0.58813\tvalidation-aucpr:0.76432\tvalidation-IoU:0.58531\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 50\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 50%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg050pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 60% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 64,636\n",
      "Class counts in sweep train/val dataset:\n",
      "0    64636\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 60%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg060pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 92,165\n",
      "  Val  : 26,334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.68684\ttrain-IoU:0.53469\tvalidation-aucpr:0.68412\tvalidation-IoU:0.53198\n",
      "[50]\ttrain-aucpr:0.73585\ttrain-IoU:0.54524\tvalidation-aucpr:0.72637\tvalidation-IoU:0.54133\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 60\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.47\n",
      "Recall       : 0.93\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 60%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg060pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 70% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 75,408\n",
      "Class counts in sweep train/val dataset:\n",
      "0    75408\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 70%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg070pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 100,544\n",
      "  Val  : 28,727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.66124\ttrain-IoU:0.50079\tvalidation-aucpr:0.65555\tvalidation-IoU:0.49704\n",
      "[49]\ttrain-aucpr:0.70731\ttrain-IoU:0.50893\tvalidation-aucpr:0.69685\tvalidation-IoU:0.50550\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 70\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.47\n",
      "Recall       : 0.93\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 70%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg070pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 80% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 86,181\n",
      "Class counts in sweep train/val dataset:\n",
      "0    86181\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 80%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg080pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 108,923\n",
      "  Val  : 31,121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.62655\ttrain-IoU:0.46456\tvalidation-aucpr:0.62056\tvalidation-IoU:0.46380\n",
      "[50]\ttrain-aucpr:0.68044\ttrain-IoU:0.47834\tvalidation-aucpr:0.66619\tvalidation-IoU:0.47560\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 80\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.88\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 80%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg080pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 90% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 96,953\n",
      "Class counts in sweep train/val dataset:\n",
      "0    96953\n",
      "1    53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 90%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg090pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 117,301\n",
      "  Val  : 33,515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.60045\ttrain-IoU:0.43826\tvalidation-aucpr:0.59911\tvalidation-IoU:0.43789\n",
      "[50]\ttrain-aucpr:0.65341\ttrain-IoU:0.44944\tvalidation-aucpr:0.64669\tvalidation-IoU:0.44917\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 90\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.91\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 90%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg090pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 100% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 100%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg100pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58942\ttrain-IoU:0.43327\tvalidation-aucpr:0.59210\tvalidation-IoU:0.43187\n",
      "[50]\ttrain-aucpr:0.64632\ttrain-IoU:0.44077\tvalidation-aucpr:0.64070\tvalidation-IoU:0.43901\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 100\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.91\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 100%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg100pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 110% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 110%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg110pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59052\ttrain-IoU:0.43747\tvalidation-aucpr:0.59223\tvalidation-IoU:0.43650\n",
      "[50]\ttrain-aucpr:0.64578\ttrain-IoU:0.44120\tvalidation-aucpr:0.63988\tvalidation-IoU:0.44027\n",
      "[51]\ttrain-aucpr:0.64633\ttrain-IoU:0.44127\tvalidation-aucpr:0.64022\tvalidation-IoU:0.44018\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 110\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 110%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg110pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 120% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 120%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg120pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58990\ttrain-IoU:0.43768\tvalidation-aucpr:0.58639\tvalidation-IoU:0.43738\n",
      "[50]\ttrain-aucpr:0.64595\ttrain-IoU:0.44095\tvalidation-aucpr:0.63768\tvalidation-IoU:0.43982\n",
      "[52]\ttrain-aucpr:0.64781\ttrain-IoU:0.44114\tvalidation-aucpr:0.63920\tvalidation-IoU:0.44022\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 120\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 120%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg120pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 130% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 130%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg130pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59073\ttrain-IoU:0.43852\tvalidation-aucpr:0.58905\tvalidation-IoU:0.43788\n",
      "[50]\ttrain-aucpr:0.64604\ttrain-IoU:0.44103\tvalidation-aucpr:0.63857\tvalidation-IoU:0.44063\n",
      "[51]\ttrain-aucpr:0.64642\ttrain-IoU:0.44112\tvalidation-aucpr:0.63896\tvalidation-IoU:0.44075\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 130\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 130%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg130pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 140% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 140%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg140pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59031\ttrain-IoU:0.43766\tvalidation-aucpr:0.58869\tvalidation-IoU:0.43864\n",
      "[50]\ttrain-aucpr:0.64631\ttrain-IoU:0.44054\tvalidation-aucpr:0.63677\tvalidation-IoU:0.44186\n",
      "[52]\ttrain-aucpr:0.64799\ttrain-IoU:0.44071\tvalidation-aucpr:0.63853\tvalidation-IoU:0.44185\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 140\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 140%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg140pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 150% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 150%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg150pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n",
      "[0]\ttrain-aucpr:0.58999\ttrain-IoU:0.43729\tvalidation-aucpr:0.59164\tvalidation-IoU:0.43576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-aucpr:0.64607\ttrain-IoU:0.44089\tvalidation-aucpr:0.63986\tvalidation-IoU:0.43845\n",
      "[51]\ttrain-aucpr:0.64653\ttrain-IoU:0.44093\tvalidation-aucpr:0.64033\tvalidation-IoU:0.43868\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 150\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.88\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 150%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg150pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 160% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 160%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg160pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58979\ttrain-IoU:0.43656\tvalidation-aucpr:0.59347\tvalidation-IoU:0.43470\n",
      "[50]\ttrain-aucpr:0.64510\ttrain-IoU:0.44158\tvalidation-aucpr:0.64296\tvalidation-IoU:0.43902\n",
      "[52]\ttrain-aucpr:0.64687\ttrain-IoU:0.44161\tvalidation-aucpr:0.64455\tvalidation-IoU:0.43917\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 160\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.89\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 160%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg160pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 170% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 170%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg170pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58952\ttrain-IoU:0.43730\tvalidation-aucpr:0.58468\tvalidation-IoU:0.43616\n",
      "[50]\ttrain-aucpr:0.64623\ttrain-IoU:0.44097\tvalidation-aucpr:0.63700\tvalidation-IoU:0.43832\n",
      "[51]\ttrain-aucpr:0.64687\ttrain-IoU:0.44102\tvalidation-aucpr:0.63754\tvalidation-IoU:0.43850\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 170\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 170%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg170pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 180% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 180%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg180pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58937\ttrain-IoU:0.43725\tvalidation-aucpr:0.58738\tvalidation-IoU:0.43597\n",
      "[50]\ttrain-aucpr:0.64735\ttrain-IoU:0.44185\tvalidation-aucpr:0.63689\tvalidation-IoU:0.43913\n",
      "[51]\ttrain-aucpr:0.64803\ttrain-IoU:0.44196\tvalidation-aucpr:0.63766\tvalidation-IoU:0.43925\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 180\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 180%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg180pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 190% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 190%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg190pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59021\ttrain-IoU:0.43772\tvalidation-aucpr:0.58984\tvalidation-IoU:0.43733\n",
      "[50]\ttrain-aucpr:0.64567\ttrain-IoU:0.44089\tvalidation-aucpr:0.64148\tvalidation-IoU:0.44055\n",
      "[51]\ttrain-aucpr:0.64622\ttrain-IoU:0.44105\tvalidation-aucpr:0.64184\tvalidation-IoU:0.44054\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 190\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 190%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg190pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 200% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 200%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg200pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58995\ttrain-IoU:0.42642\tvalidation-aucpr:0.58748\tvalidation-IoU:0.42452\n",
      "[49]\ttrain-aucpr:0.64639\ttrain-IoU:0.44115\tvalidation-aucpr:0.63925\tvalidation-IoU:0.43874\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 200\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.89\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 200%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg200pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 210% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 210%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg210pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59121\ttrain-IoU:0.43762\tvalidation-aucpr:0.58683\tvalidation-IoU:0.43545\n",
      "[50]\ttrain-aucpr:0.64824\ttrain-IoU:0.44103\tvalidation-aucpr:0.63334\tvalidation-IoU:0.43828\n",
      "[51]\ttrain-aucpr:0.64872\ttrain-IoU:0.44112\tvalidation-aucpr:0.63381\tvalidation-IoU:0.43842\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 210\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.91\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 210%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg210pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 220% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 220%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg220pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58827\ttrain-IoU:0.43862\tvalidation-aucpr:0.58885\tvalidation-IoU:0.43695\n",
      "[50]\ttrain-aucpr:0.64500\ttrain-IoU:0.44113\tvalidation-aucpr:0.64267\tvalidation-IoU:0.43889\n",
      "[53]\ttrain-aucpr:0.64812\ttrain-IoU:0.44144\tvalidation-aucpr:0.64492\tvalidation-IoU:0.43901\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 220\n",
      "Threshold    : 0.638\n",
      "IoU (Jaccard): 0.47\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.64\n",
      "Saved weighted-logloss feature importance plot for 220%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg220pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 230% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 230%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg230pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58151\ttrain-IoU:0.43356\tvalidation-aucpr:0.57864\tvalidation-IoU:0.43139\n",
      "[50]\ttrain-aucpr:0.64679\ttrain-IoU:0.44185\tvalidation-aucpr:0.63893\tvalidation-IoU:0.43896\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 230\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 230%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg230pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 240% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 240%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg240pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58844\ttrain-IoU:0.43321\tvalidation-aucpr:0.58866\tvalidation-IoU:0.43204\n",
      "[50]\ttrain-aucpr:0.64757\ttrain-IoU:0.44092\tvalidation-aucpr:0.63938\tvalidation-IoU:0.44032\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 240\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 240%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg240pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 250% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 250%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg250pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.57938\ttrain-IoU:0.43823\tvalidation-aucpr:0.58263\tvalidation-IoU:0.43810\n",
      "[50]\ttrain-aucpr:0.64513\ttrain-IoU:0.44091\tvalidation-aucpr:0.63987\tvalidation-IoU:0.44107\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 250\n",
      "Threshold    : 0.631\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 250%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg250pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 260% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 260%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg260pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58961\ttrain-IoU:0.43874\tvalidation-aucpr:0.58677\tvalidation-IoU:0.43859\n",
      "[50]\ttrain-aucpr:0.64662\ttrain-IoU:0.44083\tvalidation-aucpr:0.64020\tvalidation-IoU:0.44033\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 260\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.88\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 260%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg260pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 270% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 270%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg270pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59017\ttrain-IoU:0.43499\tvalidation-aucpr:0.59005\tvalidation-IoU:0.43193\n",
      "[50]\ttrain-aucpr:0.64622\ttrain-IoU:0.44139\tvalidation-aucpr:0.63732\tvalidation-IoU:0.43822\n",
      "[51]\ttrain-aucpr:0.64655\ttrain-IoU:0.44147\tvalidation-aucpr:0.63779\tvalidation-IoU:0.43837\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 270\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.80\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 270%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg270pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 280% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 280%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg280pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59148\ttrain-IoU:0.43801\tvalidation-aucpr:0.58915\tvalidation-IoU:0.43810\n",
      "[50]\ttrain-aucpr:0.64598\ttrain-IoU:0.44098\tvalidation-aucpr:0.63880\tvalidation-IoU:0.44016\n",
      "[51]\ttrain-aucpr:0.64656\ttrain-IoU:0.44102\tvalidation-aucpr:0.63935\tvalidation-IoU:0.44024\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 280\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 280%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg280pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 290% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 290%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg290pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58833\ttrain-IoU:0.44099\tvalidation-aucpr:0.58856\tvalidation-IoU:0.44060\n",
      "[50]\ttrain-aucpr:0.64762\ttrain-IoU:0.44138\tvalidation-aucpr:0.64325\tvalidation-IoU:0.43997\n",
      "[51]\ttrain-aucpr:0.64808\ttrain-IoU:0.44145\tvalidation-aucpr:0.64344\tvalidation-IoU:0.44026\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 290\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 290%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg290pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 300% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 300%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg300pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58070\ttrain-IoU:0.43822\tvalidation-aucpr:0.58446\tvalidation-IoU:0.43835\n",
      "[50]\ttrain-aucpr:0.64572\ttrain-IoU:0.44063\tvalidation-aucpr:0.64182\tvalidation-IoU:0.44007\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 300\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 300%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg300pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 310% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 310%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg310pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59093\ttrain-IoU:0.43818\tvalidation-aucpr:0.59077\tvalidation-IoU:0.43631\n",
      "[50]\ttrain-aucpr:0.64519\ttrain-IoU:0.44123\tvalidation-aucpr:0.64115\tvalidation-IoU:0.43905\n",
      "[51]\ttrain-aucpr:0.64564\ttrain-IoU:0.44131\tvalidation-aucpr:0.64136\tvalidation-IoU:0.43920\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 310\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 310%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg310pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 320% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 320%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg320pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58126\ttrain-IoU:0.42703\tvalidation-aucpr:0.58311\tvalidation-IoU:0.42541\n",
      "[49]\ttrain-aucpr:0.64587\ttrain-IoU:0.44120\tvalidation-aucpr:0.64030\tvalidation-IoU:0.43916\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 320\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 320%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg320pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 330% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 330%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg330pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58033\ttrain-IoU:0.43224\tvalidation-aucpr:0.57772\tvalidation-IoU:0.43050\n",
      "[50]\ttrain-aucpr:0.64626\ttrain-IoU:0.44114\tvalidation-aucpr:0.63900\tvalidation-IoU:0.43904\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 330\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 330%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg330pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 340% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 340%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg340pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58875\ttrain-IoU:0.43639\tvalidation-aucpr:0.58881\tvalidation-IoU:0.43611\n",
      "[50]\ttrain-aucpr:0.64564\ttrain-IoU:0.44066\tvalidation-aucpr:0.64332\tvalidation-IoU:0.43994\n",
      "[52]\ttrain-aucpr:0.64727\ttrain-IoU:0.44080\tvalidation-aucpr:0.64470\tvalidation-IoU:0.44022\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 340\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.49\n",
      "Recall       : 0.89\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 340%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg340pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 350% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 350%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg350pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59093\ttrain-IoU:0.43848\tvalidation-aucpr:0.58767\tvalidation-IoU:0.43777\n",
      "[50]\ttrain-aucpr:0.64763\ttrain-IoU:0.44132\tvalidation-aucpr:0.63404\tvalidation-IoU:0.43998\n",
      "[51]\ttrain-aucpr:0.64833\ttrain-IoU:0.44136\tvalidation-aucpr:0.63470\tvalidation-IoU:0.44014\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 350\n",
      "Threshold    : 0.630\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.91\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 350%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg350pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 360% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 360%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg360pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58989\ttrain-IoU:0.43909\tvalidation-aucpr:0.58979\tvalidation-IoU:0.43923\n",
      "[50]\ttrain-aucpr:0.64439\ttrain-IoU:0.44068\tvalidation-aucpr:0.63841\tvalidation-IoU:0.44055\n",
      "[51]\ttrain-aucpr:0.64504\ttrain-IoU:0.44079\tvalidation-aucpr:0.63897\tvalidation-IoU:0.44066\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 360\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.52\n",
      "Recall       : 0.81\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 360%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg360pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 370% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 370%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg370pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59145\ttrain-IoU:0.42675\tvalidation-aucpr:0.58550\tvalidation-IoU:0.42549\n",
      "[50]\ttrain-aucpr:0.64843\ttrain-IoU:0.44086\tvalidation-aucpr:0.63146\tvalidation-IoU:0.43911\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 370\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.45\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.62\n",
      "Saved weighted-logloss feature importance plot for 370%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg370pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 380% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 380%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg380pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.59049\ttrain-IoU:0.43901\tvalidation-aucpr:0.58961\tvalidation-IoU:0.43798\n",
      "[50]\ttrain-aucpr:0.64526\ttrain-IoU:0.44098\tvalidation-aucpr:0.64010\tvalidation-IoU:0.43948\n",
      "[51]\ttrain-aucpr:0.64587\ttrain-IoU:0.44113\tvalidation-aucpr:0.64059\tvalidation-IoU:0.43959\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 380\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 380%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg380pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 390% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 390%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg390pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58846\ttrain-IoU:0.42588\tvalidation-aucpr:0.58807\tvalidation-IoU:0.42607\n",
      "[50]\ttrain-aucpr:0.64681\ttrain-IoU:0.44085\tvalidation-aucpr:0.64135\tvalidation-IoU:0.43991\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 390\n",
      "Threshold    : 0.627\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 390%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg390pct_weightedlogloss.png\n",
      "\n",
      "======================================================================\n",
      "== Option 4 (Weighted log loss): NEGATIVE PERCENT = 400% (100% = 2x positives in train/val) ==\n",
      "Target negatives for this sweep: 101,001\n",
      "Class counts in sweep train/val dataset:\n",
      "0    101001\n",
      "1     53863\n",
      "Name: burned, dtype: int64\n",
      "Saved sweep train/val parquet for 400%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/trainval_data_neg400pct_weightedlogloss.parquet\n",
      "\n",
      "Sweep split sizes:\n",
      "  Train: 120,449\n",
      "  Val  : 34,415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.conda/envs/xgboost_gpu/lib/python3.9/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-aucpr:0.58582\ttrain-IoU:0.43895\tvalidation-aucpr:0.58266\tvalidation-IoU:0.43980\n",
      "[50]\ttrain-aucpr:0.64534\ttrain-IoU:0.44116\tvalidation-aucpr:0.63924\tvalidation-IoU:0.44019\n",
      "[52]\ttrain-aucpr:0.64729\ttrain-IoU:0.44144\tvalidation-aucpr:0.64114\tvalidation-IoU:0.44032\n",
      "\n",
      "==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\n",
      "NEG % in train/val (100%=2x pos): 400\n",
      "Threshold    : 0.634\n",
      "IoU (Jaccard): 0.46\n",
      "Precision    : 0.48\n",
      "Recall       : 0.90\n",
      "F1 Score     : 0.63\n",
      "Saved weighted-logloss feature importance plot for 400%: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/feature_importance_neg400pct_weightedlogloss.png\n",
      "\n",
      "Saved Option 4 (weighted log loss) global-test sweep summary to: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest/option4_weighted_logloss/option4_weightedlogloss_neg_ratio_sweep_globaltest_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Option 4 (Weighted log loss, global fixed test set) with robust fallback:\n",
    "- Try LightGBM core API with custom weighted log loss via fobj.\n",
    "- If LightGBM lacks `fobj`, fall back to XGBoost with the same weighted loss.\n",
    "- Threshold stored as a true probability in [0,1]; metrics rounded in CSV.\n",
    "\n",
    "Outputs under:\n",
    ".../neg_ratio_experiments_globaltest/option4_weighted_logloss/\n",
    "\"\"\"\n",
    "\n",
    "import os, inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    jaccard_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "PARQUET_IN    = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/cems_with_fraction.parquet\"\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "TEST_SIZE_GLOBAL = 0.10\n",
    "VAL_SIZE_OVERALL = 0.20\n",
    "\n",
    "THRESH_INIT   = 0.50     # only for IoU logging / feval\n",
    "RECALL_FLOOR  = 0.80\n",
    "TOP_N_IMPORT  = 30\n",
    "\n",
    "# 10%..400% (100% â 2x negatives per positive; 400% â 8x)\n",
    "PCT_STEPS     = list(range(10, 401, 10))\n",
    "MAX_SAMPLES_POS_TRAINVAL = None\n",
    "\n",
    "# Weight for false negatives in custom loss\n",
    "FN_WEIGHT = 10.0\n",
    "\n",
    "LGB_PARAMS = dict(\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=48,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.75,\n",
    "    bagging_fraction=0.75,\n",
    "    bagging_freq=5,\n",
    "    lambda_l2=2.0,\n",
    "    n_jobs=-1,\n",
    "    metric=\"aucpr\",\n",
    ")\n",
    "\n",
    "OUT_ROOT = \"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/neg_ratio_experiments_globaltest\"\n",
    "OUT_DIR  = os.path.join(OUT_ROOT, \"option4_weighted_logloss\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def lgb_has_fobj():\n",
    "    try:\n",
    "        import inspect as _inspect\n",
    "        sig = _inspect.signature(lgb.train)\n",
    "        return \"fobj\" in sig.parameters\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# --- WEIGHTED LOG LOSS for LightGBM (margin -> grad/hess) ---\n",
    "def weighted_logloss_lgb(y_pred, dataset):\n",
    "    \"\"\"\n",
    "    Custom weighted log loss for LightGBM:\n",
    "    - Higher weight on positives (to penalize false negatives).\n",
    "    \"\"\"\n",
    "    y_true = dataset.get_label()\n",
    "    pred_prob = sigmoid(y_pred)\n",
    "\n",
    "    grad = pred_prob - y_true\n",
    "    grad[y_true == 1] *= FN_WEIGHT\n",
    "\n",
    "    hess = pred_prob * (1.0 - pred_prob)\n",
    "    hess[y_true == 1] *= FN_WEIGHT\n",
    "\n",
    "    return grad, hess\n",
    "\n",
    "# Same math for XGBoost (preds, dtrain signature)\n",
    "def weighted_logloss_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    pred_prob = sigmoid(preds)\n",
    "\n",
    "    grad = pred_prob - y_true\n",
    "    grad[y_true == 1] *= FN_WEIGHT\n",
    "\n",
    "    hess = pred_prob * (1.0 - pred_prob)\n",
    "    hess[y_true == 1] *= FN_WEIGHT\n",
    "\n",
    "    return grad, hess\n",
    "\n",
    "def iou_metric_lgb(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    y_hat  = (sigmoid(y_pred) >= THRESH_INIT).astype(np.uint8)\n",
    "    iou    = jaccard_score(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    return \"IoU\", float(iou), True\n",
    "\n",
    "# ----------------- LOAD & PREP -----------------\n",
    "print(f\"Loading: {PARQUET_IN}\")\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "if \"fraction\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'fraction' in dataset.\")\n",
    "\n",
    "df[\"fraction\"] = df[\"fraction\"].astype(\"float32\").clip(0, 1)\n",
    "before = len(df)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how=\"any\").copy()\n",
    "print(f\"Dropped {before - len(df):,} rows with NaNs/Â±inf; {len(df):,} remain.\")\n",
    "\n",
    "df[\"burned\"] = (df[\"fraction\"] > THRESH_INIT).astype(np.uint8)\n",
    "print(\"\\nClass counts before any splitting:\")\n",
    "print(df[\"burned\"].value_counts(dropna=False))\n",
    "\n",
    "drop_cols = {\"fraction\", \"burned\", \"bin\", \"year\", \"month\", \"latitude\", \"longitude\"}\n",
    "predictors = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "X_full = df[predictors].copy()\n",
    "y_full = df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "if \"b1\" in X_full.columns and not pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "    X_full[\"b1\"] = X_full[\"b1\"].astype(\"category\")\n",
    "    print(\"\\nTreating 'b1' as pandas 'category'.\")\n",
    "\n",
    "coerced = 0\n",
    "for c in X_full.columns:\n",
    "    if c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[c]):\n",
    "        continue\n",
    "    if not np.issubdtype(X_full[c].dtype, np.number):\n",
    "        X_full[c] = pd.to_numeric(X_full[c], errors=\"coerce\")\n",
    "        coerced += 1\n",
    "\n",
    "if coerced:\n",
    "    pre = len(X_full)\n",
    "    num_cols = [c for c in X_full.columns if not (c == \"b1\" and pd.api.types.is_categorical_dtype(X_full[\"b1\"]))]\n",
    "    mask = X_full[num_cols].notna().all(axis=1)\n",
    "    if \"b1\" in X_full.columns and pd.api.types.is_categorical_dtype(X_full[\"b1\"]):\n",
    "        mask &= X_full[\"b1\"].notna()\n",
    "    X_full = X_full.loc[mask].copy()\n",
    "    y_full = y_full.loc[X_full.index]\n",
    "    print(f\"Coerced {coerced} column(s); dropped {pre - len(X_full):,} rows post-coercion.\")\n",
    "print(f\"\\nPredictor columns: {len(X_full.columns)}\")\n",
    "\n",
    "data = X_full.copy()\n",
    "data[\"burned\"] = y_full\n",
    "\n",
    "# Global split (fixed test with true distribution)\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    data.index,\n",
    "    test_size=TEST_SIZE_GLOBAL,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=data[\"burned\"],\n",
    ")\n",
    "trainval = data.loc[idx_trainval].copy()\n",
    "test     = data.loc[idx_test].copy()\n",
    "\n",
    "print(\"\\nGlobal split sizes (true distribution in test):\")\n",
    "print(f\"  Train/Val pool: {len(trainval):,}\")\n",
    "print(f\"  Test (fixed)  : {len(test):,}\")\n",
    "print(\"\\nTest set class counts:\")\n",
    "print(test[\"burned\"].value_counts())\n",
    "\n",
    "X_test = test[predictors].copy()\n",
    "y_test = test[\"burned\"].astype(np.uint8)\n",
    "\n",
    "# Test set class counts (constant across sweeps)\n",
    "test_pos = int((y_test == 1).sum())\n",
    "test_neg = int((y_test == 0).sum())\n",
    "print(f\"\\nTest set positives (1): {test_pos:,}\")\n",
    "print(f\"Test set negatives (0): {test_neg:,}\")\n",
    "\n",
    "pos_tv = trainval[trainval[\"burned\"] == 1]\n",
    "neg_tv = trainval[trainval[\"burned\"] == 0]\n",
    "n_pos_tv, n_neg_tv = len(pos_tv), len(neg_tv)\n",
    "print(\"\\nTrain/Val pool class counts:\")\n",
    "print(trainval[\"burned\"].value_counts())\n",
    "if n_pos_tv == 0 or n_neg_tv == 0:\n",
    "    raise ValueError(\"Train/Val pool has only one class; cannot proceed.\")\n",
    "\n",
    "# Fix positive subset in train/val pool (optionally capped)\n",
    "target_pos = n_pos_tv if MAX_SAMPLES_POS_TRAINVAL is None else min(n_pos_tv, MAX_SAMPLES_POS_TRAINVAL)\n",
    "pos_tv_s = pos_tv.sample(n=target_pos, random_state=RANDOM_STATE)\n",
    "n_pos_eff = len(pos_tv_s)\n",
    "print(f\"\\nEffective positive samples in train/val sweeps: {n_pos_eff:,}\")\n",
    "\n",
    "USE_LGB_FOBJ = lgb_has_fobj()\n",
    "if not USE_LGB_FOBJ:\n",
    "    print(\"\\n[INFO] LightGBM build lacks `fobj` support on train(); falling back to XGBoost for weighted log loss.\")\n",
    "    import xgboost as xgb  # imported only when needed\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ----------------- SWEEP -----------------\n",
    "for pct in PCT_STEPS:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"== Option 4 (Weighted log loss): NEGATIVE PERCENT = {pct}% (100% = 2x positives in train/val) ==\")\n",
    "\n",
    "    neg_target = int(round((pct / 100.0) * 2.0 * n_pos_eff))\n",
    "    neg_target = max(1, min(neg_target, n_neg_tv))\n",
    "    print(f\"Target negatives for this sweep: {neg_target:,}\")\n",
    "\n",
    "    neg_tv_s = neg_tv.sample(n=neg_target, random_state=RANDOM_STATE + pct)\n",
    "\n",
    "    sweep_df = (\n",
    "        pd.concat([pos_tv_s, neg_tv_s], axis=0)\n",
    "        .sample(frac=1.0, random_state=RANDOM_STATE)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    print(\"Class counts in sweep train/val dataset:\")\n",
    "    print(sweep_df[\"burned\"].value_counts())\n",
    "\n",
    "    parquet_out = os.path.join(OUT_DIR, f\"trainval_data_neg{pct:03d}pct_weightedlogloss.parquet\")\n",
    "    sweep_df.to_parquet(parquet_out)\n",
    "    print(f\"Saved sweep train/val parquet for {pct}%: {parquet_out}\")\n",
    "\n",
    "    X_sweep = sweep_df[predictors].copy()\n",
    "    y_sweep = sweep_df[\"burned\"].astype(np.uint8)\n",
    "\n",
    "    val_size_inner = VAL_SIZE_OVERALL / (1.0 - TEST_SIZE_GLOBAL)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_sweep, y_sweep,\n",
    "        test_size=val_size_inner,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_sweep,\n",
    "    )\n",
    "\n",
    "    print(\"\\nSweep split sizes:\")\n",
    "    print(f\"  Train: {len(X_train):,}\")\n",
    "    print(f\"  Val  : {len(X_val):,}\")\n",
    "\n",
    "    evals_result = {}\n",
    "    if USE_LGB_FOBJ:\n",
    "        # ---------- LightGBM path with custom weighted log loss ----------\n",
    "        train_set = lgb.Dataset(X_train, label=y_train)\n",
    "        val_set   = lgb.Dataset(X_val, label=y_val, reference=train_set)\n",
    "        params = LGB_PARAMS.copy()\n",
    "        params[\"seed\"] = RANDOM_STATE\n",
    "        params[\"objective\"] = \"binary\"  # overridden by fobj\n",
    "\n",
    "        booster = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            num_boost_round=10000,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            valid_names=[\"train\", \"validation\"],\n",
    "            fobj=weighted_logloss_lgb,\n",
    "            feval=iou_metric_lgb,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(period=50),\n",
    "                lgb.record_evaluation(evals_result),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Learning curve (IoU)\n",
    "        if \"IoU\" in evals_result.get(\"train\", {}):\n",
    "            plt.figure(figsize=(8,5))\n",
    "            plt.plot(evals_result[\"train\"][\"IoU\"], label=\"Train IoU (weighted log loss)\")\n",
    "            plt.plot(evals_result[\"validation\"][\"IoU\"], label=\"Validation IoU (weighted log loss)\")\n",
    "            plt.xlabel(\"Boosting Rounds\"); plt.ylabel(\"IoU (Jaccard)\")\n",
    "            plt.title(\n",
    "                f\"Option 4 (Weighted log loss - LGB): Train vs Val IoU\\n\"\n",
    "                f\"NEG={pct}%  THRESH_INIT={THRESH_INIT:.2f}\"\n",
    "            )\n",
    "            plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "            iou_fig_out = os.path.join(OUT_DIR, f\"iou_curve_neg{pct:03d}pct_weightedlogloss.png\")\n",
    "            plt.savefig(iou_fig_out, dpi=150); plt.close()\n",
    "            print(f\"Saved IoU curve for {pct}%: {iou_fig_out}\")\n",
    "\n",
    "        # Validation probabilities (convert margins to probs)\n",
    "        y_val_proba = sigmoid(booster.predict(X_val, num_iteration=booster.best_iteration))\n",
    "        # ---------- end LightGBM path ----------\n",
    "\n",
    "    else:\n",
    "        # ---------- XGBoost fallback with custom objective ----------\n",
    "        import xgboost as xgb\n",
    "\n",
    "        def iou_metric_xgb(preds, dtrain):\n",
    "            y = dtrain.get_label()\n",
    "            y_hat = (sigmoid(preds) >= THRESH_INIT).astype(np.uint8)\n",
    "            iou = jaccard_score(y, y_hat, average=\"binary\", zero_division=0)\n",
    "            return \"IoU\", float(iou)\n",
    "\n",
    "        # >>>>>>>>>>>>> enable_categorical=True <<<<<<<<<<<<<<\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "        dval   = xgb.DMatrix(X_val,   label=y_val,   enable_categorical=True)\n",
    "\n",
    "        params_xgb = dict(\n",
    "            booster=\"gbtree\",\n",
    "            eta=0.05,\n",
    "            max_depth=0,        # use `max_leaves` with tree_method=hist\n",
    "            max_leaves=48,\n",
    "            subsample=0.75,\n",
    "            colsample_bytree=0.75,\n",
    "            reg_lambda=2.0,\n",
    "            tree_method=\"hist\",   # or \"gpu_hist\" if you want GPU\n",
    "            objective=\"reg:logistic\",  # overridden by custom obj\n",
    "            eval_metric=\"aucpr\",\n",
    "            seed=RANDOM_STATE,\n",
    "            nthread=-1,\n",
    "        )\n",
    "\n",
    "        watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "        booster = xgb.train(\n",
    "            params_xgb,\n",
    "            dtrain,\n",
    "            num_boost_round=10000,\n",
    "            evals=watchlist,\n",
    "            obj=weighted_logloss_xgb,\n",
    "            feval=iou_metric_xgb,\n",
    "            verbose_eval=50,\n",
    "            early_stopping_rounds=50,\n",
    "        )\n",
    "\n",
    "        # Validation probabilities (margins -> probs)\n",
    "        y_val_proba = sigmoid(\n",
    "            booster.predict(dval, iteration_range=(0, booster.best_iteration + 1))\n",
    "        )\n",
    "        # ---------- end XGBoost path ----------\n",
    "\n",
    "    # Threshold selection (validation) with recall floor\n",
    "    prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "    mask = rec[:-1] >= RECALL_FLOOR\n",
    "    if not np.any(mask):\n",
    "        best_idx = np.argmax(prec[:-1])\n",
    "    else:\n",
    "        best_idx = np.flatnonzero(mask)[np.argmax(prec[:-1][mask])]\n",
    "    best_thr = float(thr[best_idx])\n",
    "\n",
    "    # Test metrics (fixed global test)\n",
    "    if USE_LGB_FOBJ:\n",
    "        y_test_proba = sigmoid(\n",
    "            booster.predict(X_test, num_iteration=booster.best_iteration)\n",
    "        )\n",
    "    else:\n",
    "        import xgboost as xgb\n",
    "        dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
    "        y_test_proba = sigmoid(\n",
    "            booster.predict(dtest, iteration_range=(0, booster.best_iteration + 1))\n",
    "        )\n",
    "\n",
    "    y_test_hat = (y_test_proba >= best_thr).astype(np.uint8)\n",
    "    test_iou  = jaccard_score(y_test, y_test_hat, average=\"binary\", zero_division=0)\n",
    "    test_prec = precision_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_rec  = recall_score(y_test, y_test_hat, zero_division=0)\n",
    "    test_f1   = f1_score(y_test, y_test_hat, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== FINAL TEST METRICS (weighted log loss, fixed global test set) ====\")\n",
    "    print(f\"NEG % in train/val (100%=2x pos): {pct}\")\n",
    "    print(f\"Threshold    : {best_thr:.3f}\")\n",
    "    print(f\"IoU (Jaccard): {test_iou:.2f}\")\n",
    "    print(f\"Precision    : {test_prec:.2f}\")\n",
    "    print(f\"Recall       : {test_rec:.2f}\")\n",
    "    print(f\"F1 Score     : {test_f1:.2f}\")\n",
    "\n",
    "    summary_rows.append(\n",
    "        dict(\n",
    "            neg_percent=pct,\n",
    "            n_pos_train=int((y_sweep == 1).sum()),\n",
    "            n_neg_train=int((y_sweep == 0).sum()),\n",
    "            test_pos=test_pos,          # number of 1s in test set\n",
    "            test_neg=test_neg,          # number of 0s in test set\n",
    "            fn_weight=FN_WEIGHT,\n",
    "            threshold=round(best_thr, 3),        # 0â1\n",
    "            test_iou=round(test_iou, 2),\n",
    "            test_precision=round(test_prec, 2),\n",
    "            test_recall=round(test_rec, 2),\n",
    "            test_f1=round(test_f1, 2),\n",
    "            best_iteration=int(\n",
    "                getattr(booster, \"best_iteration\", getattr(booster, \"best_ntree_limit\", 0))\n",
    "            ),\n",
    "            backend=(\"lightgbm\" if USE_LGB_FOBJ else \"xgboost\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Feature importance (gain)\n",
    "    if USE_LGB_FOBJ:\n",
    "        gain_imp = booster.feature_importance(importance_type=\"gain\")\n",
    "        feat_names = np.array(X_train.columns)\n",
    "    else:\n",
    "        fmap = booster.get_score(importance_type=\"gain\")\n",
    "        feat_names = np.array(X_train.columns)\n",
    "        gain_imp = np.array(\n",
    "            [fmap.get(f\"f{i}\", 0.0) for i in range(len(feat_names))],\n",
    "            dtype=float,\n",
    "        )\n",
    "\n",
    "    gain_imp = gain_imp / (gain_imp.sum() + 1e-12)\n",
    "    order = np.argsort(gain_imp)[::-1][:TOP_N_IMPORT]\n",
    "\n",
    "    plt.figure(figsize=(9, max(5, 0.28 * len(order))))\n",
    "    plt.barh(feat_names[order][::-1], gain_imp[order][::-1])\n",
    "    plt.xlabel(\"Relative Gain Importance\")\n",
    "    plt.title(\n",
    "        f\"Option 4 (Weighted log loss, {('LGB' if USE_LGB_FOBJ else 'XGB')}): \"\n",
    "        f\"Feature Importance (Top {len(order)})\\nNEG={pct}% (100% = 2x positives)\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fi_fig_out = os.path.join(OUT_DIR, f\"feature_importance_neg{pct:03d}pct_weightedlogloss.png\")\n",
    "    plt.savefig(fi_fig_out, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved weighted-logloss feature importance plot for {pct}%: {fi_fig_out}\")\n",
    "\n",
    "# ----------------- SUMMARY CSV -----------------\n",
    "if summary_rows:\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv = os.path.join(OUT_DIR, \"option4_weightedlogloss_neg_ratio_sweep_globaltest_metrics.csv\")\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\nSaved Option 4 (weighted log loss) global-test sweep summary to: {summary_csv}\")\n",
    "else:\n",
    "    print(\"\\nNo sweeps were run; summary not saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
