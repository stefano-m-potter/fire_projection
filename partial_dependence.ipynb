{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff04e179-d67c-4f90-bf30-b7f38397529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Parquet dataset from:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\n",
      "Warning: 'year' column not found. Yearly analysis will be skipped.\n",
      "\n",
      "Data Loaded & Split Replicated.\n",
      "Test Set Size: 7458650\n",
      "Loading model from: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\n",
      "Re-calculating best threshold on Validation set (Max F1)...\n",
      "Best Validation Threshold: 0.95 (F1: 0.9640)\n",
      "\n",
      "=== TEST METRICS ===\n",
      "Test PR-AUC (threshold-free): 0.972710\n",
      "Threshold used: 0.95\n",
      "Precision: 0.9800\n",
      "Recall    : 0.9460\n",
      "F1        : 0.9627\n",
      "IoU       : 0.9280\n",
      "\n",
      "Artifacts saved to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical\n",
      "Best model loaded from:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\n",
      "\n",
      "Generating Feature Importance Plot...\n",
      " Saved feature_importance.png\n",
      "\n",
      "Generating Partial Dependence Plots (Log-Odds)...\n",
      " Saved partial_dependence_plot_logodds.png\n",
      "\n",
      "Comparing Burned Areas...\n",
      "\n",
      "[INFO] 'year' column not available. Calculating total sums only.\n",
      "Total Observed Pixels: 19344\n",
      "Total Predicted Pixels: 18673\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Evaluate XGBoost Model (Native API)\n",
    "-- LOADS EXISTING MODEL --\n",
    "-- UPDATED: Partial Dependence Plots now use LOG-ODDS --\n",
    "\n",
    "Tasks:\n",
    "1. Load dataset & replicate train/val/test splits (Random State 42).\n",
    "2. Load saved native XGBoost model.\n",
    "3. Re-determine best threshold from Validation set (Max F1).\n",
    "4. Evaluate on Test set (Print metrics).\n",
    "5. Generate Feature Importance Plot.\n",
    "6. Generate Multi-panel Partial Dependence Plots (PDP) in LOG-ODDS.\n",
    "7. Compare Predicted vs Observed Burned Area (Total & Yearly).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG (Must match Training Script)\n",
    "# ============================================================\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# DATASET & MODEL PATHS\n",
    "DATASET_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\"\n",
    ")\n",
    "\n",
    "# Directory where your model was saved\n",
    "MODEL_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical\"\n",
    ")\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"models\" / \"xgb_best_pr_auc.json\"\n",
    "FIGS_DIR = MODEL_DIR / \"eval_figures\"\n",
    "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = [\n",
    "    \"DEM\", \"slope\", \"aspect\", \"b1\", \"relative_humidity\", \n",
    "    \"total_precipitation_sum\", \"temperature_2m\", \"temperature_2m_min\", \n",
    "    \"temperature_2m_max\", \"build_up_index\", \"drought_code\", \n",
    "    \"duff_moisture_code\", \"fine_fuel_moisture_code\", \n",
    "    \"fire_weather_index\", \"initial_fire_spread_index\",\n",
    "]\n",
    "\n",
    "FRACTION_COL = \"fraction\"\n",
    "LABEL_COL = \"burned\"\n",
    "\n",
    "# We attempt to load 'year' for the area analysis. \n",
    "# If your dataset calls it 'time' or something else, update this.\n",
    "YEAR_COL = \"year\" \n",
    "\n",
    "TEST_SIZE = 0.10\n",
    "VAL_SIZE  = 0.20\n",
    "THRESHOLDS = np.round(np.arange(0.05, 0.96, 0.05), 2)\n",
    "N_JOBS = 6\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "\n",
    "class XGBNativeSklearnWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper to make a native xgb.Booster look like an sklearn estimator.\n",
    "    \"\"\"\n",
    "    def __init__(self, booster, feature_names):\n",
    "        self.booster = booster\n",
    "        self.feature_names = feature_names\n",
    "        self.dummy_ = True\n",
    "        self._estimator_type = \"classifier\"\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Returns Probabilities\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        else:\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        \n",
    "        preds = self.booster.predict(dmat)\n",
    "        return np.vstack([1 - preds, preds]).T\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # NEW: Returns Log-Odds (Raw Margin)\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        else:\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "            \n",
    "        # output_margin=True gives the raw log-odds\n",
    "        return self.booster.predict(dmat, output_margin=True)\n",
    "\n",
    "def iou_from_confusion(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    denom = tp + fp + fn\n",
    "    return float(tp / denom) if denom > 0 else 0.0\n",
    "\n",
    "def load_dataset(dataset_dir: Path) -> pd.DataFrame:\n",
    "    print(f\"Reading Parquet dataset from:\\n  {dataset_dir}\")\n",
    "    dset = ds.dataset(str(dataset_dir), format=\"parquet\")\n",
    "    \n",
    "    # Try to include Year column if it exists in schema\n",
    "    all_cols = dset.schema.names\n",
    "    cols_to_load = FEATURES + [FRACTION_COL]\n",
    "    \n",
    "    if YEAR_COL in all_cols:\n",
    "        cols_to_load.append(YEAR_COL)\n",
    "        print(f\"Found '{YEAR_COL}' column, including it for analysis.\")\n",
    "    else:\n",
    "        print(f\"Warning: '{YEAR_COL}' column not found. Yearly analysis will be skipped.\")\n",
    "\n",
    "    table = dset.to_table(columns=cols_to_load)\n",
    "    df = table.to_pandas()\n",
    "    return df\n",
    "\n",
    "def prepare_xy_with_meta(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Clean Fraction\n",
    "    df[FRACTION_COL] = pd.to_numeric(df[FRACTION_COL], errors=\"coerce\").astype(\"float32\")\n",
    "    keep = df[FRACTION_COL].notna() & (df[FRACTION_COL] != 0.5)\n",
    "    df = df.loc[keep].copy()\n",
    "    \n",
    "    # 2. Create Label\n",
    "    df[LABEL_COL] = (df[FRACTION_COL] > 0.5).astype(\"uint8\")\n",
    "    \n",
    "    # 3. Clean Features\n",
    "    df[\"b1\"] = pd.to_numeric(df[\"b1\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 4. Drop NaNs\n",
    "    req_cols = FEATURES + [LABEL_COL]\n",
    "    if YEAR_COL in df.columns:\n",
    "        req_cols.append(YEAR_COL)\n",
    "        \n",
    "    df = df.dropna(subset=req_cols).copy()\n",
    "\n",
    "    # 5. Extract X, y, meta\n",
    "    X = df[FEATURES].copy()\n",
    "    y = df[LABEL_COL].astype(\"uint8\").to_numpy()\n",
    "    \n",
    "    # Enforce dtypes\n",
    "    X[\"b1\"] = X[\"b1\"].astype(\"int32\")\n",
    "    for c in X.columns:\n",
    "        if c == \"b1\": continue\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").astype(\"float32\")\n",
    "    \n",
    "    # Final NaN check on X\n",
    "    mask = X.notna().all(axis=1)\n",
    "    X = X.loc[mask].copy()\n",
    "    y = y[mask.to_numpy()]\n",
    "    \n",
    "    # Meta (Year)\n",
    "    meta = None\n",
    "    if YEAR_COL in df.columns:\n",
    "        meta = df.loc[mask, [YEAR_COL]].copy()\n",
    "\n",
    "    return X, y, meta\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # 1. LOAD DATA & REPLICATE SPLIT\n",
    "    # --------------------------------------------------------\n",
    "    df = load_dataset(DATASET_DIR)\n",
    "    X, y, meta = prepare_xy_with_meta(df)\n",
    "\n",
    "    # To ensure X_test is identical to training, we must perform the exact same splits\n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    X_trainval, X_test, y_trainval, y_test, idx_trainval, idx_test = train_test_split(\n",
    "        X, y, indices,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # Split 2: Train / Val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval,\n",
    "        test_size=VAL_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_trainval,\n",
    "    )\n",
    "    \n",
    "    # Meta for test set\n",
    "    meta_test = None\n",
    "    if meta is not None:\n",
    "        meta_test = meta.iloc[idx_test].copy()\n",
    "\n",
    "    print(f\"\\nData Loaded & Split Replicated.\")\n",
    "    print(f\"Test Set Size: {len(X_test)}\")\n",
    "\n",
    "    # 2. LOAD MODEL\n",
    "    # --------------------------------------------------------\n",
    "    if not MODEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
    "    \n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(str(MODEL_PATH))\n",
    "\n",
    "    # 3. DETERMINE BEST THRESHOLD (ON VAL SET)\n",
    "    # --------------------------------------------------------\n",
    "    print(\"Re-calculating best threshold on Validation set (Max F1)...\")\n",
    "    dval = xgb.DMatrix(X_val, feature_names=FEATURES)\n",
    "    val_probs = booster.predict(dval)\n",
    "    \n",
    "    best_f1 = -1\n",
    "    best_thr = 0.5\n",
    "    \n",
    "    # Sweep thresholds\n",
    "    for thr in THRESHOLDS:\n",
    "        pred_tmp = (val_probs >= thr).astype(np.uint8)\n",
    "        f1 = f1_score(y_val, pred_tmp, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = thr\n",
    "            \n",
    "    print(f\"Best Validation Threshold: {best_thr} (F1: {best_f1:.4f})\")\n",
    "\n",
    "    # 4. TEST METRICS\n",
    "    # --------------------------------------------------------\n",
    "    dtest = xgb.DMatrix(X_test, feature_names=FEATURES)\n",
    "    test_prob = booster.predict(dtest)\n",
    "    \n",
    "    test_pred = (test_prob >= best_thr).astype(np.uint8)\n",
    "    \n",
    "    test_pr_auc = average_precision_score(y_test, test_prob)\n",
    "    test_prec = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_test, test_pred, zero_division=0)\n",
    "    test_iou  = iou_from_confusion(y_test, test_pred)\n",
    "\n",
    "    print(\"\\n=== TEST METRICS ===\")\n",
    "    print(f\"Test PR-AUC (threshold-free): {test_pr_auc:.6f}\")\n",
    "    print(f\"Threshold used: {best_thr:.2f}\")\n",
    "    print(f\"Precision: {test_prec:.4f}\")\n",
    "    print(f\"Recall    : {test_rec:.4f}\")\n",
    "    print(f\"F1        : {test_f1:.4f}\")\n",
    "    print(f\"IoU       : {test_iou:.4f}\")\n",
    "\n",
    "    print(\"\\nArtifacts saved to:\")\n",
    "    print(f\"  {MODEL_DIR}\")\n",
    "    print(f\"Best model loaded from:\\n  {MODEL_PATH}\")\n",
    "\n",
    "    # 5. FEATURE IMPORTANCE PLOT\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nGenerating Feature Importance Plot...\")\n",
    "    importance_type = 'total_gain' \n",
    "    imp = booster.get_score(importance_type=importance_type)\n",
    "    imp_df = pd.DataFrame(list(imp.items()), columns=['Feature', 'Importance'])\n",
    "    imp_df = imp_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(imp_df['Feature'], imp_df['Importance'], color='skyblue')\n",
    "    plt.xlabel(f\"Importance ({importance_type})\")\n",
    "    plt.title(\"XGBoost Feature Importance\")\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS_DIR / \"feature_importance.png\", dpi=200)\n",
    "    plt.close()\n",
    "    print(\" Saved feature_importance.png\")\n",
    "\n",
    "    # 6. PARTIAL DEPENDENCE PLOTS (LOG-ODDS) \n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nGenerating Partial Dependence Plots (Log-Odds)...\")\n",
    "    top_features = imp_df.sort_values(by='Importance', ascending=False)['Feature'].head(9).tolist()\n",
    "    \n",
    "    sklearn_model = XGBNativeSklearnWrapper(booster, FEATURES)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 12))\n",
    "    X_pdp = X_test.sample(n=min(len(X_test), 5000), random_state=RANDOM_STATE) if len(X_test) > 5000 else X_test\n",
    "    \n",
    "    # Use response_method='decision_function' for Log-Odds\n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        sklearn_model,\n",
    "        X_pdp,\n",
    "        features=top_features,\n",
    "        response_method=\"decision_function\",  # <--- FORCE LOG-ODDS\n",
    "        ax=ax,\n",
    "        n_cols=3,\n",
    "        grid_resolution=30,\n",
    "        line_kw={\"color\": \"darkblue\", \"linewidth\": 2}\n",
    "    )\n",
    "    \n",
    "    # Manually label Y-axis to be clear\n",
    "    for sub_ax in display.axes_.flatten():\n",
    "        sub_ax.set_ylabel(\"Partial Dependence (Log-Odds)\")\n",
    "\n",
    "    plt.suptitle(f\"Partial Dependence Plots (Log-Odds) - Top {len(top_features)} Features\", fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92, hspace=0.3)\n",
    "    plt.savefig(FIGS_DIR / \"partial_dependence_plot_logodds.png\", dpi=200)\n",
    "    plt.close()\n",
    "    print(\" Saved partial_dependence_plot_logodds.png\")\n",
    "\n",
    "    # 7. BURNED AREA COMPARISON\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nComparing Burned Areas...\")\n",
    "    res_df = pd.DataFrame({\n",
    "        \"observed_binary\": y_test,\n",
    "        \"predicted_binary\": test_pred,\n",
    "        \"predicted_prob\": test_prob\n",
    "    })\n",
    "    \n",
    "    if meta_test is not None:\n",
    "        res_df[YEAR_COL] = meta_test[YEAR_COL].values\n",
    "        yearly = res_df.groupby(YEAR_COL)[[\"observed_binary\", \"predicted_binary\"]].sum().reset_index()\n",
    "        yearly.rename(columns={\n",
    "            \"observed_binary\": \"Observed_Pixels\", \n",
    "            \"predicted_binary\": \"Predicted_Pixels\"\n",
    "        }, inplace=True)\n",
    "        \n",
    "        yearly.to_csv(FIGS_DIR / \"burned_area_comparison_yearly.csv\", index=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        x_idx = np.arange(len(yearly))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x_idx - width/2, yearly[\"Observed_Pixels\"], width, label='Observed (Label=1)', color='tab:orange', alpha=0.8)\n",
    "        plt.bar(x_idx + width/2, yearly[\"Predicted_Pixels\"], width, label=f'Predicted (Prob>{best_thr})', color='tab:blue', alpha=0.8)\n",
    "        \n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Burned Area (Pixel Count)\")\n",
    "        plt.title(\"Observed vs Predicted Burned Area by Year (Test Set)\")\n",
    "        plt.xticks(x_idx, yearly[YEAR_COL], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS_DIR / \"burned_area_yearly_comparison.png\", dpi=200)\n",
    "        plt.close()\n",
    "        print(\" Saved burned_area_yearly_comparison.png and .csv\")\n",
    "        \n",
    "        print(\"\\nYearly Burned Area Counts (Pixels):\")\n",
    "        print(yearly.to_string(index=False))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n[INFO] 'year' column not available. Calculating total sums only.\")\n",
    "        total_obs = res_df[\"observed_binary\"].sum()\n",
    "        total_pred = res_df[\"predicted_binary\"].sum()\n",
    "        print(f\"Total Observed Pixels: {total_obs}\")\n",
    "        print(f\"Total Predicted Pixels: {total_pred}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22f380c-7992-4aea-9ec7-7e9694c85483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Parquet dataset from:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\n",
      "Warning: 'year' column not found. Yearly analysis will be skipped.\n",
      "\n",
      "Data Loaded & Split Replicated.\n",
      "Test Set Size: 7458650\n",
      "Loading model from: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\n",
      "\n",
      "Using Fixed Probability Threshold: 0.85\n",
      "\n",
      "=== TEST METRICS ===\n",
      "Test PR-AUC (threshold-free): 0.972710\n",
      "Threshold used: 0.85\n",
      "Precision: 0.9658\n",
      "Recall    : 0.9519\n",
      "F1        : 0.9588\n",
      "IoU       : 0.9208\n",
      "\n",
      "Artifacts saved to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical\n",
      "Best model loaded from:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical/models/xgb_best_pr_auc.json\n",
      "\n",
      "Generating Feature Importance Plot...\n",
      " Saved feature_importance.png\n",
      "\n",
      "Generating Partial Dependence Plots (Log-Odds)...\n",
      " Saved partial_dependence_plot_logodds.png\n",
      "\n",
      "Comparing Burned Areas...\n",
      "\n",
      "[INFO] 'year' column not available. Calculating total sums only.\n",
      "Total Observed Pixels: 19344\n",
      "Total Predicted Pixels: 19067\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Evaluate XGBoost Model (Native API)\n",
    "-- LOADS EXISTING MODEL --\n",
    "-- UPDATED: Partial Dependence Plots now use LOG-ODDS --\n",
    "-- UPDATED: Uses Fixed Probability Threshold (0.85) --\n",
    "\n",
    "Tasks:\n",
    "1. Load dataset & replicate train/val/test splits (Random State 42).\n",
    "2. Load saved native XGBoost model.\n",
    "3. Set fixed threshold (0.85).\n",
    "4. Evaluate on Test set (Print metrics).\n",
    "5. Generate Feature Importance Plot.\n",
    "6. Generate Multi-panel Partial Dependence Plots (PDP) in LOG-ODDS.\n",
    "7. Compare Predicted vs Observed Burned Area (Total & Yearly).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG (Must match Training Script)\n",
    "# ============================================================\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# DATASET & MODEL PATHS\n",
    "DATASET_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\"\n",
    ")\n",
    "\n",
    "# Directory where your model was saved\n",
    "MODEL_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"ml_training/xgb_pr_auc_filtered_burnedlabmask_native_analytical\"\n",
    ")\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"models\" / \"xgb_best_pr_auc.json\"\n",
    "FIGS_DIR = MODEL_DIR / \"eval_figures\"\n",
    "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = [\n",
    "    \"DEM\", \"slope\", \"aspect\", \"b1\", \"relative_humidity\", \n",
    "    \"total_precipitation_sum\", \"temperature_2m\", \"temperature_2m_min\", \n",
    "    \"temperature_2m_max\", \"build_up_index\", \"drought_code\", \n",
    "    \"duff_moisture_code\", \"fine_fuel_moisture_code\", \n",
    "    \"fire_weather_index\", \"initial_fire_spread_index\",\n",
    "]\n",
    "\n",
    "FRACTION_COL = \"fraction\"\n",
    "LABEL_COL = \"burned\"\n",
    "\n",
    "# We attempt to load 'year' for the area analysis. \n",
    "# If your dataset calls it 'time' or something else, update this.\n",
    "YEAR_COL = \"year\" \n",
    "\n",
    "TEST_SIZE = 0.10\n",
    "VAL_SIZE  = 0.20\n",
    "# THRESHOLDS search range removed (using fixed 0.85)\n",
    "N_JOBS = 6\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "\n",
    "class XGBNativeSklearnWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper to make a native xgb.Booster look like an sklearn estimator.\n",
    "    \"\"\"\n",
    "    def __init__(self, booster, feature_names):\n",
    "        self.booster = booster\n",
    "        self.feature_names = feature_names\n",
    "        self.dummy_ = True\n",
    "        self._estimator_type = \"classifier\"\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Returns Probabilities\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        else:\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        \n",
    "        preds = self.booster.predict(dmat)\n",
    "        return np.vstack([1 - preds, preds]).T\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # NEW: Returns Log-Odds (Raw Margin)\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        else:\n",
    "            dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "            \n",
    "        # output_margin=True gives the raw log-odds\n",
    "        return self.booster.predict(dmat, output_margin=True)\n",
    "\n",
    "def iou_from_confusion(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    denom = tp + fp + fn\n",
    "    return float(tp / denom) if denom > 0 else 0.0\n",
    "\n",
    "def load_dataset(dataset_dir: Path) -> pd.DataFrame:\n",
    "    print(f\"Reading Parquet dataset from:\\n  {dataset_dir}\")\n",
    "    dset = ds.dataset(str(dataset_dir), format=\"parquet\")\n",
    "    \n",
    "    # Try to include Year column if it exists in schema\n",
    "    all_cols = dset.schema.names\n",
    "    cols_to_load = FEATURES + [FRACTION_COL]\n",
    "    \n",
    "    if YEAR_COL in all_cols:\n",
    "        cols_to_load.append(YEAR_COL)\n",
    "        print(f\"Found '{YEAR_COL}' column, including it for analysis.\")\n",
    "    else:\n",
    "        print(f\"Warning: '{YEAR_COL}' column not found. Yearly analysis will be skipped.\")\n",
    "\n",
    "    table = dset.to_table(columns=cols_to_load)\n",
    "    df = table.to_pandas()\n",
    "    return df\n",
    "\n",
    "def prepare_xy_with_meta(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Clean Fraction\n",
    "    df[FRACTION_COL] = pd.to_numeric(df[FRACTION_COL], errors=\"coerce\").astype(\"float32\")\n",
    "    keep = df[FRACTION_COL].notna() & (df[FRACTION_COL] != 0.5)\n",
    "    df = df.loc[keep].copy()\n",
    "    \n",
    "    # 2. Create Label\n",
    "    df[LABEL_COL] = (df[FRACTION_COL] > 0.5).astype(\"uint8\")\n",
    "    \n",
    "    # 3. Clean Features\n",
    "    df[\"b1\"] = pd.to_numeric(df[\"b1\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 4. Drop NaNs\n",
    "    req_cols = FEATURES + [LABEL_COL]\n",
    "    if YEAR_COL in df.columns:\n",
    "        req_cols.append(YEAR_COL)\n",
    "        \n",
    "    df = df.dropna(subset=req_cols).copy()\n",
    "\n",
    "    # 5. Extract X, y, meta\n",
    "    X = df[FEATURES].copy()\n",
    "    y = df[LABEL_COL].astype(\"uint8\").to_numpy()\n",
    "    \n",
    "    # Enforce dtypes\n",
    "    X[\"b1\"] = X[\"b1\"].astype(\"int32\")\n",
    "    for c in X.columns:\n",
    "        if c == \"b1\": continue\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").astype(\"float32\")\n",
    "    \n",
    "    # Final NaN check on X\n",
    "    mask = X.notna().all(axis=1)\n",
    "    X = X.loc[mask].copy()\n",
    "    y = y[mask.to_numpy()]\n",
    "    \n",
    "    # Meta (Year)\n",
    "    meta = None\n",
    "    if YEAR_COL in df.columns:\n",
    "        meta = df.loc[mask, [YEAR_COL]].copy()\n",
    "\n",
    "    return X, y, meta\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # 1. LOAD DATA & REPLICATE SPLIT\n",
    "    # --------------------------------------------------------\n",
    "    df = load_dataset(DATASET_DIR)\n",
    "    X, y, meta = prepare_xy_with_meta(df)\n",
    "\n",
    "    # To ensure X_test is identical to training, we must perform the exact same splits\n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    X_trainval, X_test, y_trainval, y_test, idx_trainval, idx_test = train_test_split(\n",
    "        X, y, indices,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    # Split 2: Train / Val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval,\n",
    "        test_size=VAL_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_trainval,\n",
    "    )\n",
    "    \n",
    "    # Meta for test set\n",
    "    meta_test = None\n",
    "    if meta is not None:\n",
    "        meta_test = meta.iloc[idx_test].copy()\n",
    "\n",
    "    print(f\"\\nData Loaded & Split Replicated.\")\n",
    "    print(f\"Test Set Size: {len(X_test)}\")\n",
    "\n",
    "    # 2. LOAD MODEL\n",
    "    # --------------------------------------------------------\n",
    "    if not MODEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
    "    \n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(str(MODEL_PATH))\n",
    "\n",
    "    # 3. SET FIXED THRESHOLD\n",
    "    # --------------------------------------------------------\n",
    "    # Previous logic searched for Max F1 on Validation set.\n",
    "    # New logic uses a hardcoded high-confidence threshold.\n",
    "    best_thr = 0.85\n",
    "    print(f\"\\nUsing Fixed Probability Threshold: {best_thr}\")\n",
    "\n",
    "    # 4. TEST METRICS\n",
    "    # --------------------------------------------------------\n",
    "    dtest = xgb.DMatrix(X_test, feature_names=FEATURES)\n",
    "    test_prob = booster.predict(dtest)\n",
    "    \n",
    "    test_pred = (test_prob >= best_thr).astype(np.uint8)\n",
    "    \n",
    "    test_pr_auc = average_precision_score(y_test, test_prob)\n",
    "    test_prec = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_test, test_pred, zero_division=0)\n",
    "    test_iou  = iou_from_confusion(y_test, test_pred)\n",
    "\n",
    "    print(\"\\n=== TEST METRICS ===\")\n",
    "    print(f\"Test PR-AUC (threshold-free): {test_pr_auc:.6f}\")\n",
    "    print(f\"Threshold used: {best_thr:.2f}\")\n",
    "    print(f\"Precision: {test_prec:.4f}\")\n",
    "    print(f\"Recall    : {test_rec:.4f}\")\n",
    "    print(f\"F1        : {test_f1:.4f}\")\n",
    "    print(f\"IoU       : {test_iou:.4f}\")\n",
    "\n",
    "    print(\"\\nArtifacts saved to:\")\n",
    "    print(f\"  {MODEL_DIR}\")\n",
    "    print(f\"Best model loaded from:\\n  {MODEL_PATH}\")\n",
    "\n",
    "    # 5. FEATURE IMPORTANCE PLOT\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nGenerating Feature Importance Plot...\")\n",
    "    importance_type = 'total_gain' \n",
    "    imp = booster.get_score(importance_type=importance_type)\n",
    "    imp_df = pd.DataFrame(list(imp.items()), columns=['Feature', 'Importance'])\n",
    "    imp_df = imp_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(imp_df['Feature'], imp_df['Importance'], color='skyblue')\n",
    "    plt.xlabel(f\"Importance ({importance_type})\")\n",
    "    plt.title(\"XGBoost Feature Importance\")\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS_DIR / \"feature_importance.png\", dpi=200)\n",
    "    plt.close()\n",
    "    print(\" Saved feature_importance.png\")\n",
    "\n",
    "    # 6. PARTIAL DEPENDENCE PLOTS (LOG-ODDS) \n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nGenerating Partial Dependence Plots (Log-Odds)...\")\n",
    "    top_features = imp_df.sort_values(by='Importance', ascending=False)['Feature'].head(9).tolist()\n",
    "    \n",
    "    sklearn_model = XGBNativeSklearnWrapper(booster, FEATURES)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 12))\n",
    "    X_pdp = X_test.sample(n=min(len(X_test), 5000), random_state=RANDOM_STATE) if len(X_test) > 5000 else X_test\n",
    "    \n",
    "    # Use response_method='decision_function' for Log-Odds\n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        sklearn_model,\n",
    "        X_pdp,\n",
    "        features=top_features,\n",
    "        response_method=\"decision_function\",  # <--- FORCE LOG-ODDS\n",
    "        ax=ax,\n",
    "        n_cols=3,\n",
    "        grid_resolution=30,\n",
    "        line_kw={\"color\": \"darkblue\", \"linewidth\": 2}\n",
    "    )\n",
    "    \n",
    "    # Manually label Y-axis to be clear\n",
    "    for sub_ax in display.axes_.flatten():\n",
    "        sub_ax.set_ylabel(\"Partial Dependence (Log-Odds)\")\n",
    "\n",
    "    plt.suptitle(f\"Partial Dependence Plots (Log-Odds) - Top {len(top_features)} Features\", fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92, hspace=0.3)\n",
    "    plt.savefig(FIGS_DIR / \"partial_dependence_plot_logodds.png\", dpi=200)\n",
    "    plt.close()\n",
    "    print(\" Saved partial_dependence_plot_logodds.png\")\n",
    "\n",
    "    # 7. BURNED AREA COMPARISON\n",
    "    # --------------------------------------------------------\n",
    "    print(\"\\nComparing Burned Areas...\")\n",
    "    res_df = pd.DataFrame({\n",
    "        \"observed_binary\": y_test,\n",
    "        \"predicted_binary\": test_pred,\n",
    "        \"predicted_prob\": test_prob\n",
    "    })\n",
    "    \n",
    "    if meta_test is not None:\n",
    "        res_df[YEAR_COL] = meta_test[YEAR_COL].values\n",
    "        yearly = res_df.groupby(YEAR_COL)[[\"observed_binary\", \"predicted_binary\"]].sum().reset_index()\n",
    "        yearly.rename(columns={\n",
    "            \"observed_binary\": \"Observed_Pixels\", \n",
    "            \"predicted_binary\": \"Predicted_Pixels\"\n",
    "        }, inplace=True)\n",
    "        \n",
    "        yearly.to_csv(FIGS_DIR / \"burned_area_comparison_yearly.csv\", index=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        x_idx = np.arange(len(yearly))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x_idx - width/2, yearly[\"Observed_Pixels\"], width, label='Observed (Label=1)', color='tab:orange', alpha=0.8)\n",
    "        plt.bar(x_idx + width/2, yearly[\"Predicted_Pixels\"], width, label=f'Predicted (Prob>{best_thr})', color='tab:blue', alpha=0.8)\n",
    "        \n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Burned Area (Pixel Count)\")\n",
    "        plt.title(\"Observed vs Predicted Burned Area by Year (Test Set)\")\n",
    "        plt.xticks(x_idx, yearly[YEAR_COL], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGS_DIR / \"burned_area_yearly_comparison.png\", dpi=200)\n",
    "        plt.close()\n",
    "        print(\" Saved burned_area_yearly_comparison.png and .csv\")\n",
    "        \n",
    "        print(\"\\nYearly Burned Area Counts (Pixels):\")\n",
    "        print(yearly.to_string(index=False))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n[INFO] 'year' column not available. Calculating total sums only.\")\n",
    "        total_obs = res_df[\"observed_binary\"].sum()\n",
    "        total_pred = res_df[\"predicted_binary\"].sum()\n",
    "        print(f\"Total Observed Pixels: {total_obs}\")\n",
    "        print(f\"Total Predicted Pixels: {total_pred}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42960762-4f78-4611-b18c-330c7507f379",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14da8fec-b0c4-462b-9d1b-7e27028eb5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Parquet dataset from:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\n",
      "Splitting Data: Test Years [2003, 2004]\n",
      "  Test Set ([2003, 2004]): 9,511,308 rows\n",
      "  Validation Set (subset of rest): 13,015,037 rows\n",
      "Loading model from: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_temporal_split_2003_2004/models/xgb_best_pr_auc_temporal.json\n",
      "\n",
      "Running Predictions...\n",
      "Generating Probability Distribution Shift Plot...\n",
      " Saved /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_temporal_split_2003_2004/eval_figures_diagnostics/prob_dist_shift.png\n",
      "\n",
      "=== TEST METRICS ===\n",
      "PR-AUC (Threshold Independent): 0.019825\n",
      "Threshold used: 0.5\n",
      "Precision: 0.0658\n",
      "Recall    : 0.0008\n",
      "F1        : 0.0017\n",
      "IoU       : 0.0008\n",
      "\n",
      "Generating Feature Importance...\n",
      "Generating Partial Dependence (Log-Odds)...\n",
      "\n",
      "Comparing Burned Areas...\n",
      "\n",
      "Yearly Breakdown:\n",
      " Year  Observed_Pixels  Predicted_Pixels\n",
      " 2003            28701               402\n",
      " 2004             6744                54\n",
      "\n",
      "Done. Results saved to /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_temporal_split_2003_2004/eval_figures_diagnostics\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Evaluate XGBoost Model (Temporal Split Version)\n",
    "-- JUPYTER COMPATIBLE --\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# DATASET\n",
    "DATASET_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\"\n",
    ")\n",
    "\n",
    "# MODEL DIRECTORY (Where the temporal model was saved)\n",
    "MODEL_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"ml_training/xgb_pr_auc_temporal_split_2003_2004\"\n",
    ")\n",
    "\n",
    "# MODEL PATH\n",
    "MODEL_PATH = MODEL_DIR / \"models\" / \"xgb_best_pr_auc_temporal.json\"\n",
    "\n",
    "FIGS_DIR = MODEL_DIR / \"eval_figures_diagnostics\"\n",
    "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES = [\n",
    "    \"DEM\", \"slope\", \"aspect\", \"b1\", \"relative_humidity\", \n",
    "    \"total_precipitation_sum\", \"temperature_2m\", \"temperature_2m_min\", \n",
    "    \"temperature_2m_max\", \"build_up_index\", \"drought_code\", \n",
    "    \"duff_moisture_code\", \"fine_fuel_moisture_code\", \n",
    "    \"fire_weather_index\", \"initial_fire_spread_index\",\n",
    "]\n",
    "\n",
    "FRACTION_COL = \"fraction\"\n",
    "LABEL_COL = \"burned\"\n",
    "YEAR_COL = \"year\"\n",
    "\n",
    "# TEMPORAL SPLIT CONFIG\n",
    "TEST_YEARS = [2003, 2004]\n",
    "VAL_SIZE_OF_REMAINING = 0.20 \n",
    "\n",
    "# Threshold for binary metrics\n",
    "FIXED_THRESHOLD = 0.50 \n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "\n",
    "class XGBNativeSklearnWrapper:\n",
    "    \"\"\"Wrapper to make native xgb.Booster look like an sklearn estimator for PDP.\"\"\"\n",
    "    def __init__(self, booster, feature_names):\n",
    "        self.booster = booster\n",
    "        self.feature_names = feature_names\n",
    "        self.dummy_ = True\n",
    "        self._estimator_type = \"classifier\"\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        preds = self.booster.predict(dmat)\n",
    "        return np.vstack([1 - preds, preds]).T\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        # output_margin=True gives raw log-odds\n",
    "        dmat = xgb.DMatrix(X, feature_names=self.feature_names)\n",
    "        return self.booster.predict(dmat, output_margin=True)\n",
    "\n",
    "def iou_from_confusion(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    denom = tp + fp + fn\n",
    "    return float(tp / denom) if denom > 0 else 0.0\n",
    "\n",
    "def load_and_clean_data(dataset_dir: Path):\n",
    "    \"\"\"\n",
    "    Loads data and cleans it, ensuring 'year' is present for temporal splitting.\n",
    "    \"\"\"\n",
    "    print(f\"Reading Parquet dataset from:\\n  {dataset_dir}\", flush=True)\n",
    "    # partitioning=\"hive\" is usually required if year is a folder level\n",
    "    dset = ds.dataset(str(dataset_dir), format=\"parquet\", partitioning=\"hive\")\n",
    "    \n",
    "    # Check schema\n",
    "    cols_available = dset.schema.names\n",
    "    cols_to_load = FEATURES + [FRACTION_COL]\n",
    "    \n",
    "    if YEAR_COL in cols_available:\n",
    "        cols_to_load.append(YEAR_COL)\n",
    "    else:\n",
    "        raise ValueError(f\"Column '{YEAR_COL}' required for temporal split but not found.\")\n",
    "\n",
    "    table = dset.to_table(columns=cols_to_load)\n",
    "    df = table.to_pandas()\n",
    "    \n",
    "    # Cleanup\n",
    "    df[FRACTION_COL] = pd.to_numeric(df[FRACTION_COL], errors=\"coerce\").astype(\"float32\")\n",
    "    df = df[df[FRACTION_COL].notna() & (df[FRACTION_COL] != 0.5)].copy()\n",
    "    \n",
    "    df[LABEL_COL] = (df[FRACTION_COL] > 0.5).astype(\"uint8\")\n",
    "    \n",
    "    # Fix B1 and Year\n",
    "    df[\"b1\"] = pd.to_numeric(df[\"b1\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df[YEAR_COL] = pd.to_numeric(df[YEAR_COL], errors=\"coerce\").astype(\"Int64\")\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Drop NaNs\n",
    "    subset = FEATURES + [LABEL_COL, YEAR_COL]\n",
    "    df = df.dropna(subset=subset).copy()\n",
    "    \n",
    "    # Final types\n",
    "    df[\"b1\"] = df[\"b1\"].astype(\"int32\")\n",
    "    for c in FEATURES:\n",
    "        if c == \"b1\": continue\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def get_X_y_meta(df):\n",
    "    X = df[FEATURES].copy()\n",
    "    y = df[LABEL_COL].astype(\"uint8\").to_numpy()\n",
    "    meta = df[[YEAR_COL]].copy()\n",
    "    return X, y, meta\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTION START\n",
    "# ============================================================\n",
    "\n",
    "# 1. LOAD DATA\n",
    "# --------------------------------------------------------\n",
    "df_clean = load_and_clean_data(DATASET_DIR)\n",
    "\n",
    "# 2. REPLICATE TEMPORAL SPLIT\n",
    "# --------------------------------------------------------\n",
    "print(f\"Splitting Data: Test Years {TEST_YEARS}\", flush=True)\n",
    "\n",
    "mask_test = df_clean[YEAR_COL].isin(TEST_YEARS)\n",
    "df_test_full = df_clean.loc[mask_test]\n",
    "df_trainval_full = df_clean.loc[~mask_test]\n",
    "\n",
    "if len(df_test_full) == 0:\n",
    "    raise ValueError(f\"No data found for test years {TEST_YEARS}\")\n",
    "\n",
    "# Prepare arrays\n",
    "X_test, y_test, meta_test = get_X_y_meta(df_test_full)\n",
    "X_tv, y_tv, _ = get_X_y_meta(df_trainval_full)\n",
    "\n",
    "# We need the Validation set to compare probability distributions\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tv, y_tv,\n",
    "    test_size=VAL_SIZE_OF_REMAINING,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_tv,\n",
    ")\n",
    "\n",
    "print(f\"  Test Set ({TEST_YEARS}): {len(X_test):,} rows\", flush=True)\n",
    "print(f\"  Validation Set (subset of rest): {len(X_val):,} rows\", flush=True)\n",
    "\n",
    "# 3. LOAD MODEL\n",
    "# --------------------------------------------------------\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
    "\n",
    "print(f\"Loading model from: {MODEL_PATH}\", flush=True)\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(str(MODEL_PATH))\n",
    "\n",
    "# 4. PREDICT & DIAGNOSTICS\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nRunning Predictions...\", flush=True)\n",
    "dval = xgb.DMatrix(X_val, feature_names=FEATURES)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=FEATURES)\n",
    "\n",
    "val_prob = booster.predict(dval)\n",
    "test_prob = booster.predict(dtest)\n",
    "\n",
    "# --- DIAGNOSTIC A: PROBABILITY DISTRIBUTION SHIFT ---\n",
    "print(\"Generating Probability Distribution Shift Plot...\", flush=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram of probabilities for POSITIVE labels only\n",
    "plt.hist(val_prob[y_val == 1], bins=50, alpha=0.5, label='Validation Positives', density=True)\n",
    "plt.hist(test_prob[y_test == 1], bins=50, alpha=0.5, label=f'Test Positives ({TEST_YEARS})', density=True)\n",
    "\n",
    "plt.title(\"Probability Distribution Shift (Positives Only)\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "out_hist = FIGS_DIR / \"prob_dist_shift.png\"\n",
    "plt.savefig(out_hist, dpi=150)\n",
    "plt.close()\n",
    "print(f\" Saved {out_hist}\", flush=True)\n",
    "\n",
    "# 5. TEST METRICS (Fixed Threshold)\n",
    "# --------------------------------------------------------\n",
    "test_pred = (test_prob >= FIXED_THRESHOLD).astype(np.uint8)\n",
    "\n",
    "test_pr_auc = average_precision_score(y_test, test_prob)\n",
    "test_prec = precision_score(y_test, test_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_test, test_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_test, test_pred, zero_division=0)\n",
    "test_iou  = iou_from_confusion(y_test, test_pred)\n",
    "\n",
    "print(\"\\n=== TEST METRICS ===\", flush=True)\n",
    "print(f\"PR-AUC (Threshold Independent): {test_pr_auc:.6f}\", flush=True)\n",
    "print(f\"Threshold used: {FIXED_THRESHOLD}\", flush=True)\n",
    "print(f\"Precision: {test_prec:.4f}\", flush=True)\n",
    "print(f\"Recall    : {test_rec:.4f}\", flush=True)\n",
    "print(f\"F1        : {test_f1:.4f}\", flush=True)\n",
    "print(f\"IoU       : {test_iou:.4f}\", flush=True)\n",
    "\n",
    "# 6. FEATURE IMPORTANCE & PDP\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nGenerating Feature Importance...\", flush=True)\n",
    "imp_dict = booster.get_score(importance_type='total_gain')\n",
    "imp_df = pd.DataFrame(list(imp_dict.items()), columns=['Feature', 'Importance'])\n",
    "imp_df = imp_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(imp_df['Feature'], imp_df['Importance'], color='skyblue')\n",
    "plt.xlabel(\"Total Gain\")\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGS_DIR / \"feature_importance.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Generating Partial Dependence (Log-Odds)...\", flush=True)\n",
    "top_features = imp_df.sort_values(by='Importance', ascending=False)['Feature'].head(9).tolist()\n",
    "sklearn_model = XGBNativeSklearnWrapper(booster, FEATURES)\n",
    "\n",
    "# Subsample for speed\n",
    "X_pdp = X_test.sample(n=min(len(X_test), 5000), random_state=RANDOM_STATE)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    sklearn_model,\n",
    "    X_pdp,\n",
    "    features=top_features,\n",
    "    response_method=\"decision_function\", # Log-odds\n",
    "    ax=ax,\n",
    "    n_cols=3,\n",
    "    grid_resolution=30,\n",
    "    line_kw={\"color\": \"darkblue\", \"linewidth\": 2}\n",
    ")\n",
    "for sub_ax in display.axes_.flatten():\n",
    "    sub_ax.set_ylabel(\"Partial Dependence (Log-Odds)\")\n",
    "plt.suptitle(\"Partial Dependence (Log-Odds) - Test Set\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.92, hspace=0.3)\n",
    "plt.savefig(FIGS_DIR / \"partial_dependence_logodds.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 7. BURNED AREA COMPARISON\n",
    "# --------------------------------------------------------\n",
    "print(\"\\nComparing Burned Areas...\", flush=True)\n",
    "res_df = pd.DataFrame({\n",
    "    \"observed_binary\": y_test,\n",
    "    \"predicted_binary\": test_pred,\n",
    "    \"year\": meta_test[YEAR_COL].values\n",
    "})\n",
    "\n",
    "yearly = res_df.groupby(\"year\")[[\"observed_binary\", \"predicted_binary\"]].sum().reset_index()\n",
    "yearly.columns = [\"Year\", \"Observed_Pixels\", \"Predicted_Pixels\"]\n",
    "\n",
    "yearly.to_csv(FIGS_DIR / \"burned_area_comparison.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "x_idx = np.arange(len(yearly))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x_idx - width/2, yearly[\"Observed_Pixels\"], width, label='Observed', color='tab:orange', alpha=0.8)\n",
    "plt.bar(x_idx + width/2, yearly[\"Predicted_Pixels\"], width, label='Predicted', color='tab:blue', alpha=0.8)\n",
    "\n",
    "plt.xticks(x_idx, yearly[\"Year\"])\n",
    "plt.ylabel(\"Pixel Count\")\n",
    "plt.title(f\"Burned Area: Test Years (Thr={FIXED_THRESHOLD})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGS_DIR / \"burned_area_yearly.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nYearly Breakdown:\", flush=True)\n",
    "print(yearly.to_string(index=False), flush=True)\n",
    "print(f\"\\nDone. Results saved to {FIGS_DIR}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed146ee-aba0-438d-8cec-d596c85fa642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting: /explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\n",
      "\n",
      "Found 19 columns:\n",
      "--------------------------------------------------\n",
      "['DEM', 'slope', 'aspect', 'b1', 'relative_humidity', 'total_precipitation_sum', 'temperature_2m', 'temperature_2m_min', 'temperature_2m_max', 'build_up_index', 'drought_code', 'duff_moisture_code', 'fine_fuel_moisture_code', 'fire_weather_index', 'initial_fire_spread_index', 'fraction', 'burned_pixel', 'longitude', 'latitude']\n",
      "--------------------------------------------------\n",
      "\n",
      "No obvious 'year', 'time', or 'date' columns found.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "\n",
    "# The path you are trying to read\n",
    "DATASET_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/\"\n",
    "    \"parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\"\n",
    ")\n",
    "\n",
    "def inspect_columns():\n",
    "    print(f\"Inspecting: {DATASET_DIR}\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset object (does not read full data, just schema/metadata)\n",
    "        dataset = ds.dataset(str(DATASET_DIR), format=\"parquet\")\n",
    "        \n",
    "        # Get all column names\n",
    "        cols = dataset.schema.names\n",
    "        \n",
    "        print(f\"\\nFound {len(cols)} columns:\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(cols)\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "        # Check specifically for \"year\" (case-insensitive)\n",
    "        year_candidates = [c for c in cols if \"year\" in c.lower() or \"time\" in c.lower() or \"date\" in c.lower()]\n",
    "        \n",
    "        if year_candidates:\n",
    "            print(f\"\\nPossible time-related columns found: {year_candidates}\")\n",
    "        else:\n",
    "            print(\"\\nNo obvious 'year', 'time', or 'date' columns found.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading dataset: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d75d565-5070-4d14-bc33-d54294040bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_temporal_split_2003_2004/models/xgb_best_pr_auc_temporal.json\n",
      "\n",
      "=== FEATURE IMPORTANCE (Total Gain) ===\n",
      "                    Feature         Gain\n",
      "11       duff_moisture_code  176305920.0\n",
      "9            build_up_index  133733224.0\n",
      "10             drought_code   44027412.0\n",
      "4         relative_humidity   41658844.0\n",
      "8        temperature_2m_max   36435028.0\n",
      "5   total_precipitation_sum   35740504.0\n",
      "6            temperature_2m   34386928.0\n",
      "0                       DEM   32631598.0\n",
      "7        temperature_2m_min   31890110.0\n",
      "12  fine_fuel_moisture_code   31301266.0\n",
      "\n",
      "Top Suspect Feature: duff_moisture_code\n",
      "\n",
      "Loading data for duff_moisture_code to check for shifts...\n",
      "Train/Val Mean: -51.6529\n",
      "Test Mean:      -121.2161\n",
      "Saved histogram to /panfs/ccds02/home/spotter5/fire_projections/diagnostic_shift.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Diagnostic: Identify the 'Cheat' Feature\n",
    "1. Loads the saved model.\n",
    "2. Prints Feature Importance (Gain).\n",
    "3. Plots the histogram of the Top Feature (Train vs Test) to see the shift.\n",
    "\"\"\"\n",
    "\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.dataset as ds\n",
    "from pathlib import Path\n",
    "\n",
    "# CONFIG (Must match your paths)\n",
    "MODEL_PATH = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/ml_training/xgb_pr_auc_temporal_split_2003_2004/models/xgb_best_pr_auc_temporal.json\")\n",
    "DATASET_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/parquet_cems_with_fraction_dataset_burnedlab_mask_analytical\")\n",
    "\n",
    "FEATURES = [\n",
    "    \"DEM\", \"slope\", \"aspect\", \"b1\", \"relative_humidity\", \n",
    "    \"total_precipitation_sum\", \"temperature_2m\", \"temperature_2m_min\", \n",
    "    \"temperature_2m_max\", \"build_up_index\", \"drought_code\", \n",
    "    \"duff_moisture_code\", \"fine_fuel_moisture_code\", \n",
    "    \"fire_weather_index\", \"initial_fire_spread_index\",\n",
    "]\n",
    "TEST_YEARS = [2003, 2004]\n",
    "\n",
    "def main():\n",
    "    # 1. Load Model and Get Importance\n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(str(MODEL_PATH))\n",
    "    \n",
    "    # Get Importance (Total Gain is best for identifying heavy lifters)\n",
    "    importance = booster.get_score(importance_type='total_gain')\n",
    "    imp_df = pd.DataFrame(list(importance.items()), columns=['Feature', 'Gain'])\n",
    "    imp_df = imp_df.sort_values(by='Gain', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== FEATURE IMPORTANCE (Total Gain) ===\")\n",
    "    print(imp_df.head(10))\n",
    "    \n",
    "    top_feature = imp_df.iloc[0]['Feature']\n",
    "    print(f\"\\nTop Suspect Feature: {top_feature}\")\n",
    "    \n",
    "    # 2. Load Data for the Top Feature ONLY\n",
    "    print(f\"\\nLoading data for {top_feature} to check for shifts...\")\n",
    "    dset = ds.dataset(str(DATASET_DIR), format=\"parquet\", partitioning=\"hive\")\n",
    "    cols = [top_feature, \"year\"]\n",
    "    \n",
    "    table = dset.to_table(columns=cols)\n",
    "    df = table.to_pandas()\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "    \n",
    "    # 3. Compare Distributions\n",
    "    val_data = df[~df['year'].isin(TEST_YEARS)][top_feature].dropna()\n",
    "    test_data = df[df['year'].isin(TEST_YEARS)][top_feature].dropna()\n",
    "    \n",
    "    print(f\"Train/Val Mean: {val_data.mean():.4f}\")\n",
    "    print(f\"Test Mean:      {test_data.mean():.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(val_data, bins=50, alpha=0.5, label='Train/Val (2001-2019)', density=True)\n",
    "    plt.hist(test_data, bins=50, alpha=0.5, label='Test (2003-2004)', density=True, color='orange')\n",
    "    plt.title(f\"Distribution Shift: {top_feature}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Save to current directory so you can open it\n",
    "    out_file = Path(\"diagnostic_shift.png\")\n",
    "    plt.savefig(out_file)\n",
    "    print(f\"Saved histogram to {out_file.absolute()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b3efc-ae5e-4b13-94f4-7cc8d8b936bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xgboost_gpu]",
   "language": "python",
   "name": "conda-env-.conda-xgboost_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
