{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3521fc1-a45e-4d9f-a5b2-fc36b7bbfeda",
   "metadata": {},
   "source": [
    "This script will calculate total burned area per year and by ecoregion for fire cci, MCD64a1, and our predictions.  For our predictions we will take monthly predictions and calculate max value to deal with multiple burns in same location across months. For fire cci and mcd64a1 we will call it burned if the fractin is >0.50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33413870-c823-4445-833d-8b105411101d",
   "metadata": {},
   "source": [
    "All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e480936-2cfe-4e9b-a8db-f5275460c101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecoregions...\n",
      "Reading existing burned area CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_all_models.csv\n",
      "Preparing template and reprojecting ecoregions (MCD grid)...\n",
      "\n",
      "Found Option 4 focal prediction model class directories:\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac010_mcd  -> negfrac=10%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac020_mcd  -> negfrac=20%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac030_mcd  -> negfrac=30%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac040_mcd  -> negfrac=40%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac050_mcd  -> negfrac=50%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac060_mcd  -> negfrac=60%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac070_mcd  -> negfrac=70%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac080_mcd  -> negfrac=80%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac090_mcd  -> negfrac=90%\n",
      "  - predictions_option4_focal_10x_negative_auc_thresh_negfrac100_mcd  -> negfrac=100%\n",
      "\n",
      "Checking that prediction grids match native MCD grid (using the first model)...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=10%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac010_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac10\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac10'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=20%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac020_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac20\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac20'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=30%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac030_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac30\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac30'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=40%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac040_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac40\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac40'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=50%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac050_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac50\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac50'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=60%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac060_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac60\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac60'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=70%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac070_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac70\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac70'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=80%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac080_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac80\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac80'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=90%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac090_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac90\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac90'...\n",
      "\n",
      "================================================================================\n",
      "Processing Option 4 focal model: negfrac=100%\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option4_focal_10x_negative_auc_thresh_negfrac100_mcd/class\n",
      "New column name:   ba_pred_Mha_focal10x_negfrac100\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_focal10x_negfrac100'...\n",
      "\n",
      "✅ Saved updated CSV with all Option 4 focal model prediction columns to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_all_models_option4_focal_auc_thresh.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Compute annual burned area (Mha) per ecoregion for ALL Option 4 focal models\n",
    "(10x negatives, AUC-threshold) and merge into existing CSV that already has:\n",
    "\n",
    "  - ba_mcd_native_Mha\n",
    "  - ba_firecci_native_Mha\n",
    "  - ba_pred_Mha (original predictions)\n",
    "  - ba_pred_Mha_* from Option 2, etc.\n",
    "\n",
    "For each prediction directory:\n",
    "\n",
    "  /explore/nobackup/people/spotter5/clelland_fire_ml/\n",
    "      predictions_option4_focal_10x_negative_auc_thresh_negfrac{pct:03d}_mcd/class/\n",
    "\n",
    "we:\n",
    "\n",
    "  - For each year (2001–2023), stack 12 monthly predicted class rasters\n",
    "    (cems_pred_class_YYYY_MM_thr*.tif), take max across months\n",
    "    -> annual 0/1 mask (1=burned at least once in the year).\n",
    "  - For each ecoregion polygon:\n",
    "      * rasterize polygon\n",
    "      * count burned pixels\n",
    "      * multiply by pixel area (m²) and convert to Mha.\n",
    "  - Add a column:\n",
    "\n",
    "      ba_pred_Mha_focal10x_negfrac{pct}\n",
    "\n",
    "    e.g. ba_pred_Mha_focal10x_negfrac10, ba_pred_Mha_focal10x_negfrac50\n",
    "\n",
    "and merge into the existing CSV.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "# Years for MCD / predictions\n",
    "YEARS_MCD = list(range(2001, 2024))\n",
    "MONTHS    = list(range(1, 13))\n",
    "\n",
    "# --- Native MCD monthly fraction rasters (for template / pixel area only) ---\n",
    "NATIVE_MCD_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# Root where prediction dirs live (must match prediction script)\n",
    "PRED_ROOT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml\")\n",
    "\n",
    "# Pattern of prediction dirs created by the Option 4 focal prediction script\n",
    "# e.g. predictions_option4_focal_10x_negative_auc_thresh_negfrac050_mcd\n",
    "PRED_DIR_PATTERN = \"predictions_option4_focal_10x_negative_auc_thresh_negfrac*_mcd\"\n",
    "\n",
    "# Glob pattern for predicted class TIFFs:\n",
    "#   cems_pred_class_YYYY_MM_thr{thr}.tif\n",
    "PRED_CLASS_PATTERN = \"cems_pred_class_{year}_{month:02d}_thr*.tif\"\n",
    "\n",
    "# --- Ecoregion shapefile ---\n",
    "ECOS_PATH = \"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\"\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "# --- Existing + new CSV paths ---\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Existing CSV that already has MCD, FireCCI, Option 2 cols, etc.\n",
    "IN_CSV_OLD  = OUT_DIR / \"burned_area_by_ecoregion_predictions_all_models.csv\"\n",
    "\n",
    "# New CSV with added Option 4 focal cols.\n",
    "# If you prefer to update in place, set this equal to IN_CSV_OLD.\n",
    "OUT_CSV_NEW = OUT_DIR / \"burned_area_by_ecoregion_predictions_all_models_option4_focal_auc_thresh.csv\"\n",
    "\n",
    "\n",
    "# ============================\n",
    "# HELPERS\n",
    "# ============================\n",
    "\n",
    "def find_native_monthly_path(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Try a few reasonable filename variants for the native monthly *_with_fraction.tif.\n",
    "    prefix is 'cems_e5l_mcd'.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        base_dir / f\"{prefix}_{year}_{month}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month}.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}.tif\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_template_path_native(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    years,\n",
    "    months\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find one existing native monthly file to use as template (for CRS, transform, shape).\n",
    "    \"\"\"\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            p = find_native_monthly_path(base_dir, prefix, y, m)\n",
    "            if p is not None:\n",
    "                return p\n",
    "    raise FileNotFoundError(f\"No native files found for prefix {prefix} in {base_dir}\")\n",
    "\n",
    "\n",
    "def find_pred_class_month_path(\n",
    "    pred_class_dir: Path,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find predicted class raster for given year/month in a given model dir.\n",
    "    Expects filenames like cems_pred_class_YYYY_MM_thr*.tif\n",
    "    \"\"\"\n",
    "    matches = list(pred_class_dir.glob(PRED_CLASS_PATTERN.format(year=year, month=month)))\n",
    "    if matches:\n",
    "        # If multiple thresholds exist, just use the first one\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_annual_pred_mask(\n",
    "    year: int,\n",
    "    months,\n",
    "    pred_class_dir: Path\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build annual 0/1 burned mask from predicted monthly class rasters for given year.\n",
    "    Assumes class TIFF has 1=burned, 0=unburned, 255=nodata.\n",
    "    Returns uint8 array with shape (H, W) or None if no months are found.\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "\n",
    "    for m in months:\n",
    "        src_path = find_pred_class_month_path(pred_class_dir, year, m)\n",
    "        if src_path is None:\n",
    "            continue\n",
    "\n",
    "        with rio.open(src_path) as ds:\n",
    "            arr = ds.read(1)\n",
    "            monthly_burn = (arr == 1).astype(np.uint8)\n",
    "\n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "            else:\n",
    "                annual = np.maximum(annual, monthly_burn)\n",
    "\n",
    "    return annual\n",
    "\n",
    "\n",
    "def prepare_ecos_for_dataset(template_path: Path, ecos: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Open template raster, check CRS, compute pixel area, and reproject ecos to that CRS.\n",
    "    \"\"\"\n",
    "    with rio.open(template_path) as ds:\n",
    "        crs = ds.crs\n",
    "        transform = ds.transform\n",
    "        height, width = ds.height, ds.width\n",
    "\n",
    "        if crs is None:\n",
    "            raise ValueError(f\"Template {template_path} has no CRS\")\n",
    "\n",
    "        if crs.is_geographic:\n",
    "            raise ValueError(\n",
    "                f\"Template CRS {crs} is geographic (degrees). \"\n",
    "                \"Reproject rasters to an equal-area projection (meters) before area calculation.\"\n",
    "            )\n",
    "\n",
    "        pixel_area_m2 = abs(transform.a * transform.e)  # a=width, e=height (negative)\n",
    "        ecos_reproj = ecos.to_crs(crs)\n",
    "\n",
    "    return ecos_reproj, transform, (height, width), pixel_area_m2\n",
    "\n",
    "\n",
    "def compute_area_per_ecoregion(\n",
    "    annual_mask: np.ndarray,\n",
    "    ecos_reproj: gpd.GeoDataFrame,\n",
    "    transform,\n",
    "    pixel_area_m2: float,\n",
    "    id_col: str,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Given an annual 0/1 mask and an ecoregion GeoDataFrame (already in raster CRS),\n",
    "    compute burned area (Mha) for each ecoregion.\n",
    "    Returns dict: {ecoregion_id: burned_area_Mha}\n",
    "    \"\"\"\n",
    "    height, width = annual_mask.shape\n",
    "    results = {}\n",
    "\n",
    "    for idx, row in ecos_reproj.iterrows():\n",
    "        eco_id = row[id_col]\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            results[eco_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        eco_mask = geometry_mask(\n",
    "            [geom.__geo_interface__],\n",
    "            transform=transform,\n",
    "            invert=True,\n",
    "            out_shape=(height, width),\n",
    "        )\n",
    "\n",
    "        burned_pixels = (annual_mask == 1) & eco_mask\n",
    "        area_m2 = burned_pixels.sum() * pixel_area_m2\n",
    "        area_Mha = area_m2 / 1e10  # m^2 -> Mha\n",
    "\n",
    "        results[eco_id] = area_Mha\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_negfrac_from_dir(dirname: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Parse neg_fraction_pct from a prediction directory name, e.g.:\n",
    "\n",
    "      predictions_option4_focal_10x_negative_auc_thresh_negfrac050_mcd\n",
    "\n",
    "    Returns neg_fraction_pct as int (e.g. 50) or None if it doesn't match.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"negfrac(\\d{2,3})_mcd\", dirname)\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1))  # e.g. 050 -> 50\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    # ---------- Load ecoregions & old CSV ----------\n",
    "    print(\"Loading ecoregions...\")\n",
    "    ecos = gpd.read_file(ECOS_PATH)\n",
    "    if ECO_ID_COL not in ecos.columns:\n",
    "        raise ValueError(\n",
    "            f\"ECO_ID_COL='{ECO_ID_COL}' not found in {ECOS_PATH}. \"\n",
    "            f\"Columns: {list(ecos.columns)}\"\n",
    "        )\n",
    "\n",
    "    print(f\"Reading existing burned area CSV: {IN_CSV_OLD}\")\n",
    "    df_old = pd.read_csv(IN_CSV_OLD)\n",
    "\n",
    "    # ---------- Prepare template & reproject ecos ----------\n",
    "    print(\"Preparing template and reprojecting ecoregions (MCD grid)...\")\n",
    "    tmpl_mcd_native = find_template_path_native(\n",
    "        NATIVE_MCD_DIR, \"cems_e5l_mcd\", YEARS_MCD, MONTHS\n",
    "    )\n",
    "    ecos_mcd, transform_mcd, shape_mcd, pixel_area_mcd = prepare_ecos_for_dataset(\n",
    "        tmpl_mcd_native, ecos\n",
    "    )\n",
    "\n",
    "    # ---------- Find all Option 4 focal model 'class' directories ----------\n",
    "    pred_class_dirs = sorted(PRED_ROOT_DIR.glob(f\"{PRED_DIR_PATTERN}/class\"))\n",
    "    if not pred_class_dirs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No prediction class directories matching '{PRED_DIR_PATTERN}' under {PRED_ROOT_DIR}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nFound Option 4 focal prediction model class directories:\")\n",
    "    model_info = []  # list of (neg_pct, class_dir)\n",
    "    for class_dir in pred_class_dirs:\n",
    "        neg_pct = parse_negfrac_from_dir(class_dir.parent.name)\n",
    "        if neg_pct is None:\n",
    "            print(f\"  [SKIP] Could not parse negfrac from: {class_dir.parent.name}\")\n",
    "            continue\n",
    "        print(f\"  - {class_dir.parent.name}  -> negfrac={neg_pct}%\")\n",
    "        model_info.append((neg_pct, class_dir))\n",
    "\n",
    "    if not model_info:\n",
    "        raise RuntimeError(\"No valid Option 4 focal model prediction directories parsed from names.\")\n",
    "\n",
    "    # ---------- Check that prediction grids match native MCD grid ----------\n",
    "    print(\"\\nChecking that prediction grids match native MCD grid (using the first model)...\")\n",
    "    first_class_dir = model_info[0][1]\n",
    "    tmpl_new_pred = None\n",
    "    for y in YEARS_MCD:\n",
    "        for m in MONTHS:\n",
    "            p = find_pred_class_month_path(first_class_dir, y, m)\n",
    "            if p is not None:\n",
    "                tmpl_new_pred = p\n",
    "                break\n",
    "        if tmpl_new_pred is not None:\n",
    "            break\n",
    "\n",
    "    if tmpl_new_pred is None:\n",
    "        raise FileNotFoundError(f\"No prediction class files found in {first_class_dir}\")\n",
    "\n",
    "    with rio.open(tmpl_new_pred) as ds_pred, rio.open(tmpl_mcd_native) as ds_nat:\n",
    "        if (\n",
    "            ds_pred.transform != ds_nat.transform\n",
    "            or ds_pred.width != ds_nat.width\n",
    "            or ds_pred.height != ds_nat.height\n",
    "        ):\n",
    "            raise ValueError(\"Predicted MCD grid does not match native MCD grid.\")\n",
    "\n",
    "    # ---------- Start from the existing CSV and add columns per model ----------\n",
    "    df_merged = df_old.copy()\n",
    "\n",
    "    # ---------- For each model, compute burned area and merge ----------\n",
    "    for neg_pct, class_dir in model_info:\n",
    "        col_name = f\"ba_pred_Mha_focal10x_negfrac{neg_pct}\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Processing Option 4 focal model: negfrac={neg_pct}%\")\n",
    "        print(f\"Class rasters dir: {class_dir}\")\n",
    "        print(f\"New column name:   {col_name}\")\n",
    "\n",
    "        results = {}  # key: (eco_id, year) -> area\n",
    "\n",
    "        for year in YEARS_MCD:\n",
    "            print(f\"  Year {year}...\")\n",
    "            annual_mask = build_annual_pred_mask(year, MONTHS, class_dir)\n",
    "            if annual_mask is None:\n",
    "                print(f\"    -> No predictions found for {year} in {class_dir}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            if annual_mask.shape != shape_mcd:\n",
    "                raise ValueError(\n",
    "                    f\"Shape mismatch for predictions {year} in {class_dir}: \"\n",
    "                    f\"{annual_mask.shape} vs {shape_mcd}\"\n",
    "                )\n",
    "\n",
    "            area_dict = compute_area_per_ecoregion(\n",
    "                annual_mask, ecos_mcd, transform_mcd, pixel_area_mcd, ECO_ID_COL\n",
    "            )\n",
    "\n",
    "            for eco_id, area_Mha in area_dict.items():\n",
    "                results[(eco_id, year)] = area_Mha\n",
    "\n",
    "        if not results:\n",
    "            print(f\"  -> No valid annual masks computed for model negfrac{neg_pct}; skipping merge.\")\n",
    "            continue\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        rows = []\n",
    "        for (eco_id, year), area_Mha in results.items():\n",
    "            rows.append({ECO_ID_COL: eco_id, \"year\": year, col_name: area_Mha})\n",
    "        df_new = pd.DataFrame(rows)\n",
    "\n",
    "        print(f\"  Merging {len(df_new)} rows into main CSV for column '{col_name}'...\")\n",
    "        df_merged = df_merged.merge(df_new, on=[ECO_ID_COL, \"year\"], how=\"left\")\n",
    "\n",
    "    # ---------- Final save ----------\n",
    "    df_merged = df_merged.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "    df_merged.to_csv(OUT_CSV_NEW, index=False)\n",
    "\n",
    "    print(\"\\n✅ Saved updated CSV with all Option 4 focal model prediction columns to:\")\n",
    "    print(f\"  {OUT_CSV_NEW}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b32c1-cbfa-4039-87ae-68ae21ebb26f",
   "metadata": {},
   "source": [
    "All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3e9753-7b4f-4fa6-b22a-ed9175f4974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_all_models_option4_focal_auc_thresh.csv\n",
      "Option 4 focal prediction columns to plot:\n",
      "  - ba_pred_Mha_focal10x_negfrac10\n",
      "  - ba_pred_Mha_focal10x_negfrac20\n",
      "  - ba_pred_Mha_focal10x_negfrac30\n",
      "  - ba_pred_Mha_focal10x_negfrac40\n",
      "  - ba_pred_Mha_focal10x_negfrac50\n",
      "  - ba_pred_Mha_focal10x_negfrac60\n",
      "  - ba_pred_Mha_focal10x_negfrac70\n",
      "  - ba_pred_Mha_focal10x_negfrac80\n",
      "  - ba_pred_Mha_focal10x_negfrac90\n",
      "  - ba_pred_Mha_focal10x_negfrac100\n",
      "Found 23 ecoregions after exclusion: ['ALASKA BOREAL INTERIOR', 'ALASKA TUNDRA', 'ARCTIC CORDILLERA', 'Arctic Deserts and Tundra', 'BOREAL CORDILLERA', 'BOREAL PLAIN', 'BROOKS RANGE TUNDRA', 'Central Taiga', 'Forest Tundra', 'HUDSON PLAIN', 'MARINE WEST COAST FOREST', 'Montane Boreal', 'Montane Sub-Arctic', 'Montane Sub-Boreal', 'NORTHERN ARCTIC', 'Northern Taiga', 'SOFTWOOD SHIELD', 'SOUTHERN ARCTIC', 'Southern Taiga', 'TAIGA CORDILLERA', 'TAIGA PLAIN', 'TAIGA SHIELD', 'Wetlands']\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac10\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac10 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac10.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac20\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac20 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac20.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac30\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac30 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac30.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac40\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac40 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac40.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac50\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac50 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac50.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac60\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac60 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac60.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac70\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac70 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac70.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac80\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac80 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac80.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac90\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac90 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac90.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_focal10x_negfrac100\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_focal10x_negfrac100 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh/burned_area_multipanel_focal10x_negfrac100.png\n",
      "\n",
      "✅ Done. One multipanel PNG per Option 4 focal prediction model written to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_option4_focal10x_auc_thresh\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "For EACH Option 4 focal prediction column (ba_pred_Mha_focal10x_negfracXX, ...),\n",
    "create a multipanel plot (ecoregions as subplots) comparing:\n",
    "\n",
    "    - MCD64A1 (ba_mcd_native_Mha)\n",
    "    - Fire CCI (ba_firecci_native_Mha)\n",
    "    - That specific Option 4 focal prediction column\n",
    "\n",
    "Input:\n",
    "    burned_area_by_ecoregion_predictions_all_models_option4_focal_auc_thresh.csv\n",
    "\n",
    "Output:\n",
    "    <OUT_DIR>/multipanel_option4_focal10x_auc_thresh/\n",
    "        burned_area_multipanel_<pred_col>.png\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "IN_CSV  = OUT_DIR / \"burned_area_by_ecoregion_predictions_all_models_option4_focal_auc_thresh.csv\"\n",
    "\n",
    "# Folder where all multipanel PNGs (one per focal model) will go\n",
    "OUT_PNG_DIR = OUT_DIR / \"multipanel_option4_focal10x_auc_thresh\"\n",
    "OUT_PNG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base / native columns\n",
    "MCD_COL      = \"ba_mcd_native_Mha\"\n",
    "FIRECCI_COL  = \"ba_firecci_native_Mha\"\n",
    "\n",
    "BASE_LABELS = {\n",
    "    MCD_COL: \"MCD64A1\",\n",
    "    FIRECCI_COL: \"Fire CCI\",\n",
    "}\n",
    "\n",
    "# Ecoregions to exclude from plotting\n",
    "EXCLUDE_ECOS = {\n",
    "    \"WATER\",\n",
    "    \"MIXED WOOD SHIELD\",\n",
    "    \"TEMPERATE PRAIRIES\",\n",
    "    \"WESTERN CORDILLERA\",\n",
    "}\n",
    "\n",
    "\n",
    "def nice_pred_label(colname: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn prediction column names into nicer legend labels.\n",
    "\n",
    "    Examples:\n",
    "      ba_pred_Mha                         -> \"Pred (orig)\"\n",
    "      ba_pred_Mha_neg50_w2                -> \"Pred neg50 w2\"\n",
    "      ba_pred_Mha_focal10x_negfrac50      -> \"Focal10x negfrac50%\"\n",
    "    \"\"\"\n",
    "    if colname == \"ba_pred_Mha\":\n",
    "        return \"Pred (orig)\"\n",
    "\n",
    "    # Option 4 focal 10x pattern\n",
    "    if colname.startswith(\"ba_pred_Mha_focal10x_negfrac\"):\n",
    "        # try to extract the percent for a slightly nicer label\n",
    "        m = re.search(r\"negfrac(\\d+)$\", colname)\n",
    "        if m:\n",
    "            pct = m.group(1)\n",
    "            return f\"Focal10x negfrac{pct}%\"\n",
    "        return \"Focal10x (AUC-thresh)\"\n",
    "\n",
    "    if colname.startswith(\"ba_pred_Mha_\"):\n",
    "        sfx = colname.replace(\"ba_pred_Mha_\", \"\").replace(\"_\", \" \")\n",
    "        return f\"Pred {sfx}\"\n",
    "\n",
    "    return colname\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(f\"Reading CSV: {IN_CSV}\")\n",
    "    df = pd.read_csv(IN_CSV)\n",
    "\n",
    "    # Basic sanity check\n",
    "    needed_base = [ECO_ID_COL, \"year\", MCD_COL, FIRECCI_COL]\n",
    "    missing_base = [c for c in needed_base if c not in df.columns]\n",
    "    if missing_base:\n",
    "        raise ValueError(f\"Missing base columns in CSV: {missing_base}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "\n",
    "    # Find all Option 4 focal prediction columns\n",
    "    # (anything starting with 'ba_pred_Mha_focal10x_')\n",
    "    pred_cols = [c for c in df.columns if c.startswith(\"ba_pred_Mha_focal10x_\")]\n",
    "    if not pred_cols:\n",
    "        raise ValueError(\n",
    "            \"No Option 4 focal prediction columns starting with \"\n",
    "            \"'ba_pred_Mha_focal10x_' found in CSV.\"\n",
    "        )\n",
    "\n",
    "    print(\"Option 4 focal prediction columns to plot:\")\n",
    "    for c in pred_cols:\n",
    "        print(\"  -\", c)\n",
    "\n",
    "    # Unique ecoregions excluding the undesired ones\n",
    "    ecos_all = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    ecos_list = [e for e in ecos_all if e not in EXCLUDE_ECOS]\n",
    "\n",
    "    if not ecos_list:\n",
    "        print(\"No ecoregions left after exclusion; nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    n_ecos = len(ecos_list)\n",
    "    print(f\"Found {n_ecos} ecoregions after exclusion: {ecos_list}\")\n",
    "\n",
    "    # Loop over each prediction column and make a separate multipanel PNG\n",
    "    for pred_col in pred_cols:\n",
    "        print(\"\\n==============================================\")\n",
    "        print(f\"Creating multipanel plot for prediction column: {pred_col}\")\n",
    "\n",
    "        # Columns to plot in this figure\n",
    "        COLS_AREA = [MCD_COL, FIRECCI_COL, pred_col]\n",
    "        LABELS = {\n",
    "            MCD_COL: BASE_LABELS[MCD_COL],\n",
    "            FIRECCI_COL: BASE_LABELS[FIRECCI_COL],\n",
    "            pred_col: nice_pred_label(pred_col),\n",
    "        }\n",
    "\n",
    "        # Layout: up to 4 columns of subplots\n",
    "        ncols = 4 if n_ecos > 4 else n_ecos\n",
    "        nrows = int(np.ceil(n_ecos / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(4 * ncols, 3 * nrows),\n",
    "            sharex=True,\n",
    "            sharey=False,  # floating y-axis per panel\n",
    "        )\n",
    "\n",
    "        # Normalize axes to 2D array\n",
    "        if nrows == 1 and ncols == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif nrows == 1:\n",
    "            axes = np.array([axes])\n",
    "        elif ncols == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "\n",
    "        handles_for_legend, labels_for_legend = None, None\n",
    "\n",
    "        # Plot per ecoregion\n",
    "        for i, eco_id in enumerate(ecos_list):\n",
    "            row = i // ncols\n",
    "            col = i % ncols\n",
    "            ax = axes[row, col]\n",
    "\n",
    "            df_eco = df[df[ECO_ID_COL] == eco_id]\n",
    "\n",
    "            # Plot all three datasets for this model\n",
    "            for col_name in COLS_AREA:\n",
    "                if col_name in df_eco.columns and df_eco[col_name].notna().any():\n",
    "                    ax.plot(\n",
    "                        df_eco[\"year\"],\n",
    "                        df_eco[col_name],\n",
    "                        marker=\"o\",\n",
    "                        label=LABELS[col_name],\n",
    "                    )\n",
    "\n",
    "            # Capture legend handles from first non-empty panel\n",
    "            if handles_for_legend is None:\n",
    "                h, l = ax.get_legend_handles_labels()\n",
    "                if h:\n",
    "                    handles_for_legend, labels_for_legend = h, l\n",
    "\n",
    "            ax.set_title(str(eco_id))\n",
    "            ax.grid(True, ls=\"--\", alpha=0.4)\n",
    "\n",
    "            # Floating y-axis logic: choose sensible default if all zeros / NaN\n",
    "            ydata_list = [df_eco[c].dropna().values for c in COLS_AREA if c in df_eco.columns]\n",
    "            if ydata_list:\n",
    "                ydata = np.concatenate(ydata_list)\n",
    "                if ydata.size == 0 or np.nanmax(ydata) == 0:\n",
    "                    ax.set_ylim(0, 1.0)\n",
    "            else:\n",
    "                ax.set_ylim(0, 1.0)\n",
    "\n",
    "            if row == nrows - 1:\n",
    "                ax.set_xlabel(\"Year\")\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"Burned area (Mha)\")\n",
    "\n",
    "        # Hide unused panels\n",
    "        total_plots = nrows * ncols\n",
    "        if total_plots > n_ecos:\n",
    "            for j in range(n_ecos, total_plots):\n",
    "                row = j // ncols\n",
    "                col = j % ncols\n",
    "                axes[row, col].axis(\"off\")\n",
    "\n",
    "        # Global legend at bottom\n",
    "        if handles_for_legend:\n",
    "            fig.legend(\n",
    "                handles_for_legend,\n",
    "                labels_for_legend,\n",
    "                loc=\"lower center\",\n",
    "                ncol=len(handles_for_legend),\n",
    "                bbox_to_anchor=(0.5, -0.02),\n",
    "            )\n",
    "\n",
    "        # Clean filenames: replace spaces with underscores\n",
    "        pred_tag = pred_col.replace(\"ba_pred_Mha_\", \"\") if pred_col != \"ba_pred_Mha\" else \"orig\"\n",
    "        pred_tag = pred_tag.replace(\" \", \"_\")\n",
    "\n",
    "        out_png = OUT_PNG_DIR / f\"burned_area_multipanel_{pred_tag}.png\"\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "        plt.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"  -> Saved multipanel PNG for {pred_col} to:\\n     {out_png}\")\n",
    "\n",
    "    print(\"\\n✅ Done. One multipanel PNG per Option 4 focal prediction model written to:\")\n",
    "    print(f\"  {OUT_PNG_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e9287-0452-42e8-a083-3b7206f29d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning_old]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning_old-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
