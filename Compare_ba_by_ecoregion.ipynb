{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3521fc1-a45e-4d9f-a5b2-fc36b7bbfeda",
   "metadata": {},
   "source": [
    "This script will calculate total burned area per year and by ecoregion for fire cci, MCD64a1, and our predictions.  For our predictions we will take monthly predictions and calculate max value to deal with multiple burns in same location across months. For fire cci and mcd64a1 we will call it burned if the fractin is >0.50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2732c6-fb32-4ffe-9465-80752c33d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#ecoregion columns is unique identifier, convert to crs of rasters when extracting by mask\n",
    "ecos = gpd.read_file(\"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff40fa26-79a2-4530-8a71-b69a8ee62ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecoregions...\n",
      "Preparing templates and reprojecting ecoregions...\n",
      "\n",
      "[1/3] Processing native MCD64A1...\n",
      "  Year 2001 (native MCD64A1)\n",
      "  Year 2002 (native MCD64A1)\n",
      "  Year 2003 (native MCD64A1)\n",
      "  Year 2004 (native MCD64A1)\n",
      "  Year 2005 (native MCD64A1)\n",
      "  Year 2006 (native MCD64A1)\n",
      "  Year 2007 (native MCD64A1)\n",
      "  Year 2008 (native MCD64A1)\n",
      "  Year 2009 (native MCD64A1)\n",
      "  Year 2010 (native MCD64A1)\n",
      "  Year 2011 (native MCD64A1)\n",
      "  Year 2012 (native MCD64A1)\n",
      "  Year 2013 (native MCD64A1)\n",
      "  Year 2014 (native MCD64A1)\n",
      "  Year 2015 (native MCD64A1)\n",
      "  Year 2016 (native MCD64A1)\n",
      "  Year 2017 (native MCD64A1)\n",
      "  Year 2018 (native MCD64A1)\n",
      "  Year 2019 (native MCD64A1)\n",
      "  Year 2020 (native MCD64A1)\n",
      "  Year 2021 (native MCD64A1)\n",
      "  Year 2022 (native MCD64A1)\n",
      "  Year 2023 (native MCD64A1)\n",
      "\n",
      "[2/3] Processing native FireCCI...\n",
      "  Year 2001 (native FireCCI)\n",
      "  Year 2002 (native FireCCI)\n",
      "  Year 2003 (native FireCCI)\n",
      "  Year 2004 (native FireCCI)\n",
      "  Year 2005 (native FireCCI)\n",
      "  Year 2006 (native FireCCI)\n",
      "  Year 2007 (native FireCCI)\n",
      "  Year 2008 (native FireCCI)\n",
      "  Year 2009 (native FireCCI)\n",
      "  Year 2010 (native FireCCI)\n",
      "  Year 2011 (native FireCCI)\n",
      "  Year 2012 (native FireCCI)\n",
      "  Year 2013 (native FireCCI)\n",
      "  Year 2014 (native FireCCI)\n",
      "  Year 2015 (native FireCCI)\n",
      "  Year 2016 (native FireCCI)\n",
      "  Year 2017 (native FireCCI)\n",
      "  Year 2018 (native FireCCI)\n",
      "  Year 2019 (native FireCCI)\n",
      "\n",
      "[3/3] Processing predictions (MCD model)...\n",
      "  Year 2001 (predictions / MCD model)\n",
      "  Year 2002 (predictions / MCD model)\n",
      "  Year 2003 (predictions / MCD model)\n",
      "  Year 2004 (predictions / MCD model)\n",
      "  Year 2005 (predictions / MCD model)\n",
      "  Year 2006 (predictions / MCD model)\n",
      "  Year 2007 (predictions / MCD model)\n",
      "  Year 2008 (predictions / MCD model)\n",
      "  Year 2009 (predictions / MCD model)\n",
      "  Year 2010 (predictions / MCD model)\n",
      "  Year 2011 (predictions / MCD model)\n",
      "  Year 2012 (predictions / MCD model)\n",
      "  Year 2013 (predictions / MCD model)\n",
      "  Year 2014 (predictions / MCD model)\n",
      "  Year 2015 (predictions / MCD model)\n",
      "  Year 2016 (predictions / MCD model)\n",
      "  Year 2017 (predictions / MCD model)\n",
      "  Year 2018 (predictions / MCD model)\n",
      "  Year 2019 (predictions / MCD model)\n",
      "  Year 2020 (predictions / MCD model)\n",
      "  Year 2021 (predictions / MCD model)\n",
      "  Year 2022 (predictions / MCD model)\n",
      "  Year 2023 (predictions / MCD model)\n",
      "\n",
      "Building DataFrame and saving CSV...\n",
      "Saved per-ecoregion annual burned area to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions.csv\n",
      "Creating multipanel plot (one panel per ecoregion)...\n",
      "Saved multipanel per-ecoregion plot to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_multipanel_by_ecoregion.png\n",
      "\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Compute annual burned area (Mha) per ecoregion for three datasets:\n",
    "\n",
    "  1) Native MCD64A1 (monthly fraction > 0.5 -> burned)\n",
    "  2) Native FireCCI  (monthly fraction > 0.5 -> burned)\n",
    "  3) Predictions (MCD64A1 model outputs; monthly class TIFFs, 1=burned)\n",
    "\n",
    "Steps per dataset:\n",
    "  - For each year, stack 12 monthly rasters, take max across months -> annual 0/1 mask.\n",
    "  - For each ecoregion polygon (from merge_eco_v2.shp):\n",
    "      * rasterize a polygon mask on the same grid\n",
    "      * count burned pixels inside the polygon\n",
    "      * multiply by pixel area (assumes projected CRS in meters)\n",
    "      * convert to Mha.\n",
    "\n",
    "Outputs:\n",
    "  - CSV: burned_area_by_ecoregion_predictions.csv\n",
    "  - PNG: burned_area_multipanel_by_ecoregion.png  (one panel per ecoregion)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import geometry_mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "# Years\n",
    "YEARS_FIRECCI = list(range(2001, 2020))   # Native FireCCI\n",
    "YEARS_MCD     = list(range(2001, 2024))   # Native MCD + predictions\n",
    "\n",
    "MONTHS = list(range(1, 13))               # 1..12\n",
    "\n",
    "# --- Native monthly fraction rasters (last band = \"fraction\") ---\n",
    "NATIVE_FIRECCI_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_firecci_with_fraction\"\n",
    ")\n",
    "NATIVE_MCD_DIR     = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# --- Predicted class rasters (0/1, 255 nodata) ---\n",
    "# MCD predictions live here:\n",
    "PRED_MCD_DIR       = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg040pct_w3_mcd\"\n",
    ")\n",
    "PRED_MCD_CLASS_DIR = PRED_MCD_DIR / \"class\"\n",
    "\n",
    "# Glob pattern for predicted class TIFFs:\n",
    "#   cems_pred_class_YYYY_MM_thr{thr}.tif\n",
    "PRED_CLASS_PATTERN = \"cems_pred_class_{year}_{month:02d}_thr*.tif\"\n",
    "\n",
    "# --- Ecoregion shapefile ---\n",
    "ECOS_PATH = \"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\"\n",
    "\n",
    "# Column in ecos that uniquely identifies an ecoregion\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "# --- Output paths ---\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = OUT_DIR / \"burned_area_by_ecoregion_predictions.csv\"\n",
    "OUT_PNG_MULTIPANEL = OUT_DIR / \"burned_area_multipanel_by_ecoregion.png\"\n",
    "\n",
    "# Threshold for native monthly \"fraction\" band to consider burned\n",
    "FRACTION_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "# ============================\n",
    "# HELPERS\n",
    "# ============================\n",
    "\n",
    "def find_native_monthly_path(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Try a few reasonable filename variants for the native monthly *_with_fraction.tif.\n",
    "    prefix is 'cems_e5l_mcd' or 'cems_e5l_firecci'.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        base_dir / f\"{prefix}_{year}_{month}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month}.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}.tif\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_annual_native_mask(\n",
    "    year: int,\n",
    "    months,\n",
    "    base_dir: Path,\n",
    "    prefix: str\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build annual 0/1 burned mask from native monthly fraction rasters for given year.\n",
    "    Returns uint8 array with shape (H, W) or None if no months found.\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "\n",
    "    for m in months:\n",
    "        src_path = find_native_monthly_path(base_dir, prefix, year, m)\n",
    "        if src_path is None:\n",
    "            continue\n",
    "\n",
    "        with rio.open(src_path) as ds:\n",
    "            # assume last band is 'fraction'\n",
    "            frac = ds.read(ds.count).astype(np.float32)\n",
    "            monthly_burn = (frac > FRACTION_THRESHOLD) & np.isfinite(frac)\n",
    "            monthly_burn = monthly_burn.astype(np.uint8)\n",
    "\n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "            else:\n",
    "                annual = np.maximum(annual, monthly_burn)\n",
    "\n",
    "    return annual\n",
    "\n",
    "\n",
    "def find_pred_class_month_path(\n",
    "    pred_class_dir: Path,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find predicted class raster for given year/month.\n",
    "    Expects filenames like cems_pred_class_YYYY_MM_thr*.tif\n",
    "    \"\"\"\n",
    "    matches = list(pred_class_dir.glob(PRED_CLASS_PATTERN.format(year=year, month=month)))\n",
    "    if matches:\n",
    "        # If multiple thresholds exist, just use the first one\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_annual_pred_mask(\n",
    "    year: int,\n",
    "    months,\n",
    "    pred_class_dir: Path\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build annual 0/1 burned mask from predicted monthly class rasters for given year.\n",
    "    Assumes class TIFF has 1=burned, 0=unburned, 255=nodata.\n",
    "    Returns uint8 array with shape (H, W) or None if no months are found.\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "\n",
    "    for m in months:\n",
    "        src_path = find_pred_class_month_path(pred_class_dir, year, m)\n",
    "        if src_path is None:\n",
    "            continue\n",
    "\n",
    "        with rio.open(src_path) as ds:\n",
    "            arr = ds.read(1)\n",
    "            monthly_burn = (arr == 1).astype(np.uint8)\n",
    "\n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "            else:\n",
    "                annual = np.maximum(annual, monthly_burn)\n",
    "\n",
    "    return annual\n",
    "\n",
    "\n",
    "def find_template_path_native(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    years,\n",
    "    months\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find one existing native monthly file to use as template (for CRS, transform, shape).\n",
    "    \"\"\"\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            p = find_native_monthly_path(base_dir, prefix, y, m)\n",
    "            if p is not None:\n",
    "                return p\n",
    "    raise FileNotFoundError(f\"No native files found for prefix {prefix} in {base_dir}\")\n",
    "\n",
    "\n",
    "def find_template_path_pred(\n",
    "    pred_class_dir: Path,\n",
    "    years,\n",
    "    months\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find one existing predicted class file to use as template.\n",
    "    \"\"\"\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            p = find_pred_class_month_path(pred_class_dir, y, m)\n",
    "            if p is not None:\n",
    "                return p\n",
    "    raise FileNotFoundError(f\"No predicted class files found in {pred_class_dir}\")\n",
    "\n",
    "\n",
    "def prepare_ecos_for_dataset(template_path: Path, ecos: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Open template raster, check CRS, compute pixel area, and reproject ecos to that CRS.\n",
    "    \"\"\"\n",
    "    with rio.open(template_path) as ds:\n",
    "        crs = ds.crs\n",
    "        transform = ds.transform\n",
    "        height, width = ds.height, ds.width\n",
    "\n",
    "        if crs is None:\n",
    "            raise ValueError(f\"Template {template_path} has no CRS\")\n",
    "\n",
    "        if crs.is_geographic:\n",
    "            raise ValueError(\n",
    "                f\"Template CRS {crs} is geographic (degrees). \"\n",
    "                \"Reproject rasters to an equal-area projection (meters) before area calculation.\"\n",
    "            )\n",
    "\n",
    "        pixel_area_m2 = abs(transform.a * transform.e)  # a=width, e=height (negative)\n",
    "        ecos_reproj = ecos.to_crs(crs)\n",
    "\n",
    "    return ecos_reproj, transform, (height, width), pixel_area_m2\n",
    "\n",
    "\n",
    "def compute_area_per_ecoregion(\n",
    "    annual_mask: np.ndarray,\n",
    "    ecos_reproj: gpd.GeoDataFrame,\n",
    "    transform,\n",
    "    pixel_area_m2: float,\n",
    "    id_col: str,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Given an annual 0/1 mask and an ecoregion GeoDataFrame (already in raster CRS),\n",
    "    compute burned area (Mha) for each ecoregion.\n",
    "    Returns dict: {ecoregion_id: burned_area_Mha}\n",
    "    \"\"\"\n",
    "    height, width = annual_mask.shape\n",
    "    results = {}\n",
    "\n",
    "    for idx, row in ecos_reproj.iterrows():\n",
    "        eco_id = row[id_col]\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            results[eco_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        eco_mask = geometry_mask(\n",
    "            [geom.__geo_interface__],\n",
    "            transform=transform,\n",
    "            invert=True,\n",
    "            out_shape=(height, width),\n",
    "        )\n",
    "\n",
    "        burned_pixels = (annual_mask == 1) & eco_mask\n",
    "        area_m2 = burned_pixels.sum() * pixel_area_m2\n",
    "        area_Mha = area_m2 / 1e10  # m^2 -> Mha\n",
    "\n",
    "        results[eco_id] = area_Mha\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(\"Loading ecoregions...\")\n",
    "    ecos = gpd.read_file(ECOS_PATH)\n",
    "    if ECO_ID_COL not in ecos.columns:\n",
    "        raise ValueError(f\"ECO_ID_COL='{ECO_ID_COL}' not found in {ECOS_PATH}. Columns: {list(ecos.columns)}\")\n",
    "\n",
    "    # ------------- Prepare templates + reproject ecos -------------\n",
    "    print(\"Preparing templates and reprojecting ecoregions...\")\n",
    "\n",
    "    # MCD (native & predictions) use same grid\n",
    "    tmpl_mcd_native = find_template_path_native(NATIVE_MCD_DIR, \"cems_e5l_mcd\", YEARS_MCD, MONTHS)\n",
    "    ecos_mcd, transform_mcd, shape_mcd, pixel_area_mcd = prepare_ecos_for_dataset(tmpl_mcd_native, ecos)\n",
    "\n",
    "    # FireCCI (native) grid\n",
    "    tmpl_firecci_native = find_template_path_native(NATIVE_FIRECCI_DIR, \"cems_e5l_firecci\", YEARS_FIRECCI, MONTHS)\n",
    "    ecos_firecci, transform_firecci, shape_firecci, pixel_area_firecci = prepare_ecos_for_dataset(tmpl_firecci_native, ecos)\n",
    "\n",
    "    # ------------- Accumulate results -------------\n",
    "    # Key: (eco_id, year) -> dict of values\n",
    "    results = {}\n",
    "\n",
    "    def update_results(eco_id, year, col_name, value):\n",
    "        key = (eco_id, year)\n",
    "        if key not in results:\n",
    "            results[key] = {ECO_ID_COL: eco_id, \"year\": year}\n",
    "        results[key][col_name] = value\n",
    "\n",
    "    # --- 1) Native MCD ---\n",
    "    print(\"\\n[1/3] Processing native MCD64A1...\")\n",
    "    for year in YEARS_MCD:\n",
    "        print(f\"  Year {year} (native MCD64A1)\")\n",
    "        annual_mask = build_annual_native_mask(year, MONTHS, NATIVE_MCD_DIR, \"cems_e5l_mcd\")\n",
    "        if annual_mask is None:\n",
    "            print(f\"    -> No native MCD data found for {year}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if annual_mask.shape != shape_mcd:\n",
    "            raise ValueError(f\"Shape mismatch for native MCD {year}: {annual_mask.shape} vs {shape_mcd}\")\n",
    "\n",
    "        area_dict = compute_area_per_ecoregion(\n",
    "            annual_mask, ecos_mcd, transform_mcd, pixel_area_mcd, ECO_ID_COL\n",
    "        )\n",
    "\n",
    "        for eco_id, area_Mha in area_dict.items():\n",
    "            update_results(eco_id, year, \"ba_mcd_native_Mha\", area_Mha)\n",
    "\n",
    "    # --- 2) Native FireCCI ---\n",
    "    print(\"\\n[2/3] Processing native FireCCI...\")\n",
    "    for year in YEARS_FIRECCI:\n",
    "        print(f\"  Year {year} (native FireCCI)\")\n",
    "        annual_mask = build_annual_native_mask(year, MONTHS, NATIVE_FIRECCI_DIR, \"cems_e5l_firecci\")\n",
    "        if annual_mask is None:\n",
    "            print(f\"    -> No native FireCCI data found for {year}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if annual_mask.shape != shape_firecci:\n",
    "            raise ValueError(f\"Shape mismatch for native FireCCI {year}: {annual_mask.shape} vs {shape_firecci}\")\n",
    "\n",
    "        area_dict = compute_area_per_ecoregion(\n",
    "            annual_mask, ecos_firecci, transform_firecci, pixel_area_firecci, ECO_ID_COL\n",
    "        )\n",
    "\n",
    "        for eco_id, area_Mha in area_dict.items():\n",
    "            update_results(eco_id, year, \"ba_firecci_native_Mha\", area_Mha)\n",
    "\n",
    "    # --- 3) Predictions (MCD model) ---\n",
    "    print(\"\\n[3/3] Processing predictions (MCD model)...\")\n",
    "    tmpl_mcd_pred = find_template_path_pred(PRED_MCD_CLASS_DIR, YEARS_MCD, MONTHS)\n",
    "    # Ensure the predicted grid matches native MCD grid\n",
    "    with rio.open(tmpl_mcd_pred) as ds_pred, rio.open(tmpl_mcd_native) as ds_nat:\n",
    "        if (ds_pred.transform != ds_nat.transform) or (ds_pred.width != ds_nat.width) or (ds_pred.height != ds_nat.height):\n",
    "            raise ValueError(\"Predicted MCD grid does not match native MCD grid.\")\n",
    "\n",
    "    for year in YEARS_MCD:\n",
    "        print(f\"  Year {year} (predictions / MCD model)\")\n",
    "        annual_mask = build_annual_pred_mask(year, MONTHS, PRED_MCD_CLASS_DIR)\n",
    "        if annual_mask is None:\n",
    "            print(f\"    -> No predictions found for {year}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if annual_mask.shape != shape_mcd:\n",
    "            raise ValueError(f\"Shape mismatch for predictions {year}: {annual_mask.shape} vs {shape_mcd}\")\n",
    "\n",
    "        area_dict = compute_area_per_ecoregion(\n",
    "            annual_mask, ecos_mcd, transform_mcd, pixel_area_mcd, ECO_ID_COL\n",
    "        )\n",
    "\n",
    "        for eco_id, area_Mha in area_dict.items():\n",
    "            update_results(eco_id, year, \"ba_pred_Mha\", area_Mha)\n",
    "\n",
    "    # ------------- Build DataFrame & save -------------\n",
    "    print(\"\\nBuilding DataFrame and saving CSV...\")\n",
    "    df = pd.DataFrame(list(results.values()))\n",
    "    df = df.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    print(f\"Saved per-ecoregion annual burned area to:\\n  {OUT_CSV}\")\n",
    "\n",
    "    # ------------- Multipanel plot: per-ecoregion comparisons -------------\n",
    "    print(\"Creating multipanel plot (one panel per ecoregion)...\")\n",
    "\n",
    "    cols_area = [\n",
    "        \"ba_mcd_native_Mha\",\n",
    "        \"ba_firecci_native_Mha\",\n",
    "        \"ba_pred_Mha\",\n",
    "    ]\n",
    "    labels = {\n",
    "        \"ba_mcd_native_Mha\": \"MCD native\",\n",
    "        \"ba_firecci_native_Mha\": \"FireCCI native\",\n",
    "        \"ba_pred_Mha\": \"Predictions\",\n",
    "    }\n",
    "\n",
    "    # Unique ecoregions\n",
    "    ecos_list = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    n_ecos = len(ecos_list)\n",
    "    if n_ecos == 0:\n",
    "        print(\"No ecoregions found in results; skipping multipanel plot.\")\n",
    "        return\n",
    "\n",
    "    # Global y-limit for comparability\n",
    "    global_max = 0.0\n",
    "    for col in cols_area:\n",
    "        if col in df.columns:\n",
    "            col_max = df[col].max(skipna=True)\n",
    "            if col_max > global_max:\n",
    "                global_max = col_max\n",
    "    if global_max <= 0:\n",
    "        global_max = 1.0\n",
    "\n",
    "    # Layout: up to 4 columns\n",
    "    ncols = 4 if n_ecos > 4 else n_ecos\n",
    "    nrows = int(np.ceil(n_ecos / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(4 * ncols, 3 * nrows),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "    # Normalize axes to 2D array\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif nrows == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif ncols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Plot per ecoregion\n",
    "    for i, eco_id in enumerate(ecos_list):\n",
    "        row = i // ncols\n",
    "        col = i % ncols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        df_eco = df[df[ECO_ID_COL] == eco_id]\n",
    "\n",
    "        for col_name in cols_area:\n",
    "            if col_name in df_eco.columns and df_eco[col_name].notna().any():\n",
    "                ax.plot(\n",
    "                    df_eco[\"year\"],\n",
    "                    df_eco[col_name],\n",
    "                    marker=\"o\",\n",
    "                    label=labels[col_name],\n",
    "                )\n",
    "\n",
    "        ax.set_title(str(eco_id))\n",
    "        ax.grid(True, ls=\"--\", alpha=0.4)\n",
    "        ax.set_ylim(0, global_max * 1.05)\n",
    "\n",
    "        if row == nrows - 1:\n",
    "            ax.set_xlabel(\"Year\")\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Burned area (Mha)\")\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    total_plots = nrows * ncols\n",
    "    if total_plots > n_ecos:\n",
    "        for j in range(n_ecos, total_plots):\n",
    "            row = j // ncols\n",
    "            col = j % ncols\n",
    "            axes[row, col].axis(\"off\")\n",
    "\n",
    "    # Global legend (from first axis that has lines)\n",
    "    handles, legend_labels = [], []\n",
    "    for ax in axes.flat:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        if h:\n",
    "            handles, legend_labels = h, l\n",
    "            break\n",
    "    if handles:\n",
    "        fig.legend(\n",
    "            handles,\n",
    "            legend_labels,\n",
    "            loc=\"upper center\",\n",
    "            ncol=len(handles),\n",
    "            bbox_to_anchor=(0.5, 1.02),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(OUT_PNG_MULTIPANEL, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved multipanel per-ecoregion plot to:\\n  {OUT_PNG_MULTIPANEL}\")\n",
    "\n",
    "    print(\"\\n✅ Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31963df8-b33b-4388-a7e9-f0df18158d3b",
   "metadata": {},
   "source": [
    "Now get burned arera with different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b729e2-fa67-4c9e-9848-cbfd8701d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecoregions...\n",
      "Reading existing burned area CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions.csv\n",
      "Preparing template and reprojecting ecoregions (MCD grid)...\n",
      "Checking that new prediction grid matches native MCD grid...\n",
      "\n",
      "[1/1] Processing NEW predictions (NEG=50%, w=2)...\n",
      "  Year 2001 (new predictions)\n",
      "  Year 2002 (new predictions)\n",
      "  Year 2003 (new predictions)\n",
      "  Year 2004 (new predictions)\n",
      "  Year 2005 (new predictions)\n",
      "  Year 2006 (new predictions)\n",
      "  Year 2007 (new predictions)\n",
      "  Year 2008 (new predictions)\n",
      "  Year 2009 (new predictions)\n",
      "  Year 2010 (new predictions)\n",
      "  Year 2011 (new predictions)\n",
      "  Year 2012 (new predictions)\n",
      "  Year 2013 (new predictions)\n",
      "  Year 2014 (new predictions)\n",
      "  Year 2015 (new predictions)\n",
      "  Year 2016 (new predictions)\n",
      "  Year 2017 (new predictions)\n",
      "  Year 2018 (new predictions)\n",
      "  Year 2019 (new predictions)\n",
      "  Year 2020 (new predictions)\n",
      "  Year 2021 (new predictions)\n",
      "  Year 2022 (new predictions)\n",
      "  Year 2023 (new predictions)\n",
      "\n",
      "Building DataFrame of new prediction areas...\n",
      "Merging new prediction areas into existing CSV...\n",
      "\n",
      "✅ Saved updated CSV with new prediction column 'ba_pred_Mha_neg50_w2' to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_neg50_w2.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Compute annual burned area (Mha) per ecoregion for NEW predictions\n",
    "(NEG=50%, w=2) and merge into existing CSV that already has:\n",
    "\n",
    "  - ba_mcd_native_Mha\n",
    "  - ba_firecci_native_Mha\n",
    "  - ba_pred_Mha   (old predictions)\n",
    "\n",
    "New column added:\n",
    "  - ba_pred_Mha_neg50_w2\n",
    "\n",
    "Steps:\n",
    "  - For each year (2001–2023), stack 12 monthly predicted class rasters\n",
    "    from predictions_option2_neg050pct_w2_mcd/class, take max across months\n",
    "    -> annual 0/1 mask (1=burned at least once in the year).\n",
    "  - For each ecoregion polygon:\n",
    "      * rasterize polygon\n",
    "      * count burned pixels\n",
    "      * multiply by pixel area (m²) and convert to Mha.\n",
    "  - Merge results into existing CSV and save a new CSV.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "# Years for MCD / predictions\n",
    "YEARS_MCD = list(range(2001, 2024))\n",
    "MONTHS    = list(range(1, 13))\n",
    "\n",
    "# --- Native MCD monthly fraction rasters (for template / pixel area only) ---\n",
    "NATIVE_MCD_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# --- NEW predicted class rasters (NEG=50%, w=2) ---\n",
    "NEW_PRED_MCD_DIR       = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg050pct_w2_mcd\"\n",
    ")\n",
    "NEW_PRED_MCD_CLASS_DIR = NEW_PRED_MCD_DIR / \"class\"\n",
    "\n",
    "# Glob pattern for predicted class TIFFs:\n",
    "#   cems_pred_class_YYYY_MM_thr{thr}.tif\n",
    "PRED_CLASS_PATTERN = \"cems_pred_class_{year}_{month:02d}_thr*.tif\"\n",
    "\n",
    "# --- Ecoregion shapefile ---\n",
    "ECOS_PATH = \"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\"\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "# --- Existing + new CSV paths ---\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_CSV_OLD  = OUT_DIR / \"burned_area_by_ecoregion_predictions.csv\"\n",
    "OUT_CSV_NEW = OUT_DIR / \"burned_area_by_ecoregion_predictions_neg50_w2.csv\"\n",
    "\n",
    "# Name of new column\n",
    "NEW_COL_NAME = \"ba_pred_Mha_neg50_w2\"\n",
    "\n",
    "\n",
    "# ============================\n",
    "# HELPERS\n",
    "# ============================\n",
    "\n",
    "def find_native_monthly_path(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Try a few reasonable filename variants for the native monthly *_with_fraction.tif.\n",
    "    prefix is 'cems_e5l_mcd'.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        base_dir / f\"{prefix}_{year}_{month}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month}.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}.tif\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_template_path_native(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    years,\n",
    "    months\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find one existing native monthly file to use as template (for CRS, transform, shape).\n",
    "    \"\"\"\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            p = find_native_monthly_path(base_dir, prefix, y, m)\n",
    "            if p is not None:\n",
    "                return p\n",
    "    raise FileNotFoundError(f\"No native files found for prefix {prefix} in {base_dir}\")\n",
    "\n",
    "\n",
    "def find_pred_class_month_path(\n",
    "    pred_class_dir: Path,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find NEW predicted class raster for given year/month.\n",
    "    Expects filenames like cems_pred_class_YYYY_MM_thr*.tif\n",
    "    \"\"\"\n",
    "    matches = list(pred_class_dir.glob(PRED_CLASS_PATTERN.format(year=year, month=month)))\n",
    "    if matches:\n",
    "        # If multiple thresholds exist, just use the first one\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_annual_pred_mask(\n",
    "    year: int,\n",
    "    months,\n",
    "    pred_class_dir: Path\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build annual 0/1 burned mask from predicted monthly class rasters for given year.\n",
    "    Assumes class TIFF has 1=burned, 0=unburned, 255=nodata.\n",
    "    Returns uint8 array with shape (H, W) or None if no months are found.\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "\n",
    "    for m in months:\n",
    "        src_path = find_pred_class_month_path(pred_class_dir, year, m)\n",
    "        if src_path is None:\n",
    "            continue\n",
    "\n",
    "        with rio.open(src_path) as ds:\n",
    "            arr = ds.read(1)\n",
    "            monthly_burn = (arr == 1).astype(np.uint8)\n",
    "\n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "            else:\n",
    "                annual = np.maximum(annual, monthly_burn)\n",
    "\n",
    "    return annual\n",
    "\n",
    "\n",
    "def prepare_ecos_for_dataset(template_path: Path, ecos: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Open template raster, check CRS, compute pixel area, and reproject ecos to that CRS.\n",
    "    \"\"\"\n",
    "    with rio.open(template_path) as ds:\n",
    "        crs = ds.crs\n",
    "        transform = ds.transform\n",
    "        height, width = ds.height, ds.width\n",
    "\n",
    "        if crs is None:\n",
    "            raise ValueError(f\"Template {template_path} has no CRS\")\n",
    "\n",
    "        if crs.is_geographic:\n",
    "            raise ValueError(\n",
    "                f\"Template CRS {crs} is geographic (degrees). \"\n",
    "                \"Reproject rasters to an equal-area projection (meters) before area calculation.\"\n",
    "            )\n",
    "\n",
    "        pixel_area_m2 = abs(transform.a * transform.e)  # a=width, e=height (negative)\n",
    "        ecos_reproj = ecos.to_crs(crs)\n",
    "\n",
    "    return ecos_reproj, transform, (height, width), pixel_area_m2\n",
    "\n",
    "\n",
    "def compute_area_per_ecoregion(\n",
    "    annual_mask: np.ndarray,\n",
    "    ecos_reproj: gpd.GeoDataFrame,\n",
    "    transform,\n",
    "    pixel_area_m2: float,\n",
    "    id_col: str,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Given an annual 0/1 mask and an ecoregion GeoDataFrame (already in raster CRS),\n",
    "    compute burned area (Mha) for each ecoregion.\n",
    "    Returns dict: {ecoregion_id: burned_area_Mha}\n",
    "    \"\"\"\n",
    "    from rasterio.features import geometry_mask  # local import just in case\n",
    "\n",
    "    height, width = annual_mask.shape\n",
    "    results = {}\n",
    "\n",
    "    for idx, row in ecos_reproj.iterrows():\n",
    "        eco_id = row[id_col]\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            results[eco_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        eco_mask = geometry_mask(\n",
    "            [geom.__geo_interface__],\n",
    "            transform=transform,\n",
    "            invert=True,\n",
    "            out_shape=(height, width),\n",
    "        )\n",
    "\n",
    "        burned_pixels = (annual_mask == 1) & eco_mask\n",
    "        area_m2 = burned_pixels.sum() * pixel_area_m2\n",
    "        area_Mha = area_m2 / 1e10  # m^2 -> Mha\n",
    "\n",
    "        results[eco_id] = area_Mha\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    # ---------- Load ecoregions & old CSV ----------\n",
    "    print(\"Loading ecoregions...\")\n",
    "    ecos = gpd.read_file(ECOS_PATH)\n",
    "    if ECO_ID_COL not in ecos.columns:\n",
    "        raise ValueError(f\"ECO_ID_COL='{ECO_ID_COL}' not found in {ECOS_PATH}. Columns: {list(ecos.columns)}\")\n",
    "\n",
    "    print(f\"Reading existing burned area CSV: {IN_CSV_OLD}\")\n",
    "    df_old = pd.read_csv(IN_CSV_OLD)\n",
    "\n",
    "    # ---------- Prepare template & reproject ecos ----------\n",
    "    print(\"Preparing template and reprojecting ecoregions (MCD grid)...\")\n",
    "    tmpl_mcd_native = find_template_path_native(NATIVE_MCD_DIR, \"cems_e5l_mcd\", YEARS_MCD, MONTHS)\n",
    "    ecos_mcd, transform_mcd, shape_mcd, pixel_area_mcd = prepare_ecos_for_dataset(tmpl_mcd_native, ecos)\n",
    "\n",
    "    # Check that NEW predicted grid matches native MCD grid\n",
    "    print(\"Checking that new prediction grid matches native MCD grid...\")\n",
    "    tmpl_new_pred = None\n",
    "    for y in YEARS_MCD:\n",
    "        for m in MONTHS:\n",
    "            p = find_pred_class_month_path(NEW_PRED_MCD_CLASS_DIR, y, m)\n",
    "            if p is not None:\n",
    "                tmpl_new_pred = p\n",
    "                break\n",
    "        if tmpl_new_pred is not None:\n",
    "            break\n",
    "\n",
    "    if tmpl_new_pred is None:\n",
    "        raise FileNotFoundError(f\"No new prediction class files found in {NEW_PRED_MCD_CLASS_DIR}\")\n",
    "\n",
    "    with rio.open(tmpl_new_pred) as ds_pred, rio.open(tmpl_mcd_native) as ds_nat:\n",
    "        if (ds_pred.transform != ds_nat.transform) or (ds_pred.width != ds_nat.width) or (ds_pred.height != ds_nat.height):\n",
    "            raise ValueError(\"New predicted MCD grid does not match native MCD grid.\")\n",
    "\n",
    "    # ---------- Compute new prediction burned area ----------\n",
    "    print(\"\\n[1/1] Processing NEW predictions (NEG=50%, w=2)...\")\n",
    "    results = {}  # key: (eco_id, year) -> area\n",
    "\n",
    "    for year in YEARS_MCD:\n",
    "        print(f\"  Year {year} (new predictions)\")\n",
    "        annual_mask = build_annual_pred_mask(year, MONTHS, NEW_PRED_MCD_CLASS_DIR)\n",
    "        if annual_mask is None:\n",
    "            print(f\"    -> No new predictions found for {year}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if annual_mask.shape != shape_mcd:\n",
    "            raise ValueError(f\"Shape mismatch for new predictions {year}: {annual_mask.shape} vs {shape_mcd}\")\n",
    "\n",
    "        area_dict = compute_area_per_ecoregion(\n",
    "            annual_mask, ecos_mcd, transform_mcd, pixel_area_mcd, ECO_ID_COL\n",
    "        )\n",
    "\n",
    "        for eco_id, area_Mha in area_dict.items():\n",
    "            results[(eco_id, year)] = area_Mha\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    print(\"\\nBuilding DataFrame of new prediction areas...\")\n",
    "    rows = []\n",
    "    for (eco_id, year), area_Mha in results.items():\n",
    "        rows.append({ECO_ID_COL: eco_id, \"year\": year, NEW_COL_NAME: area_Mha})\n",
    "    df_new = pd.DataFrame(rows)\n",
    "\n",
    "    # ---------- Merge with existing CSV ----------\n",
    "    print(\"Merging new prediction areas into existing CSV...\")\n",
    "    df_merged = df_old.merge(df_new, on=[ECO_ID_COL, \"year\"], how=\"left\")\n",
    "\n",
    "    df_merged = df_merged.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "\n",
    "    df_merged.to_csv(OUT_CSV_NEW, index=False)\n",
    "    print(f\"\\n✅ Saved updated CSV with new prediction column '{NEW_COL_NAME}' to:\\n  {OUT_CSV_NEW}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33413870-c823-4445-833d-8b105411101d",
   "metadata": {},
   "source": [
    "All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e480936-2cfe-4e9b-a8db-f5275460c101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ecoregions...\n",
      "Reading existing burned area CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions.csv\n",
      "Preparing template and reprojecting ecoregions (MCD grid)...\n",
      "\n",
      "Found prediction model class directories:\n",
      "  - predictions_option2_neg010pct_w1_mcd  -> neg=10%, w=1\n",
      "  - predictions_option2_neg010pct_w2_mcd  -> neg=10%, w=2\n",
      "  - predictions_option2_neg010pct_w3_mcd  -> neg=10%, w=3\n",
      "  - predictions_option2_neg010pct_w5_mcd  -> neg=10%, w=5\n",
      "  - predictions_option2_neg020pct_w1_mcd  -> neg=20%, w=1\n",
      "  - predictions_option2_neg020pct_w2_mcd  -> neg=20%, w=2\n",
      "  - predictions_option2_neg020pct_w3_mcd  -> neg=20%, w=3\n",
      "  - predictions_option2_neg020pct_w5_mcd  -> neg=20%, w=5\n",
      "  - predictions_option2_neg030pct_w1_mcd  -> neg=30%, w=1\n",
      "  - predictions_option2_neg030pct_w2_mcd  -> neg=30%, w=2\n",
      "  - predictions_option2_neg030pct_w3_mcd  -> neg=30%, w=3\n",
      "  - predictions_option2_neg030pct_w5_mcd  -> neg=30%, w=5\n",
      "  - predictions_option2_neg040pct_w1_mcd  -> neg=40%, w=1\n",
      "  - predictions_option2_neg040pct_w2_mcd  -> neg=40%, w=2\n",
      "  - predictions_option2_neg040pct_w3_mcd  -> neg=40%, w=3\n",
      "  - predictions_option2_neg040pct_w5_mcd  -> neg=40%, w=5\n",
      "  - predictions_option2_neg050pct_w1_mcd  -> neg=50%, w=1\n",
      "  - predictions_option2_neg050pct_w2_mcd  -> neg=50%, w=2\n",
      "  - predictions_option2_neg050pct_w3_mcd  -> neg=50%, w=3\n",
      "  - predictions_option2_neg050pct_w5_mcd  -> neg=50%, w=5\n",
      "  - predictions_option2_neg060pct_w1_mcd  -> neg=60%, w=1\n",
      "  - predictions_option2_neg060pct_w2_mcd  -> neg=60%, w=2\n",
      "  - predictions_option2_neg060pct_w3_mcd  -> neg=60%, w=3\n",
      "  - predictions_option2_neg060pct_w5_mcd  -> neg=60%, w=5\n",
      "  - predictions_option2_neg070pct_w1_mcd  -> neg=70%, w=1\n",
      "  - predictions_option2_neg070pct_w2_mcd  -> neg=70%, w=2\n",
      "  - predictions_option2_neg070pct_w3_mcd  -> neg=70%, w=3\n",
      "  - predictions_option2_neg070pct_w5_mcd  -> neg=70%, w=5\n",
      "  - predictions_option2_neg080pct_w1_mcd  -> neg=80%, w=1\n",
      "  - predictions_option2_neg080pct_w2_mcd  -> neg=80%, w=2\n",
      "  - predictions_option2_neg080pct_w3_mcd  -> neg=80%, w=3\n",
      "  - predictions_option2_neg080pct_w5_mcd  -> neg=80%, w=5\n",
      "  - predictions_option2_neg090pct_w1_mcd  -> neg=90%, w=1\n",
      "  - predictions_option2_neg090pct_w2_mcd  -> neg=90%, w=2\n",
      "  - predictions_option2_neg090pct_w3_mcd  -> neg=90%, w=3\n",
      "  - predictions_option2_neg090pct_w5_mcd  -> neg=90%, w=5\n",
      "  - predictions_option2_neg100pct_w1_mcd  -> neg=100%, w=1\n",
      "  - predictions_option2_neg100pct_w2_mcd  -> neg=100%, w=2\n",
      "  - predictions_option2_neg100pct_w3_mcd  -> neg=100%, w=3\n",
      "  - predictions_option2_neg100pct_w5_mcd  -> neg=100%, w=5\n",
      "\n",
      "Checking that prediction grids match native MCD grid (using the first model)...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=10%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg010pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg10_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg10_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=10%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg010pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg10_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg10_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=10%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg010pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg10_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg10_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=10%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg010pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg10_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg10_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=20%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg020pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg20_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg20_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=20%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg020pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg20_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg20_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=20%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg020pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg20_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg20_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=20%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg020pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg20_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg20_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=30%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg030pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg30_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg30_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=30%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg030pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg30_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg30_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=30%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg030pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg30_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg30_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=30%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg030pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg30_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg30_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=40%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg040pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg40_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg40_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=40%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg040pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg40_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg40_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=40%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg040pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg40_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg40_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=40%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg040pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg40_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg40_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=50%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg050pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg50_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg50_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=50%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg050pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg50_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg50_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=50%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg050pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg50_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg50_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=50%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg050pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg50_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg50_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=60%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg060pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg60_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg60_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=60%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg060pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg60_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg60_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=60%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg060pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg60_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg60_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=60%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg060pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg60_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg60_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=70%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg070pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg70_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg70_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=70%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg070pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg70_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg70_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=70%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg070pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg70_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg70_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=70%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg070pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg70_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg70_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=80%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg080pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg80_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg80_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=80%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg080pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg80_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg80_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=80%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg080pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg80_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg80_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=80%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg080pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg80_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg80_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=90%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg090pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg90_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg90_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=90%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg090pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg90_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg90_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=90%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg090pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg90_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg90_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=90%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg090pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg90_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg90_w5'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=100%, w=1\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg100pct_w1_mcd/class\n",
      "New column name:   ba_pred_Mha_neg100_w1\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg100_w1'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=100%, w=2\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg100pct_w2_mcd/class\n",
      "New column name:   ba_pred_Mha_neg100_w2\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg100_w2'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=100%, w=3\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg100pct_w3_mcd/class\n",
      "New column name:   ba_pred_Mha_neg100_w3\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg100_w3'...\n",
      "\n",
      "================================================================================\n",
      "Processing model: neg=100%, w=5\n",
      "Class rasters dir: /explore/nobackup/people/spotter5/clelland_fire_ml/predictions_option2_neg100pct_w5_mcd/class\n",
      "New column name:   ba_pred_Mha_neg100_w5\n",
      "  Year 2001...\n",
      "  Year 2002...\n",
      "  Year 2003...\n",
      "  Year 2004...\n",
      "  Year 2005...\n",
      "  Year 2006...\n",
      "  Year 2007...\n",
      "  Year 2008...\n",
      "  Year 2009...\n",
      "  Year 2010...\n",
      "  Year 2011...\n",
      "  Year 2012...\n",
      "  Year 2013...\n",
      "  Year 2014...\n",
      "  Year 2015...\n",
      "  Year 2016...\n",
      "  Year 2017...\n",
      "  Year 2018...\n",
      "  Year 2019...\n",
      "  Year 2020...\n",
      "  Year 2021...\n",
      "  Year 2022...\n",
      "  Year 2023...\n",
      "  Merging 621 rows into main CSV for column 'ba_pred_Mha_neg100_w5'...\n",
      "\n",
      "✅ Saved updated CSV with all model prediction columns to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_all_models.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Compute annual burned area (Mha) per ecoregion for ALL Option 2 models\n",
    "and merge into existing CSV that already has:\n",
    "\n",
    "  - ba_mcd_native_Mha\n",
    "  - ba_firecci_native_Mha\n",
    "  - ba_pred_Mha   (original predictions)\n",
    "  - optionally ba_pred_Mha_neg50_w2, etc.\n",
    "\n",
    "For each prediction directory:\n",
    "\n",
    "  /explore/nobackup/people/spotter5/clelland_fire_ml/\n",
    "      predictions_option2_neg{pct:03d}pct_w{w_tag}_mcd/class/\n",
    "\n",
    "we:\n",
    "\n",
    "  - For each year (2001–2023), stack 12 monthly predicted class rasters\n",
    "    (cems_pred_class_YYYY_MM_thr*.tif), take max across months\n",
    "    -> annual 0/1 mask (1=burned at least once in the year).\n",
    "  - For each ecoregion polygon:\n",
    "      * rasterize polygon\n",
    "      * count burned pixels\n",
    "      * multiply by pixel area (m²) and convert to Mha.\n",
    "  - Add a column:\n",
    "\n",
    "      ba_pred_Mha_neg{pct}_w{w_tag}\n",
    "\n",
    "    e.g. ba_pred_Mha_neg50_w2\n",
    "\n",
    "and merge into the existing CSV.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "# Years for MCD / predictions\n",
    "YEARS_MCD = list(range(2001, 2024))\n",
    "MONTHS    = list(range(1, 13))\n",
    "\n",
    "# --- Native MCD monthly fraction rasters (for template / pixel area only) ---\n",
    "NATIVE_MCD_DIR = Path(\n",
    "    \"/explore/nobackup/people/spotter5/clelland_fire_ml/training_e5l_cems_mcd_with_fraction\"\n",
    ")\n",
    "\n",
    "# Root where prediction dirs live (must match prediction script)\n",
    "PRED_ROOT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml\")\n",
    "\n",
    "# Pattern of prediction dirs created by the all-models script\n",
    "# e.g. predictions_option2_neg050pct_w2_mcd\n",
    "PRED_DIR_PATTERN = \"predictions_option2_neg*pct_w*_mcd\"\n",
    "\n",
    "# Glob pattern for predicted class TIFFs:\n",
    "#   cems_pred_class_YYYY_MM_thr{thr}.tif\n",
    "PRED_CLASS_PATTERN = \"cems_pred_class_{year}_{month:02d}_thr*.tif\"\n",
    "\n",
    "# --- Ecoregion shapefile ---\n",
    "ECOS_PATH = \"/explore/nobackup/people/spotter5/helene/raw/merge_eco_v2.shp\"\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "# --- Existing + new CSV paths ---\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_CSV_OLD  = OUT_DIR / \"burned_area_by_ecoregion_predictions.csv\"\n",
    "OUT_CSV_NEW = OUT_DIR / \"burned_area_by_ecoregion_predictions_all_models.csv\"\n",
    "\n",
    "\n",
    "# ============================\n",
    "# HELPERS\n",
    "# ============================\n",
    "\n",
    "def find_native_monthly_path(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Try a few reasonable filename variants for the native monthly *_with_fraction.tif.\n",
    "    prefix is 'cems_e5l_mcd'.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        base_dir / f\"{prefix}_{year}_{month}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}_with_fraction.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month}.tif\",\n",
    "        base_dir / f\"{prefix}_{year}_{month:02d}.tif\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_template_path_native(\n",
    "    base_dir: Path,\n",
    "    prefix: str,\n",
    "    years,\n",
    "    months\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find one existing native monthly file to use as template (for CRS, transform, shape).\n",
    "    \"\"\"\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            p = find_native_monthly_path(base_dir, prefix, y, m)\n",
    "            if p is not None:\n",
    "                return p\n",
    "    raise FileNotFoundError(f\"No native files found for prefix {prefix} in {base_dir}\")\n",
    "\n",
    "\n",
    "def find_pred_class_month_path(\n",
    "    pred_class_dir: Path,\n",
    "    year: int,\n",
    "    month: int\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find predicted class raster for given year/month in a given model dir.\n",
    "    Expects filenames like cems_pred_class_YYYY_MM_thr*.tif\n",
    "    \"\"\"\n",
    "    matches = list(pred_class_dir.glob(PRED_CLASS_PATTERN.format(year=year, month=month)))\n",
    "    if matches:\n",
    "        # If multiple thresholds exist, just use the first one\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_annual_pred_mask(\n",
    "    year: int,\n",
    "    months,\n",
    "    pred_class_dir: Path\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build annual 0/1 burned mask from predicted monthly class rasters for given year.\n",
    "    Assumes class TIFF has 1=burned, 0=unburned, 255=nodata.\n",
    "    Returns uint8 array with shape (H, W) or None if no months are found.\n",
    "    \"\"\"\n",
    "    annual = None\n",
    "\n",
    "    for m in months:\n",
    "        src_path = find_pred_class_month_path(pred_class_dir, year, m)\n",
    "        if src_path is None:\n",
    "            continue\n",
    "\n",
    "        with rio.open(src_path) as ds:\n",
    "            arr = ds.read(1)\n",
    "            monthly_burn = (arr == 1).astype(np.uint8)\n",
    "\n",
    "            if annual is None:\n",
    "                annual = monthly_burn\n",
    "            else:\n",
    "                annual = np.maximum(annual, monthly_burn)\n",
    "\n",
    "    return annual\n",
    "\n",
    "\n",
    "def prepare_ecos_for_dataset(template_path: Path, ecos: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Open template raster, check CRS, compute pixel area, and reproject ecos to that CRS.\n",
    "    \"\"\"\n",
    "    with rio.open(template_path) as ds:\n",
    "        crs = ds.crs\n",
    "        transform = ds.transform\n",
    "        height, width = ds.height, ds.width\n",
    "\n",
    "        if crs is None:\n",
    "            raise ValueError(f\"Template {template_path} has no CRS\")\n",
    "\n",
    "        if crs.is_geographic:\n",
    "            raise ValueError(\n",
    "                f\"Template CRS {crs} is geographic (degrees). \"\n",
    "                \"Reproject rasters to an equal-area projection (meters) before area calculation.\"\n",
    "            )\n",
    "\n",
    "        pixel_area_m2 = abs(transform.a * transform.e)  # a=width, e=height (negative)\n",
    "        ecos_reproj = ecos.to_crs(crs)\n",
    "\n",
    "    return ecos_reproj, transform, (height, width), pixel_area_m2\n",
    "\n",
    "\n",
    "def compute_area_per_ecoregion(\n",
    "    annual_mask: np.ndarray,\n",
    "    ecos_reproj: gpd.GeoDataFrame,\n",
    "    transform,\n",
    "    pixel_area_m2: float,\n",
    "    id_col: str,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Given an annual 0/1 mask and an ecoregion GeoDataFrame (already in raster CRS),\n",
    "    compute burned area (Mha) for each ecoregion.\n",
    "    Returns dict: {ecoregion_id: burned_area_Mha}\n",
    "    \"\"\"\n",
    "    height, width = annual_mask.shape\n",
    "    results = {}\n",
    "\n",
    "    for idx, row in ecos_reproj.iterrows():\n",
    "        eco_id = row[id_col]\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            results[eco_id] = 0.0\n",
    "            continue\n",
    "\n",
    "        eco_mask = geometry_mask(\n",
    "            [geom.__geo_interface__],\n",
    "            transform=transform,\n",
    "            invert=True,\n",
    "            out_shape=(height, width),\n",
    "        )\n",
    "\n",
    "        burned_pixels = (annual_mask == 1) & eco_mask\n",
    "        area_m2 = burned_pixels.sum() * pixel_area_m2\n",
    "        area_Mha = area_m2 / 1e10  # m^2 -> Mha\n",
    "\n",
    "        results[eco_id] = area_Mha\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_model_tag_from_dir(dirname: str) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Parse neg_percent and w_tag from a prediction directory name, e.g.:\n",
    "\n",
    "      predictions_option2_neg050pct_w2_mcd\n",
    "\n",
    "    Returns (neg_percent_int, w_tag_int) or None if it doesn't match.\n",
    "    \"\"\"\n",
    "    # Accept both 2 or 3 digits for percent; directory always has 3 but we drop leading zeros.\n",
    "    m = re.search(r\"neg(\\d{2,3})pct_w(\\d+)_mcd\", dirname)\n",
    "    if not m:\n",
    "        return None\n",
    "    neg_percent = int(m.group(1))  # 050 -> 50\n",
    "    w_tag = int(m.group(2))\n",
    "    return neg_percent, w_tag\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    # ---------- Load ecoregions & old CSV ----------\n",
    "    print(\"Loading ecoregions...\")\n",
    "    ecos = gpd.read_file(ECOS_PATH)\n",
    "    if ECO_ID_COL not in ecos.columns:\n",
    "        raise ValueError(f\"ECO_ID_COL='{ECO_ID_COL}' not found in {ECOS_PATH}. Columns: {list(ecos.columns)}\")\n",
    "\n",
    "    print(f\"Reading existing burned area CSV: {IN_CSV_OLD}\")\n",
    "    df_old = pd.read_csv(IN_CSV_OLD)\n",
    "\n",
    "    # ---------- Prepare template & reproject ecos ----------\n",
    "    print(\"Preparing template and reprojecting ecoregions (MCD grid)...\")\n",
    "    tmpl_mcd_native = find_template_path_native(NATIVE_MCD_DIR, \"cems_e5l_mcd\", YEARS_MCD, MONTHS)\n",
    "    ecos_mcd, transform_mcd, shape_mcd, pixel_area_mcd = prepare_ecos_for_dataset(tmpl_mcd_native, ecos)\n",
    "\n",
    "    # ---------- Find all prediction model 'class' directories ----------\n",
    "    pred_class_dirs = sorted(PRED_ROOT_DIR.glob(f\"{PRED_DIR_PATTERN}/class\"))\n",
    "    if not pred_class_dirs:\n",
    "        raise FileNotFoundError(f\"No prediction class directories matching '{PRED_DIR_PATTERN}' under {PRED_ROOT_DIR}\")\n",
    "\n",
    "    print(\"\\nFound prediction model class directories:\")\n",
    "    model_info = []  # list of (neg_percent, w_tag, class_dir)\n",
    "    for class_dir in pred_class_dirs:\n",
    "        neg_w = parse_model_tag_from_dir(class_dir.parent.name)\n",
    "        if neg_w is None:\n",
    "            print(f\"  [SKIP] Could not parse neg/w from: {class_dir.parent.name}\")\n",
    "            continue\n",
    "        neg_percent, w_tag = neg_w\n",
    "        print(f\"  - {class_dir.parent.name}  -> neg={neg_percent}%, w={w_tag}\")\n",
    "        model_info.append((neg_percent, w_tag, class_dir))\n",
    "\n",
    "    if not model_info:\n",
    "        raise RuntimeError(\"No valid model prediction directories parsed from names.\")\n",
    "\n",
    "    # ---------- Check that prediction grids match native MCD grid ----------\n",
    "    print(\"\\nChecking that prediction grids match native MCD grid (using the first model)...\")\n",
    "    first_class_dir = model_info[0][2]\n",
    "    tmpl_new_pred = None\n",
    "    for y in YEARS_MCD:\n",
    "        for m in MONTHS:\n",
    "            p = find_pred_class_month_path(first_class_dir, y, m)\n",
    "            if p is not None:\n",
    "                tmpl_new_pred = p\n",
    "                break\n",
    "        if tmpl_new_pred is not None:\n",
    "            break\n",
    "\n",
    "    if tmpl_new_pred is None:\n",
    "        raise FileNotFoundError(f\"No prediction class files found in {first_class_dir}\")\n",
    "\n",
    "    with rio.open(tmpl_new_pred) as ds_pred, rio.open(tmpl_mcd_native) as ds_nat:\n",
    "        if (ds_pred.transform != ds_nat.transform) or (ds_pred.width != ds_nat.width) or (ds_pred.height != ds_nat.height):\n",
    "            raise ValueError(\"Predicted MCD grid does not match native MCD grid.\")\n",
    "\n",
    "    # ---------- Start from the existing CSV and add columns per model ----------\n",
    "    df_merged = df_old.copy()\n",
    "\n",
    "    # ---------- For each model, compute burned area and merge ----------\n",
    "    for neg_percent, w_tag, class_dir in model_info:\n",
    "        col_name = f\"ba_pred_Mha_neg{neg_percent}_w{w_tag}\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Processing model: neg={neg_percent}%, w={w_tag}\")\n",
    "        print(f\"Class rasters dir: {class_dir}\")\n",
    "        print(f\"New column name:   {col_name}\")\n",
    "\n",
    "        results = {}  # key: (eco_id, year) -> area\n",
    "\n",
    "        for year in YEARS_MCD:\n",
    "            print(f\"  Year {year}...\")\n",
    "            annual_mask = build_annual_pred_mask(year, MONTHS, class_dir)\n",
    "            if annual_mask is None:\n",
    "                print(f\"    -> No predictions found for {year} in {class_dir}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            if annual_mask.shape != shape_mcd:\n",
    "                raise ValueError(\n",
    "                    f\"Shape mismatch for predictions {year} in {class_dir}: \"\n",
    "                    f\"{annual_mask.shape} vs {shape_mcd}\"\n",
    "                )\n",
    "\n",
    "            area_dict = compute_area_per_ecoregion(\n",
    "                annual_mask, ecos_mcd, transform_mcd, pixel_area_mcd, ECO_ID_COL\n",
    "            )\n",
    "\n",
    "            for eco_id, area_Mha in area_dict.items():\n",
    "                results[(eco_id, year)] = area_Mha\n",
    "\n",
    "        if not results:\n",
    "            print(f\"  -> No valid annual masks computed for model neg{neg_percent}_w{w_tag}; skipping merge.\")\n",
    "            continue\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        rows = []\n",
    "        for (eco_id, year), area_Mha in results.items():\n",
    "            rows.append({ECO_ID_COL: eco_id, \"year\": year, col_name: area_Mha})\n",
    "        df_new = pd.DataFrame(rows)\n",
    "\n",
    "        print(f\"  Merging {len(df_new)} rows into main CSV for column '{col_name}'...\")\n",
    "        df_merged = df_merged.merge(df_new, on=[ECO_ID_COL, \"year\"], how=\"left\")\n",
    "\n",
    "    # ---------- Final save ----------\n",
    "    df_merged = df_merged.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "    df_merged.to_csv(OUT_CSV_NEW, index=False)\n",
    "\n",
    "    print(\"\\n✅ Saved updated CSV with all model prediction columns to:\")\n",
    "    print(f\"  {OUT_CSV_NEW}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20461744-9718-416e-8eae-b4e6105bd097",
   "metadata": {},
   "source": [
    "Just plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81915e65-c761-4bd3-bf39-6606db4f789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Read precomputed burned area CSV and create a multipanel plot:\n",
    "\n",
    "  - Input: burned_area_by_ecoregion_predictions.csv\n",
    "      columns:\n",
    "        - ecoregion (ECO_ID_COL)\n",
    "        - year\n",
    "        - ba_mcd_native_Mha\n",
    "        - ba_firecci_native_Mha\n",
    "        - ba_pred_Mha\n",
    "\n",
    "  - Output:\n",
    "      burned_area_multipanel_by_ecoregion_floating_y.png\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "IN_CSV  = OUT_DIR / \"burned_area_by_ecoregion_predictions.csv\"\n",
    "OUT_PNG = OUT_DIR / \"burned_area_multipanel_by_ecoregion_floating_y.png\"\n",
    "\n",
    "# columns to plot + nicer labels\n",
    "COLS_AREA = [\n",
    "    \"ba_mcd_native_Mha\",\n",
    "    \"ba_firecci_native_Mha\",\n",
    "    \"ba_pred_Mha\",\n",
    "]\n",
    "\n",
    "LABELS = {\n",
    "    \"ba_mcd_native_Mha\": \"MCD64A1\",\n",
    "    \"ba_firecci_native_Mha\": \"Fire CCI\",\n",
    "    \"ba_pred_Mha\": \"Predictions\",\n",
    "}\n",
    "\n",
    "# Ecoregions to exclude from plotting\n",
    "EXCLUDE_ECOS = {\n",
    "    \"WATER\",\n",
    "    \"MIXED WOOD SHIELD\",\n",
    "    \"TEMPERATE PRAIRIES\",\n",
    "    \"WESTERN CORDILLERA\",\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(f\"Reading CSV: {IN_CSV}\")\n",
    "    df = pd.read_csv(IN_CSV)\n",
    "\n",
    "    # Basic sanity\n",
    "    missing_cols = [c for c in [ECO_ID_COL, \"year\"] + COLS_AREA if c not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing expected columns in CSV: {missing_cols}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "\n",
    "    # Unique ecoregions excluding the undesired ones\n",
    "    ecos_all = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    ecos_list = [e for e in ecos_all if e not in EXCLUDE_ECOS]\n",
    "\n",
    "    if not ecos_list:\n",
    "        print(\"No ecoregions left after exclusion; nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    n_ecos = len(ecos_list)\n",
    "    print(f\"Found {n_ecos} ecoregions after exclusion: {ecos_list}\")\n",
    "\n",
    "    # Layout: up to 4 columns\n",
    "    ncols = 4 if n_ecos > 4 else n_ecos\n",
    "    nrows = int(np.ceil(n_ecos / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(4 * ncols, 3 * nrows),\n",
    "        sharex=True,\n",
    "        sharey=False,  # floating y-axis\n",
    "    )\n",
    "\n",
    "    # Normalize axes to 2D array\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif nrows == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif ncols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    handles_for_legend, labels_for_legend = None, None\n",
    "\n",
    "    # Plot per ecoregion\n",
    "    for i, eco_id in enumerate(ecos_list):\n",
    "        row = i // ncols\n",
    "        col = i % ncols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        df_eco = df[df[ECO_ID_COL] == eco_id]\n",
    "\n",
    "        # plot all datasets\n",
    "        for col_name in COLS_AREA:\n",
    "            if col_name in df_eco.columns and df_eco[col_name].notna().any():\n",
    "                ax.plot(\n",
    "                    df_eco[\"year\"],\n",
    "                    df_eco[col_name],\n",
    "                    marker=\"o\",\n",
    "                    label=LABELS[col_name],\n",
    "                )\n",
    "\n",
    "        # capture legend handles after all 3 plotted\n",
    "        if handles_for_legend is None:\n",
    "            h, l = ax.get_legend_handles_labels()\n",
    "            if h:\n",
    "                handles_for_legend, labels_for_legend = h, l\n",
    "\n",
    "        ax.set_title(str(eco_id))\n",
    "        ax.grid(True, ls=\"--\", alpha=0.4)\n",
    "\n",
    "        # floating y-axis logic\n",
    "        ydata_list = [df_eco[c].dropna().values for c in COLS_AREA if c in df_eco.columns]\n",
    "        if ydata_list:\n",
    "            ydata = np.concatenate(ydata_list)\n",
    "            if ydata.size == 0 or np.nanmax(ydata) == 0:\n",
    "                ax.set_ylim(0, 1.0)\n",
    "        else:\n",
    "            ax.set_ylim(0, 1.0)\n",
    "\n",
    "        if row == nrows - 1:\n",
    "            ax.set_xlabel(\"Year\")\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Burned area (Mha)\")\n",
    "\n",
    "    # Hide unused panels\n",
    "    total_plots = nrows * ncols\n",
    "    if total_plots > n_ecos:\n",
    "        for j in range(n_ecos, total_plots):\n",
    "            row = j // ncols\n",
    "            col = j % ncols\n",
    "            axes[row, col].axis(\"off\")\n",
    "\n",
    "    # Global legend at bottom with all three dataset names\n",
    "    if handles_for_legend:\n",
    "        fig.legend(\n",
    "            handles_for_legend,\n",
    "            labels_for_legend,\n",
    "            loc=\"lower center\",\n",
    "            ncol=len(handles_for_legend),\n",
    "            bbox_to_anchor=(0.5, -0.02),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.savefig(OUT_PNG, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved multipanel burned area plot to:\\n  {OUT_PNG}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03ca13-1239-414e-bc21-02f685e5698d",
   "metadata": {},
   "source": [
    "new plot with fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbde1bd9-1ee4-43b5-a589-ee8f85f5b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_neg50_w2.csv\n",
      "Found 23 ecoregions after exclusion: ['ALASKA BOREAL INTERIOR', 'ALASKA TUNDRA', 'ARCTIC CORDILLERA', 'Arctic Deserts and Tundra', 'BOREAL CORDILLERA', 'BOREAL PLAIN', 'BROOKS RANGE TUNDRA', 'Central Taiga', 'Forest Tundra', 'HUDSON PLAIN', 'MARINE WEST COAST FOREST', 'Montane Boreal', 'Montane Sub-Arctic', 'Montane Sub-Boreal', 'NORTHERN ARCTIC', 'Northern Taiga', 'SOFTWOOD SHIELD', 'SOUTHERN ARCTIC', 'Southern Taiga', 'TAIGA CORDILLERA', 'TAIGA PLAIN', 'TAIGA SHIELD', 'Wetlands']\n",
      "Saved multipanel burned area plot to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_multipanel_by_ecoregion_floating_y_neg50_w2.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Read precomputed burned area CSV and create a multipanel plot:\n",
    "\n",
    "  - Input: burned_area_by_ecoregion_predictions_neg50_w2.csv\n",
    "      columns:\n",
    "        - ecoregion (ECO_ID_COL)\n",
    "        - year\n",
    "        - ba_mcd_native_Mha\n",
    "        - ba_firecci_native_Mha\n",
    "        - ba_pred_Mha                (older prediction set)\n",
    "        - ba_pred_Mha_neg50_w2       (new NEG=50%, w=2 predictions)\n",
    "\n",
    "  - Output:\n",
    "      burned_area_multipanel_by_ecoregion_floating_y_neg50_w2.png\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "IN_CSV  = OUT_DIR / \"burned_area_by_ecoregion_predictions_neg50_w2.csv\"\n",
    "OUT_PNG = OUT_DIR / \"burned_area_multipanel_by_ecoregion_floating_y_neg50_w2.png\"\n",
    "\n",
    "# columns to plot + nicer labels\n",
    "COLS_AREA = [\n",
    "    \"ba_mcd_native_Mha\",\n",
    "    \"ba_firecci_native_Mha\",\n",
    "    \"ba_pred_Mha\",\n",
    "    \"ba_pred_Mha_neg50_w2\",\n",
    "]\n",
    "\n",
    "LABELS = {\n",
    "    \"ba_mcd_native_Mha\":      \"MCD64A1\",\n",
    "    \"ba_firecci_native_Mha\":  \"Fire CCI\",\n",
    "    \"ba_pred_Mha\":            \"Predictions (neg40 w3)\",\n",
    "    \"ba_pred_Mha_neg50_w2\":   \"Predictions (neg50 w2)\",\n",
    "}\n",
    "\n",
    "# Ecoregions to exclude from plotting\n",
    "EXCLUDE_ECOS = {\n",
    "    \"WATER\",\n",
    "    \"MIXED WOOD SHIELD\",\n",
    "    \"TEMPERATE PRAIRIES\",\n",
    "    \"WESTERN CORDILLERA\",\n",
    "}\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(f\"Reading CSV: {IN_CSV}\")\n",
    "    df = pd.read_csv(IN_CSV)\n",
    "\n",
    "    # Basic sanity\n",
    "    missing_cols = [c for c in [ECO_ID_COL, \"year\"] + COLS_AREA if c not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing expected columns in CSV: {missing_cols}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "\n",
    "    # Unique ecoregions excluding the undesired ones\n",
    "    ecos_all = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    ecos_list = [e for e in ecos_all if e not in EXCLUDE_ECOS]\n",
    "\n",
    "    if not ecos_list:\n",
    "        print(\"No ecoregions left after exclusion; nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    n_ecos = len(ecos_list)\n",
    "    print(f\"Found {n_ecos} ecoregions after exclusion: {ecos_list}\")\n",
    "\n",
    "    # Layout: up to 4 columns\n",
    "    ncols = 4 if n_ecos > 4 else n_ecos\n",
    "    nrows = int(np.ceil(n_ecos / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(4 * ncols, 3 * nrows),\n",
    "        sharex=True,\n",
    "        sharey=False,  # floating y-axis\n",
    "    )\n",
    "\n",
    "    # Normalize axes to 2D array\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif nrows == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif ncols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    handles_for_legend, labels_for_legend = None, None\n",
    "\n",
    "    # Plot per ecoregion\n",
    "    for i, eco_id in enumerate(ecos_list):\n",
    "        row = i // ncols\n",
    "        col = i % ncols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        df_eco = df[df[ECO_ID_COL] == eco_id]\n",
    "\n",
    "        # plot all datasets\n",
    "        for col_name in COLS_AREA:\n",
    "            if col_name in df_eco.columns and df_eco[col_name].notna().any():\n",
    "                ax.plot(\n",
    "                    df_eco[\"year\"],\n",
    "                    df_eco[col_name],\n",
    "                    marker=\"o\",\n",
    "                    label=LABELS[col_name],\n",
    "                )\n",
    "\n",
    "        # capture legend handles after all lines for the first ecoregion\n",
    "        if handles_for_legend is None:\n",
    "            h, l = ax.get_legend_handles_labels()\n",
    "            if h:\n",
    "                handles_for_legend, labels_for_legend = h, l\n",
    "\n",
    "        ax.set_title(str(eco_id))\n",
    "        ax.grid(True, ls=\"--\", alpha=0.4)\n",
    "\n",
    "        # floating y-axis logic\n",
    "        ydata_list = [df_eco[c].dropna().values for c in COLS_AREA if c in df_eco.columns]\n",
    "        if ydata_list:\n",
    "            ydata = np.concatenate(ydata_list)\n",
    "            if ydata.size == 0 or np.nanmax(ydata) == 0:\n",
    "                ax.set_ylim(0, 1.0)\n",
    "        else:\n",
    "            ax.set_ylim(0, 1.0)\n",
    "\n",
    "        if row == nrows - 1:\n",
    "            ax.set_xlabel(\"Year\")\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(\"Burned area (Mha)\")\n",
    "\n",
    "    # Hide unused panels\n",
    "    total_plots = nrows * ncols\n",
    "    if total_plots > n_ecos:\n",
    "        for j in range(n_ecos, total_plots):\n",
    "            row = j // ncols\n",
    "            col = j % ncols\n",
    "            axes[row, col].axis(\"off\")\n",
    "\n",
    "    # Global legend at bottom with all four dataset names\n",
    "    if handles_for_legend:\n",
    "        fig.legend(\n",
    "            handles_for_legend,\n",
    "            labels_for_legend,\n",
    "            loc=\"lower center\",\n",
    "            ncol=len(handles_for_legend),\n",
    "            bbox_to_anchor=(0.5, -0.02),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.savefig(OUT_PNG, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved multipanel burned area plot to:\\n  {OUT_PNG}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b32c1-cbfa-4039-87ae-68ae21ebb26f",
   "metadata": {},
   "source": [
    "All plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3e9753-7b4f-4fa6-b22a-ed9175f4974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV: /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/burned_area_by_ecoregion_predictions_all_models.csv\n",
      "Prediction columns to plot:\n",
      "  - ba_pred_Mha\n",
      "  - ba_pred_Mha_neg10_w1\n",
      "  - ba_pred_Mha_neg10_w2\n",
      "  - ba_pred_Mha_neg10_w3\n",
      "  - ba_pred_Mha_neg10_w5\n",
      "  - ba_pred_Mha_neg20_w1\n",
      "  - ba_pred_Mha_neg20_w2\n",
      "  - ba_pred_Mha_neg20_w3\n",
      "  - ba_pred_Mha_neg20_w5\n",
      "  - ba_pred_Mha_neg30_w1\n",
      "  - ba_pred_Mha_neg30_w2\n",
      "  - ba_pred_Mha_neg30_w3\n",
      "  - ba_pred_Mha_neg30_w5\n",
      "  - ba_pred_Mha_neg40_w1\n",
      "  - ba_pred_Mha_neg40_w2\n",
      "  - ba_pred_Mha_neg40_w3\n",
      "  - ba_pred_Mha_neg40_w5\n",
      "  - ba_pred_Mha_neg50_w1\n",
      "  - ba_pred_Mha_neg50_w2\n",
      "  - ba_pred_Mha_neg50_w3\n",
      "  - ba_pred_Mha_neg50_w5\n",
      "  - ba_pred_Mha_neg60_w1\n",
      "  - ba_pred_Mha_neg60_w2\n",
      "  - ba_pred_Mha_neg60_w3\n",
      "  - ba_pred_Mha_neg60_w5\n",
      "  - ba_pred_Mha_neg70_w1\n",
      "  - ba_pred_Mha_neg70_w2\n",
      "  - ba_pred_Mha_neg70_w3\n",
      "  - ba_pred_Mha_neg70_w5\n",
      "  - ba_pred_Mha_neg80_w1\n",
      "  - ba_pred_Mha_neg80_w2\n",
      "  - ba_pred_Mha_neg80_w3\n",
      "  - ba_pred_Mha_neg80_w5\n",
      "  - ba_pred_Mha_neg90_w1\n",
      "  - ba_pred_Mha_neg90_w2\n",
      "  - ba_pred_Mha_neg90_w3\n",
      "  - ba_pred_Mha_neg90_w5\n",
      "  - ba_pred_Mha_neg100_w1\n",
      "  - ba_pred_Mha_neg100_w2\n",
      "  - ba_pred_Mha_neg100_w3\n",
      "  - ba_pred_Mha_neg100_w5\n",
      "Found 23 ecoregions after exclusion: ['ALASKA BOREAL INTERIOR', 'ALASKA TUNDRA', 'ARCTIC CORDILLERA', 'Arctic Deserts and Tundra', 'BOREAL CORDILLERA', 'BOREAL PLAIN', 'BROOKS RANGE TUNDRA', 'Central Taiga', 'Forest Tundra', 'HUDSON PLAIN', 'MARINE WEST COAST FOREST', 'Montane Boreal', 'Montane Sub-Arctic', 'Montane Sub-Boreal', 'NORTHERN ARCTIC', 'Northern Taiga', 'SOFTWOOD SHIELD', 'SOUTHERN ARCTIC', 'Southern Taiga', 'TAIGA CORDILLERA', 'TAIGA PLAIN', 'TAIGA SHIELD', 'Wetlands']\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha\n",
      "  -> Saved multipanel PNG for ba_pred_Mha to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_orig.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg10_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg10_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg10_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg10_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg10_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg10_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg10_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg10_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg10_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg10_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg10_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg10_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg20_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg20_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg20_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg20_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg20_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg20_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg20_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg20_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg20_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg20_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg20_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg20_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg30_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg30_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg30_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg30_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg30_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg30_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg30_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg30_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg30_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg30_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg30_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg30_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg40_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg40_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg40_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg40_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg40_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg40_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg40_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg40_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg40_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg40_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg40_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg40_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg50_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg50_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg50_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg50_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg50_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg50_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg50_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg50_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg50_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg50_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg50_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg50_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg60_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg60_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg60_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg60_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg60_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg60_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg60_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg60_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg60_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg60_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg60_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg60_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg70_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg70_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg70_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg70_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg70_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg70_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg70_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg70_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg70_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg70_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg70_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg70_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg80_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg80_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg80_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg80_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg80_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg80_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg80_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg80_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg80_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg80_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg80_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg80_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg90_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg90_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg90_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg90_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg90_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg90_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg90_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg90_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg90_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg90_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg90_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg90_w5.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg100_w1\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg100_w1 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg100_w1.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg100_w2\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg100_w2 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg100_w2.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg100_w3\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg100_w3 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg100_w3.png\n",
      "\n",
      "==============================================\n",
      "Creating multipanel plot for prediction column: ba_pred_Mha_neg100_w5\n",
      "  -> Saved multipanel PNG for ba_pred_Mha_neg100_w5 to:\n",
      "     /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model/burned_area_multipanel_neg100_w5.png\n",
      "\n",
      "✅ Done. One multipanel PNG per prediction model written to:\n",
      "  /explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries/multipanel_per_model\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "For EACH prediction column (ba_pred_Mha, ba_pred_Mha_negXX_wY, ...),\n",
    "create a multipanel plot (ecoregions as subplots) comparing:\n",
    "\n",
    "    - MCD64A1 (ba_mcd_native_Mha)\n",
    "    - Fire CCI (ba_firecci_native_Mha)\n",
    "    - That specific prediction column\n",
    "\n",
    "Input:\n",
    "    burned_area_by_ecoregion_predictions_all_models.csv\n",
    "\n",
    "Output:\n",
    "    <OUT_DIR>/multipanel_per_model/burned_area_multipanel_<pred_col>.png\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "ECO_ID_COL = \"ecoregion\"\n",
    "\n",
    "OUT_DIR = Path(\"/explore/nobackup/people/spotter5/clelland_fire_ml/burned_area_summaries\")\n",
    "IN_CSV  = OUT_DIR / \"burned_area_by_ecoregion_predictions_all_models.csv\"\n",
    "\n",
    "# Folder where all multipanel PNGs (one per model) will go\n",
    "OUT_PNG_DIR = OUT_DIR / \"multipanel_per_model\"\n",
    "OUT_PNG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base / native columns\n",
    "MCD_COL      = \"ba_mcd_native_Mha\"\n",
    "FIRECCI_COL  = \"ba_firecci_native_Mha\"\n",
    "\n",
    "BASE_LABELS = {\n",
    "    MCD_COL: \"MCD64A1\",\n",
    "    FIRECCI_COL: \"Fire CCI\",\n",
    "}\n",
    "\n",
    "# Ecoregions to exclude from plotting\n",
    "EXCLUDE_ECOS = {\n",
    "    \"WATER\",\n",
    "    \"MIXED WOOD SHIELD\",\n",
    "    \"TEMPERATE PRAIRIES\",\n",
    "    \"WESTERN CORDILLERA\",\n",
    "}\n",
    "\n",
    "\n",
    "def nice_pred_label(colname: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn prediction column names into nicer legend labels.\n",
    "    Examples:\n",
    "      ba_pred_Mha              -> \"Pred (orig)\"\n",
    "      ba_pred_Mha_neg50_w2     -> \"Pred neg50 w2\"\n",
    "    \"\"\"\n",
    "    if colname == \"ba_pred_Mha\":\n",
    "        return \"Pred (orig)\"\n",
    "\n",
    "    if colname.startswith(\"ba_pred_Mha_\"):\n",
    "        sfx = colname.replace(\"ba_pred_Mha_\", \"\").replace(\"_\", \" \")\n",
    "        return f\"Pred {sfx}\"\n",
    "\n",
    "    return colname\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "\n",
    "def main():\n",
    "    print(f\"Reading CSV: {IN_CSV}\")\n",
    "    df = pd.read_csv(IN_CSV)\n",
    "\n",
    "    # Basic sanity check\n",
    "    needed_base = [ECO_ID_COL, \"year\", MCD_COL, FIRECCI_COL]\n",
    "    missing_base = [c for c in needed_base if c not in df.columns]\n",
    "    if missing_base:\n",
    "        raise ValueError(f\"Missing base columns in CSV: {missing_base}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"year\", ECO_ID_COL])\n",
    "\n",
    "    # Find all prediction columns (anything starting with ba_pred_Mha)\n",
    "    pred_cols = [c for c in df.columns if c.startswith(\"ba_pred_Mha\")]\n",
    "    if not pred_cols:\n",
    "        raise ValueError(\"No prediction columns starting with 'ba_pred_Mha' found in CSV.\")\n",
    "\n",
    "    print(\"Prediction columns to plot:\")\n",
    "    for c in pred_cols:\n",
    "        print(\"  -\", c)\n",
    "\n",
    "    # Unique ecoregions excluding the undesired ones\n",
    "    ecos_all = sorted(df[ECO_ID_COL].dropna().unique())\n",
    "    ecos_list = [e for e in ecos_all if e not in EXCLUDE_ECOS]\n",
    "\n",
    "    if not ecos_list:\n",
    "        print(\"No ecoregions left after exclusion; nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    n_ecos = len(ecos_list)\n",
    "    print(f\"Found {n_ecos} ecoregions after exclusion: {ecos_list}\")\n",
    "\n",
    "    # Loop over each prediction column and make a separate multipanel PNG\n",
    "    for pred_col in pred_cols:\n",
    "        print(\"\\n==============================================\")\n",
    "        print(f\"Creating multipanel plot for prediction column: {pred_col}\")\n",
    "\n",
    "        # Columns to plot in this figure\n",
    "        COLS_AREA = [MCD_COL, FIRECCI_COL, pred_col]\n",
    "        LABELS = {\n",
    "            MCD_COL: BASE_LABELS[MCD_COL],\n",
    "            FIRECCI_COL: BASE_LABELS[FIRECCI_COL],\n",
    "            pred_col: nice_pred_label(pred_col),\n",
    "        }\n",
    "\n",
    "        # Layout: up to 4 columns of subplots\n",
    "        ncols = 4 if n_ecos > 4 else n_ecos\n",
    "        nrows = int(np.ceil(n_ecos / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(4 * ncols, 3 * nrows),\n",
    "            sharex=True,\n",
    "            sharey=False,  # floating y-axis per panel\n",
    "        )\n",
    "\n",
    "        # Normalize axes to 2D array\n",
    "        if nrows == 1 and ncols == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif nrows == 1:\n",
    "            axes = np.array([axes])\n",
    "        elif ncols == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "\n",
    "        handles_for_legend, labels_for_legend = None, None\n",
    "\n",
    "        # Plot per ecoregion\n",
    "        for i, eco_id in enumerate(ecos_list):\n",
    "            row = i // ncols\n",
    "            col = i % ncols\n",
    "            ax = axes[row, col]\n",
    "\n",
    "            df_eco = df[df[ECO_ID_COL] == eco_id]\n",
    "\n",
    "            # Plot all three datasets for this model\n",
    "            for col_name in COLS_AREA:\n",
    "                if col_name in df_eco.columns and df_eco[col_name].notna().any():\n",
    "                    ax.plot(\n",
    "                        df_eco[\"year\"],\n",
    "                        df_eco[col_name],\n",
    "                        marker=\"o\",\n",
    "                        label=LABELS[col_name],\n",
    "                    )\n",
    "\n",
    "            # Capture legend handles from first non-empty panel\n",
    "            if handles_for_legend is None:\n",
    "                h, l = ax.get_legend_handles_labels()\n",
    "                if h:\n",
    "                    handles_for_legend, labels_for_legend = h, l\n",
    "\n",
    "            ax.set_title(str(eco_id))\n",
    "            ax.grid(True, ls=\"--\", alpha=0.4)\n",
    "\n",
    "            # Floating y-axis logic: choose sensible default if all zeros / NaN\n",
    "            ydata_list = [df_eco[c].dropna().values for c in COLS_AREA if c in df_eco.columns]\n",
    "            if ydata_list:\n",
    "                ydata = np.concatenate(ydata_list)\n",
    "                if ydata.size == 0 or np.nanmax(ydata) == 0:\n",
    "                    ax.set_ylim(0, 1.0)\n",
    "            else:\n",
    "                ax.set_ylim(0, 1.0)\n",
    "\n",
    "            if row == nrows - 1:\n",
    "                ax.set_xlabel(\"Year\")\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(\"Burned area (Mha)\")\n",
    "\n",
    "        # Hide unused panels\n",
    "        total_plots = nrows * ncols\n",
    "        if total_plots > n_ecos:\n",
    "            for j in range(n_ecos, total_plots):\n",
    "                row = j // ncols\n",
    "                col = j % ncols\n",
    "                axes[row, col].axis(\"off\")\n",
    "\n",
    "        # Global legend at bottom\n",
    "        if handles_for_legend:\n",
    "            fig.legend(\n",
    "                handles_for_legend,\n",
    "                labels_for_legend,\n",
    "                loc=\"lower center\",\n",
    "                ncol=len(handles_for_legend),\n",
    "                bbox_to_anchor=(0.5, -0.02),\n",
    "            )\n",
    "\n",
    "        # Clean filenames: replace spaces with underscores\n",
    "        pred_tag = pred_col.replace(\"ba_pred_Mha_\", \"\") if pred_col != \"ba_pred_Mha\" else \"orig\"\n",
    "        pred_tag = pred_tag.replace(\" \", \"_\")\n",
    "\n",
    "        out_png = OUT_PNG_DIR / f\"burned_area_multipanel_{pred_tag}.png\"\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "        plt.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"  -> Saved multipanel PNG for {pred_col} to:\\n     {out_png}\")\n",
    "\n",
    "    print(\"\\n✅ Done. One multipanel PNG per prediction model written to:\")\n",
    "    print(f\"  {OUT_PNG_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e9287-0452-42e8-a083-3b7206f29d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning_old]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning_old-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
